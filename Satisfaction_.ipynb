{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Satisfaction.",
      "provenance": [],
      "authorship_tag": "ABX9TyM3zHwgl+QWXWTyX1urtRPO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wcaraker76/4GeeksProjects/blob/main/Satisfaction_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HOjltJuTh6H",
        "outputId": "2e3d9e77-c1f1-42b5-cde9-c91db4a55ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import imblearn\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "2rNOIqIwTs9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the data \n",
        "data = pd.read_csv('/content/drive/MyDrive/train.csv')"
      ],
      "metadata": {
        "id": "B5PKgA21UG4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display the data to see what it looks like\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "vPHBG1-WU5Bh",
        "outputId": "8f54a928-d088-4a2f-af4c-45c1587e55df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
              "0           1     2     23                 0.0                      0.0   \n",
              "1           3     2     34                 0.0                      0.0   \n",
              "2           4     2     23                 0.0                      0.0   \n",
              "3           8     2     37                 0.0                    195.0   \n",
              "4          10     2     39                 0.0                      0.0   \n",
              "...       ...   ...    ...                 ...                      ...   \n",
              "76015  151829     2     48                 0.0                      0.0   \n",
              "76016  151830     2     39                 0.0                      0.0   \n",
              "76017  151835     2     23                 0.0                      0.0   \n",
              "76018  151836     2     25                 0.0                      0.0   \n",
              "76019  151838     2     46                 0.0                      0.0   \n",
              "\n",
              "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
              "0                          0.0                      0.0   \n",
              "1                          0.0                      0.0   \n",
              "2                          0.0                      0.0   \n",
              "3                        195.0                      0.0   \n",
              "4                          0.0                      0.0   \n",
              "...                        ...                      ...   \n",
              "76015                      0.0                      0.0   \n",
              "76016                      0.0                      0.0   \n",
              "76017                      0.0                      0.0   \n",
              "76018                      0.0                      0.0   \n",
              "76019                      0.0                      0.0   \n",
              "\n",
              "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
              "0                          0.0                      0.0   \n",
              "1                          0.0                      0.0   \n",
              "2                          0.0                      0.0   \n",
              "3                          0.0                      0.0   \n",
              "4                          0.0                      0.0   \n",
              "...                        ...                      ...   \n",
              "76015                      0.0                      0.0   \n",
              "76016                      0.0                      0.0   \n",
              "76017                      0.0                      0.0   \n",
              "76018                      0.0                      0.0   \n",
              "76019                      0.0                      0.0   \n",
              "\n",
              "       imp_op_var40_efect_ult3  ...  saldo_medio_var33_hace2  \\\n",
              "0                          0.0  ...                      0.0   \n",
              "1                          0.0  ...                      0.0   \n",
              "2                          0.0  ...                      0.0   \n",
              "3                          0.0  ...                      0.0   \n",
              "4                          0.0  ...                      0.0   \n",
              "...                        ...  ...                      ...   \n",
              "76015                      0.0  ...                      0.0   \n",
              "76016                      0.0  ...                      0.0   \n",
              "76017                      0.0  ...                      0.0   \n",
              "76018                      0.0  ...                      0.0   \n",
              "76019                      0.0  ...                      0.0   \n",
              "\n",
              "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
              "0                          0.0                     0.0   \n",
              "1                          0.0                     0.0   \n",
              "2                          0.0                     0.0   \n",
              "3                          0.0                     0.0   \n",
              "4                          0.0                     0.0   \n",
              "...                        ...                     ...   \n",
              "76015                      0.0                     0.0   \n",
              "76016                      0.0                     0.0   \n",
              "76017                      0.0                     0.0   \n",
              "76018                      0.0                     0.0   \n",
              "76019                      0.0                     0.0   \n",
              "\n",
              "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
              "0                         0.0                      0.0   \n",
              "1                         0.0                      0.0   \n",
              "2                         0.0                      0.0   \n",
              "3                         0.0                      0.0   \n",
              "4                         0.0                      0.0   \n",
              "...                       ...                      ...   \n",
              "76015                     0.0                      0.0   \n",
              "76016                     0.0                      0.0   \n",
              "76017                     0.0                      0.0   \n",
              "76018                     0.0                      0.0   \n",
              "76019                     0.0                      0.0   \n",
              "\n",
              "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
              "0                          0.0                     0.0   \n",
              "1                          0.0                     0.0   \n",
              "2                          0.0                     0.0   \n",
              "3                          0.0                     0.0   \n",
              "4                          0.0                     0.0   \n",
              "...                        ...                     ...   \n",
              "76015                      0.0                     0.0   \n",
              "76016                      0.0                     0.0   \n",
              "76017                      0.0                     0.0   \n",
              "76018                      0.0                     0.0   \n",
              "76019                      0.0                     0.0   \n",
              "\n",
              "       saldo_medio_var44_ult3          var38  TARGET  \n",
              "0                         0.0   39205.170000       0  \n",
              "1                         0.0   49278.030000       0  \n",
              "2                         0.0   67333.770000       0  \n",
              "3                         0.0   64007.970000       0  \n",
              "4                         0.0  117310.979016       0  \n",
              "...                       ...            ...     ...  \n",
              "76015                     0.0   60926.490000       0  \n",
              "76016                     0.0  118634.520000       0  \n",
              "76017                     0.0   74028.150000       0  \n",
              "76018                     0.0   84278.160000       0  \n",
              "76019                     0.0  117310.979016       0  \n",
              "\n",
              "[76020 rows x 371 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f1bfdfe-af7c-4293-87f0-6b0ec57c0350\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39205.170000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49278.030000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67333.770000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64007.970000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117310.979016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76015</th>\n",
              "      <td>151829</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60926.490000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76016</th>\n",
              "      <td>151830</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118634.520000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76017</th>\n",
              "      <td>151835</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74028.150000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76018</th>\n",
              "      <td>151836</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84278.160000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76019</th>\n",
              "      <td>151838</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117310.979016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76020 rows × 371 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f1bfdfe-af7c-4293-87f0-6b0ec57c0350')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f1bfdfe-af7c-4293-87f0-6b0ec57c0350 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f1bfdfe-af7c-4293-87f0-6b0ec57c0350');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#statistics for the data set \n",
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "7wehlU0KU661",
        "outputId": "5ded9688-ef19-4379-bc58-db46e505de65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
              "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
              "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
              "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
              "min         1.000000 -999999.000000      5.000000            0.000000   \n",
              "25%     38104.750000       2.000000     23.000000            0.000000   \n",
              "50%     76043.000000       2.000000     28.000000            0.000000   \n",
              "75%    113748.750000       2.000000     40.000000            0.000000   \n",
              "max    151838.000000     238.000000    105.000000       210000.000000   \n",
              "\n",
              "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                 72.363067               119.529632   \n",
              "std                 339.315831               546.266294   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max               12888.030000             21024.810000   \n",
              "\n",
              "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                  3.559130                 6.472698   \n",
              "std                  93.155749               153.737066   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max                8237.820000             11073.570000   \n",
              "\n",
              "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
              "count             76020.000000             76020.000000  ...   \n",
              "mean                  0.412946                 0.567352  ...   \n",
              "std                  30.604864                36.513513  ...   \n",
              "min                   0.000000                 0.000000  ...   \n",
              "25%                   0.000000                 0.000000  ...   \n",
              "50%                   0.000000                 0.000000  ...   \n",
              "75%                   0.000000                 0.000000  ...   \n",
              "max                6600.000000              6600.000000  ...   \n",
              "\n",
              "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                  7.935824                 1.365146   \n",
              "std                 455.887218               113.959637   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max               50003.880000             20385.720000   \n",
              "\n",
              "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
              "count            76020.000000            76020.000000   \n",
              "mean                12.215580                8.784074   \n",
              "std                783.207399              538.439211   \n",
              "min                  0.000000                0.000000   \n",
              "25%                  0.000000                0.000000   \n",
              "50%                  0.000000                0.000000   \n",
              "75%                  0.000000                0.000000   \n",
              "max             138831.630000            91778.730000   \n",
              "\n",
              "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                 31.505324                 1.858575   \n",
              "std                2013.125393               147.786584   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max              438329.220000             24650.010000   \n",
              "\n",
              "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
              "count            76020.000000            76020.000000  7.602000e+04   \n",
              "mean                76.026165               56.614351  1.172358e+05   \n",
              "std               4040.337842             2852.579397  1.826646e+05   \n",
              "min                  0.000000                0.000000  5.163750e+03   \n",
              "25%                  0.000000                0.000000  6.787061e+04   \n",
              "50%                  0.000000                0.000000  1.064092e+05   \n",
              "75%                  0.000000                0.000000  1.187563e+05   \n",
              "max             681462.900000           397884.300000  2.203474e+07   \n",
              "\n",
              "             TARGET  \n",
              "count  76020.000000  \n",
              "mean       0.039569  \n",
              "std        0.194945  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        0.000000  \n",
              "max        1.000000  \n",
              "\n",
              "[8 rows x 371 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a33fbb7d-8bf2-4498-98e1-3a6b51ca63df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>7.602000e+04</td>\n",
              "      <td>76020.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>75964.050723</td>\n",
              "      <td>-1523.199277</td>\n",
              "      <td>33.212865</td>\n",
              "      <td>86.208265</td>\n",
              "      <td>72.363067</td>\n",
              "      <td>119.529632</td>\n",
              "      <td>3.559130</td>\n",
              "      <td>6.472698</td>\n",
              "      <td>0.412946</td>\n",
              "      <td>0.567352</td>\n",
              "      <td>...</td>\n",
              "      <td>7.935824</td>\n",
              "      <td>1.365146</td>\n",
              "      <td>12.215580</td>\n",
              "      <td>8.784074</td>\n",
              "      <td>31.505324</td>\n",
              "      <td>1.858575</td>\n",
              "      <td>76.026165</td>\n",
              "      <td>56.614351</td>\n",
              "      <td>1.172358e+05</td>\n",
              "      <td>0.039569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>43781.947379</td>\n",
              "      <td>39033.462364</td>\n",
              "      <td>12.956486</td>\n",
              "      <td>1614.757313</td>\n",
              "      <td>339.315831</td>\n",
              "      <td>546.266294</td>\n",
              "      <td>93.155749</td>\n",
              "      <td>153.737066</td>\n",
              "      <td>30.604864</td>\n",
              "      <td>36.513513</td>\n",
              "      <td>...</td>\n",
              "      <td>455.887218</td>\n",
              "      <td>113.959637</td>\n",
              "      <td>783.207399</td>\n",
              "      <td>538.439211</td>\n",
              "      <td>2013.125393</td>\n",
              "      <td>147.786584</td>\n",
              "      <td>4040.337842</td>\n",
              "      <td>2852.579397</td>\n",
              "      <td>1.826646e+05</td>\n",
              "      <td>0.194945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-999999.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.163750e+03</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>38104.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.787061e+04</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>76043.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.064092e+05</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>113748.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.187563e+05</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>151838.000000</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>210000.000000</td>\n",
              "      <td>12888.030000</td>\n",
              "      <td>21024.810000</td>\n",
              "      <td>8237.820000</td>\n",
              "      <td>11073.570000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>50003.880000</td>\n",
              "      <td>20385.720000</td>\n",
              "      <td>138831.630000</td>\n",
              "      <td>91778.730000</td>\n",
              "      <td>438329.220000</td>\n",
              "      <td>24650.010000</td>\n",
              "      <td>681462.900000</td>\n",
              "      <td>397884.300000</td>\n",
              "      <td>2.203474e+07</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 371 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a33fbb7d-8bf2-4498-98e1-3a6b51ca63df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a33fbb7d-8bf2-4498-98e1-3a6b51ca63df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a33fbb7d-8bf2-4498-98e1-3a6b51ca63df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data[\"TARGET\"] #designate the labels\n",
        "\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLbvwIisVExi",
        "outputId": "1dd6f2a1-3e1b-4c6c-d19b-557992ad2172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "76015    0\n",
              "76016    0\n",
              "76017    0\n",
              "76018    0\n",
              "76019    0\n",
              "Name: TARGET, Length: 76020, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#see if the data is balanced\n",
        "plt.hist(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "xh3YOZxz_oDK",
        "outputId": "07fe3408-e5ad-4801-ec7b-73a0d8d4ca37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([73012.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "            0.,  3008.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove the labels from the data \n",
        "data = data.drop(\"TARGET\", axis=1) \n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "n_sWfF5XVYMK",
        "outputId": "416fa578-50e8-4d99-8306-623585915163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
              "0           1     2     23                 0.0                      0.0   \n",
              "1           3     2     34                 0.0                      0.0   \n",
              "2           4     2     23                 0.0                      0.0   \n",
              "3           8     2     37                 0.0                    195.0   \n",
              "4          10     2     39                 0.0                      0.0   \n",
              "...       ...   ...    ...                 ...                      ...   \n",
              "76015  151829     2     48                 0.0                      0.0   \n",
              "76016  151830     2     39                 0.0                      0.0   \n",
              "76017  151835     2     23                 0.0                      0.0   \n",
              "76018  151836     2     25                 0.0                      0.0   \n",
              "76019  151838     2     46                 0.0                      0.0   \n",
              "\n",
              "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
              "0                          0.0                      0.0   \n",
              "1                          0.0                      0.0   \n",
              "2                          0.0                      0.0   \n",
              "3                        195.0                      0.0   \n",
              "4                          0.0                      0.0   \n",
              "...                        ...                      ...   \n",
              "76015                      0.0                      0.0   \n",
              "76016                      0.0                      0.0   \n",
              "76017                      0.0                      0.0   \n",
              "76018                      0.0                      0.0   \n",
              "76019                      0.0                      0.0   \n",
              "\n",
              "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
              "0                          0.0                      0.0   \n",
              "1                          0.0                      0.0   \n",
              "2                          0.0                      0.0   \n",
              "3                          0.0                      0.0   \n",
              "4                          0.0                      0.0   \n",
              "...                        ...                      ...   \n",
              "76015                      0.0                      0.0   \n",
              "76016                      0.0                      0.0   \n",
              "76017                      0.0                      0.0   \n",
              "76018                      0.0                      0.0   \n",
              "76019                      0.0                      0.0   \n",
              "\n",
              "       imp_op_var40_efect_ult3  ...  saldo_medio_var29_ult3  \\\n",
              "0                          0.0  ...                     0.0   \n",
              "1                          0.0  ...                     0.0   \n",
              "2                          0.0  ...                     0.0   \n",
              "3                          0.0  ...                     0.0   \n",
              "4                          0.0  ...                     0.0   \n",
              "...                        ...  ...                     ...   \n",
              "76015                      0.0  ...                     0.0   \n",
              "76016                      0.0  ...                     0.0   \n",
              "76017                      0.0  ...                     0.0   \n",
              "76018                      0.0  ...                     0.0   \n",
              "76019                      0.0  ...                     0.0   \n",
              "\n",
              "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
              "0                          0.0                      0.0   \n",
              "1                          0.0                      0.0   \n",
              "2                          0.0                      0.0   \n",
              "3                          0.0                      0.0   \n",
              "4                          0.0                      0.0   \n",
              "...                        ...                      ...   \n",
              "76015                      0.0                      0.0   \n",
              "76016                      0.0                      0.0   \n",
              "76017                      0.0                      0.0   \n",
              "76018                      0.0                      0.0   \n",
              "76019                      0.0                      0.0   \n",
              "\n",
              "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
              "0                         0.0                     0.0   \n",
              "1                         0.0                     0.0   \n",
              "2                         0.0                     0.0   \n",
              "3                         0.0                     0.0   \n",
              "4                         0.0                     0.0   \n",
              "...                       ...                     ...   \n",
              "76015                     0.0                     0.0   \n",
              "76016                     0.0                     0.0   \n",
              "76017                     0.0                     0.0   \n",
              "76018                     0.0                     0.0   \n",
              "76019                     0.0                     0.0   \n",
              "\n",
              "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
              "0                          0.0                      0.0   \n",
              "1                          0.0                      0.0   \n",
              "2                          0.0                      0.0   \n",
              "3                          0.0                      0.0   \n",
              "4                          0.0                      0.0   \n",
              "...                        ...                      ...   \n",
              "76015                      0.0                      0.0   \n",
              "76016                      0.0                      0.0   \n",
              "76017                      0.0                      0.0   \n",
              "76018                      0.0                      0.0   \n",
              "76019                      0.0                      0.0   \n",
              "\n",
              "       saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  \n",
              "0                         0.0                     0.0   39205.170000  \n",
              "1                         0.0                     0.0   49278.030000  \n",
              "2                         0.0                     0.0   67333.770000  \n",
              "3                         0.0                     0.0   64007.970000  \n",
              "4                         0.0                     0.0  117310.979016  \n",
              "...                       ...                     ...            ...  \n",
              "76015                     0.0                     0.0   60926.490000  \n",
              "76016                     0.0                     0.0  118634.520000  \n",
              "76017                     0.0                     0.0   74028.150000  \n",
              "76018                     0.0                     0.0   84278.160000  \n",
              "76019                     0.0                     0.0  117310.979016  \n",
              "\n",
              "[76020 rows x 370 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-975c7785-0e5c-4cd4-9273-1b82302b0c9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var29_ult3</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39205.170000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49278.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67333.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64007.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117310.979016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76015</th>\n",
              "      <td>151829</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60926.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76016</th>\n",
              "      <td>151830</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118634.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76017</th>\n",
              "      <td>151835</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74028.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76018</th>\n",
              "      <td>151836</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84278.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76019</th>\n",
              "      <td>151838</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117310.979016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76020 rows × 370 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-975c7785-0e5c-4cd4-9273-1b82302b0c9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-975c7785-0e5c-4cd4-9273-1b82302b0c9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-975c7785-0e5c-4cd4-9273-1b82302b0c9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count up the number of NaNs in the data set\n",
        "na = data.isna().sum()"
      ],
      "metadata": {
        "id": "dMjcpp63VgnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "na.unique() #there is no missing data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wOr98tJVymJ",
        "outputId": "26df12ba-9c2a-4042-ab53-32130da8e178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#display the values in the columns\n",
        "data.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoG_Er_hWTxu",
        "outputId": "ff16bfb1-ab5a-4f7d-8f48-eed34eb4ab34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID      var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  imp_op_var41_comer_ult1  imp_op_var41_comer_ult3  imp_op_var41_efect_ult1  imp_op_var41_efect_ult3  imp_op_var41_ult1  imp_op_var39_efect_ult1  imp_op_var39_efect_ult3  imp_op_var39_ult1  imp_sal_var16_ult1  ind_var1_0  ind_var1  ind_var2_0  ind_var2  ind_var5_0  ind_var5  ind_var6_0  ind_var6  ind_var8_0  ind_var8  ind_var12_0  ind_var12  ind_var13_0  ind_var13_corto_0  ind_var13_corto  ind_var13_largo_0  ind_var13_largo  ind_var13_medio_0  ind_var13_medio  ind_var13  ind_var14_0  ind_var14  ind_var17_0  ind_var17  ind_var18_0  ind_var18  ind_var19  ind_var20_0  ind_var20  ind_var24_0  ind_var24  ind_var25_cte  ind_var26_0  ind_var26_cte  ind_var26  ind_var25_0  ind_var25  ind_var27_0  ind_var28_0  ind_var28  ind_var27  ind_var29_0  ind_var29  ind_var30_0  ind_var30  ind_var31_0  ind_var31  ind_var32_cte  ind_var32_0  ind_var32  ind_var33_0  ind_var33  ind_var34_0  ind_var34  ind_var37_cte  ind_var37_0  ind_var37  ind_var39_0  ind_var40_0  ind_var40  ind_var41_0  ind_var41  ind_var39  ind_var44_0  ind_var44  ind_var46_0  ind_var46  num_var1_0  num_var1  num_var4  num_var5_0  num_var5  num_var6_0  num_var6  num_var8_0  num_var8  num_var12_0  num_var12  num_var13_0  num_var13_corto_0  num_var13_corto  num_var13_largo_0  num_var13_largo  num_var13_medio_0  num_var13_medio  num_var13  num_var14_0  num_var14  num_var17_0  num_var17  num_var18_0  num_var18  num_var20_0  num_var20  num_var24_0  num_var24  num_var26_0  num_var26  num_var25_0  num_var25  num_op_var40_hace2  num_op_var40_hace3  num_op_var40_ult1  num_op_var40_ult3  num_op_var41_hace2  num_op_var41_hace3  num_op_var41_ult1  num_op_var41_ult3  num_op_var39_hace2  num_op_var39_hace3  num_op_var39_ult1  num_op_var39_ult3  num_var27_0  num_var28_0  num_var28  num_var27  num_var29_0  num_var29  num_var30_0  num_var30  num_var31_0  num_var31  num_var32_0  num_var32  num_var33_0  num_var33  num_var34_0  num_var34  num_var35  num_var37_med_ult2  num_var37_0  num_var37  num_var39_0  num_var40_0  num_var40  num_var41_0  num_var41  num_var39  num_var42_0  num_var42  num_var44_0  num_var44  num_var46_0  num_var46  saldo_var1  saldo_var5  saldo_var6  saldo_var8  saldo_var12  saldo_var13_corto  saldo_var13_largo  saldo_var13_medio  saldo_var13  saldo_var14  saldo_var17  saldo_var18  saldo_var20  saldo_var24  saldo_var26  saldo_var25  saldo_var28  saldo_var27  saldo_var29  saldo_var30  saldo_var31  saldo_var32  saldo_var33  saldo_var34  saldo_var37  saldo_var40  saldo_var41  saldo_var42  saldo_var44  saldo_var46  var36  delta_imp_amort_var18_1y3  delta_imp_amort_var34_1y3  delta_imp_aport_var13_1y3  delta_imp_aport_var17_1y3  delta_imp_aport_var33_1y3  delta_imp_compra_var44_1y3  delta_imp_reemb_var13_1y3  delta_imp_reemb_var17_1y3  delta_imp_reemb_var33_1y3  delta_imp_trasp_var17_in_1y3  delta_imp_trasp_var17_out_1y3  delta_imp_trasp_var33_in_1y3  delta_imp_trasp_var33_out_1y3  delta_imp_venta_var44_1y3  delta_num_aport_var13_1y3  delta_num_aport_var17_1y3  delta_num_aport_var33_1y3  delta_num_compra_var44_1y3  delta_num_reemb_var13_1y3  delta_num_reemb_var17_1y3  delta_num_reemb_var33_1y3  delta_num_trasp_var17_in_1y3  delta_num_trasp_var17_out_1y3  delta_num_trasp_var33_in_1y3  delta_num_trasp_var33_out_1y3  delta_num_venta_var44_1y3  imp_amort_var18_hace3  imp_amort_var18_ult1  imp_amort_var34_hace3  imp_amort_var34_ult1  imp_aport_var13_hace3  imp_aport_var13_ult1  imp_aport_var17_hace3  imp_aport_var17_ult1  imp_aport_var33_hace3  imp_aport_var33_ult1  imp_var7_emit_ult1  imp_var7_recib_ult1  imp_compra_var44_hace3  imp_compra_var44_ult1  imp_reemb_var13_hace3  imp_reemb_var13_ult1  imp_reemb_var17_hace3  imp_reemb_var17_ult1  imp_reemb_var33_hace3  imp_reemb_var33_ult1  imp_var43_emit_ult1  imp_trans_var37_ult1  imp_trasp_var17_in_hace3  imp_trasp_var17_in_ult1  imp_trasp_var17_out_hace3  imp_trasp_var17_out_ult1  imp_trasp_var33_in_hace3  imp_trasp_var33_in_ult1  imp_trasp_var33_out_hace3  imp_trasp_var33_out_ult1  imp_venta_var44_hace3  imp_venta_var44_ult1  ind_var7_emit_ult1  ind_var7_recib_ult1  ind_var10_ult1  ind_var10cte_ult1  ind_var9_cte_ult1  ind_var9_ult1  ind_var43_emit_ult1  ind_var43_recib_ult1  var21  num_var2_0_ult1  num_var2_ult1  num_aport_var13_hace3  num_aport_var13_ult1  num_aport_var17_hace3  num_aport_var17_ult1  num_aport_var33_hace3  num_aport_var33_ult1  num_var7_emit_ult1  num_var7_recib_ult1  num_compra_var44_hace3  num_compra_var44_ult1  num_ent_var16_ult1  num_var22_hace2  num_var22_hace3  num_var22_ult1  num_var22_ult3  num_med_var22_ult3  num_med_var45_ult3  num_meses_var5_ult3  num_meses_var8_ult3  num_meses_var12_ult3  num_meses_var13_corto_ult3  num_meses_var13_largo_ult3  num_meses_var13_medio_ult3  num_meses_var17_ult3  num_meses_var29_ult3  num_meses_var33_ult3  num_meses_var39_vig_ult3  num_meses_var44_ult3  num_op_var39_comer_ult1  num_op_var39_comer_ult3  num_op_var40_comer_ult1  num_op_var40_comer_ult3  num_op_var40_efect_ult1  num_op_var40_efect_ult3  num_op_var41_comer_ult1  num_op_var41_comer_ult3  num_op_var41_efect_ult1  num_op_var41_efect_ult3  num_op_var39_efect_ult1  num_op_var39_efect_ult3  num_reemb_var13_hace3  num_reemb_var13_ult1  num_reemb_var17_hace3  num_reemb_var17_ult1  num_reemb_var33_hace3  num_reemb_var33_ult1  num_sal_var16_ult1  num_var43_emit_ult1  num_var43_recib_ult1  num_trasp_var11_ult1  num_trasp_var17_in_hace3  num_trasp_var17_in_ult1  num_trasp_var17_out_hace3  num_trasp_var17_out_ult1  num_trasp_var33_in_hace3  num_trasp_var33_in_ult1  num_trasp_var33_out_hace3  num_trasp_var33_out_ult1  num_venta_var44_hace3  num_venta_var44_ult1  num_var45_hace2  num_var45_hace3  num_var45_ult1  num_var45_ult3  saldo_var2_ult1  saldo_medio_var5_hace2  saldo_medio_var5_hace3  saldo_medio_var5_ult1  saldo_medio_var5_ult3  saldo_medio_var8_hace2  saldo_medio_var8_hace3  saldo_medio_var8_ult1  saldo_medio_var8_ult3  saldo_medio_var12_hace2  saldo_medio_var12_hace3  saldo_medio_var12_ult1  saldo_medio_var12_ult3  saldo_medio_var13_corto_hace2  saldo_medio_var13_corto_hace3  saldo_medio_var13_corto_ult1  saldo_medio_var13_corto_ult3  saldo_medio_var13_largo_hace2  saldo_medio_var13_largo_hace3  saldo_medio_var13_largo_ult1  saldo_medio_var13_largo_ult3  saldo_medio_var13_medio_hace2  saldo_medio_var13_medio_hace3  saldo_medio_var13_medio_ult1  saldo_medio_var13_medio_ult3  saldo_medio_var17_hace2  saldo_medio_var17_hace3  saldo_medio_var17_ult1  saldo_medio_var17_ult3  saldo_medio_var29_hace2  saldo_medio_var29_hace3  saldo_medio_var29_ult1  saldo_medio_var29_ult3  saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  saldo_medio_var44_ult1  saldo_medio_var44_ult3  var38        \n",
              "1       2     23     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         1           0         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          0              0            0              0          0            0          0            0            0          0          0            0          1            0          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         0         3           0         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          0            0          0            0          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            0          0            0          0            0          0            0          0            0          0          0                   0            0          3            0            0          3            0          0          3            0          0            0          0            0          0.0         0.0         0.0         0.00        0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         0.00         0.00         0            0            0.0          0.00         0.0          0.0          0.0          0            0.00         0.0          0            0.00         0.0          0            99     0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    0               0                  0                  0              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   0                0                0               0               0                   0                   0                    0                    0                     0                           0                           0                           0                     0                     0                     2                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     0                0                0               0               0                0.00                    0.00                    0.0                    0.00                   0.00                    0.00                    0.00                   0.00                   0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     39205.170000     1\n",
              "101199  2     24     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         1           1         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          0              0            0              0          0            0          0            0            0          0          0            0          1            1          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         1         3           3         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          0            0          0            0          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            3          0            0          0            0          0            0          0            0          3          0                   0            0          3            0            0          3            0          0          3            3          0            0          0            0          0.0         3.0         0.0         0.00        0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         0.00         0.00         0            0            0.0          3.00         0.0          0.0          0.0          0            0.00         0.0          0            3.00         0.0          0            3      0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    0               0                  0                  0              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   0                0                0               0               0                   0                   3                    0                    0                     0                           0                           0                           0                     0                     0                     1                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     0                0                0               0               0                3.00                    0.18                    3.0                    2.07                   0.00                    0.00                    0.00                   0.00                   0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     224430.540000    1\n",
              "101195  2     32     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         1           0         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          0              0            0              0          0            0          0            0            0          0          0            0          1            0          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         0         3           0         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          0            0          0            0          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            0          0            0          0            0          0            0          0            0          0          0                   0            0          3            0            0          3            0          0          3            0          0            0          0            0          0.0         0.0         0.0         0.00        0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         0.00         0.00         0            0            0.0          0.00         0.0          0.0          0.0          0            0.00         0.0          0            0.00         0.0          0            99     0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    0               0                  0                  0              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   3                0                0               3               0                   0                   0                    0                    0                     0                           0                           0                           0                     0                     0                     2                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     3                0                0               3               0                0.00                    0.00                    0.0                    0.00                   0.00                    0.00                    0.00                   0.00                   0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     117310.979016    1\n",
              "101192  2     27     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         1           1         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          0              0            0              0          0            0          0            0            0          0          0            0          1            1          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         1         3           3         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          0            0          0            0          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            3          0            0          0            0          0            0          0            0          3          0                   0            0          3            0            0          3            0          0          3            3          0            0          0            0          0.0         3.0         0.0         0.00        0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         0.00         0.00         0            0            0.0          3.00         0.0          0.0          0.0          0            0.00         0.0          0            3.00         0.0          0            99     0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    0               0                  0                  0              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   6                0                0               6               0                   0                   2                    0                    0                     0                           0                           0                           0                     0                     0                     1                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     6                0                0               6               0                3.00                    0.00                    3.0                    3.00                   0.00                    0.00                    0.00                   0.00                   0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     117310.979016    1\n",
              "101189  2     40     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         0           0         0           0         1           1         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          1              1            1              1          1            1          0            0            0          0          0            0          1            1          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         2         0           0         0           0         3           3         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          3            3          3            3          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            3          0            0          0            0          0            0          0            0          6          0                   0            0          3            0            0          3            0          0          3            3          0            0          0            0          0.0         0.0         0.0         559.44      0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         516.51       516.51       0            0            0.0          559.44       0.0          0.0          0.0          0            0.00         0.0          0            559.44       0.0          0            99     0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    1               1                  1                  1              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   6                0                0               6               0                   3                   1                    2                    0                     0                           0                           0                           0                     0                     0                     1                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     3                3                9               15              0                0.00                    0.09                    0.0                    0.00                   16.35                   0.00                    463.77                 240.06                 0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     71302.530000     1\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ..\n",
              "50751   2     48     0.0                 2928.9                   4881.27                  0.0                      0.0                      0.0                      0.0                      0.0                2928.9                   4881.27                  1260.0                   2010.0                   4188.9             1260.0                   2010.0                   4188.9             0.0                 0           0         0           0         0           0         0           0         1           1         1            1          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          1            1          1              1            1              1          1            1          0            0            0          0          0            0          1            1          0            0          0              0            0          0            0          0            0          1              1            1          1            0            0          1            0          0          0            0          0            0          0           0         5         0           0         0           0         3           3         3            3          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          3            3          3            3          3            3          0                   0                   0                  0                  42                  0                   78                 120                42                  0                   78                 120                0            0            0          0          0            0          6            6          0            0          0            0          0            0          0            0          15         6                   12           12         3            0            0          3            0          0          6            6          0            0          0            0          0.0         0.0         0.0         3191.07     15019.92     0.0                0.0                0                  0.0          0.0          0.0          0            0.0          15019.92     3566.76      3566.76      0            0            0.0          18210.99     0.0          0.0          0.0          0            650.28       0.0          0            18210.99     0.0          0            1      0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  8.4                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    1               1                  1                  1              0                    1                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   0                9                0               9               3                   9                   0                    3                    2                     0                           0                           0                           0                     0                     0                     2                         0                     69                       105                      0                        0                        0                        0                        69                       105                      9                        15                       9                        15                       0                      0                     0                      0                     0                      0                     0                   0                    3                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     12               15               0               27              0                0.00                    0.00                    0.0                    0.00                   6915.33                 2725.89                 1851.96                3831.06                11129.04                 0.0                      15013.53                13071.3                 0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     150463.470000    1\n",
              "50749   2     23     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         1           1         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          0              0            0              0          0            0          0            0            0          0          0            0          1            1          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         1         3           3         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          0            0          0            0          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            3          0            0          0            0          0            0          0            0          3          0                   0            0          3            0            0          3            0          0          3            3          0            0          0            0          0.0         30.0        0.0         0.00        0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         0.00         0.00         0            0            0.0          30.00        0.0          0.0          0.0          0            0.00         0.0          0            30.00        0.0          0            3      0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    0               0                  0                  0              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   0                0                0               0               0                   0                   3                    0                    0                     0                           0                           0                           0                     0                     0                     0                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     0                0                0               0               0                30.00                   0.96                    30.0                   20.31                  0.00                    0.00                    0.00                   0.00                   0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     63206.880000     1\n",
              "50746   2     25     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         1           1         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          0              0            0              0          0            0          0            0            0          0          0            0          1            1          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         1         3           3         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          0            0          0            0          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            3          0            0          0            0          0            0          0            0          3          0                   0            0          3            0            0          3            0          0          3            3          0            0          0            0          0.0         3.0         0.0         0.00        0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         0.00         0.00         0            0            0.0          3.00         0.0          0.0          0.0          0            0.00         0.0          0            3.00         0.0          0            99     0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    0               0                  0                  0              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   0                0                0               0               0                   0                   3                    0                    0                     0                           0                           0                           0                     0                     0                     2                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     0                0                0               0               0                3.00                    2.88                    3.0                    2.97                   0.00                    0.00                    0.00                   0.00                   0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     54821.340000     1\n",
              "50744   2     23     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         1           1         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          0              0            0              0          0            0          0            0            0          0          0            0          1            1          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         1         3           3         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          0            0          0            0          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            3          0            0          0            0          0            0          0            0          3          0                   0            0          3            0            0          3            0          0          3            3          0            0          0            0          0.0         3.0         0.0         0.00        0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         0.00         0.00         0            0            0.0          3.00         0.0          0.0          0.0          0            0.00         0.0          0            3.00         0.0          0            2      0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    0               0                  0                  0              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   0                0                0               0               0                   0                   2                    0                    0                     0                           0                           0                           0                     0                     0                     1                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     0                0                0               0               0                2.43                    0.00                    3.0                    2.73                   0.00                    0.00                    0.00                   0.00                   0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     117310.979016    1\n",
              "151838  2     46     0.0                 0.0                      0.00                     0.0                      0.0                      0.0                      0.0                      0.0                0.0                      0.00                     0.0                      0.0                      0.0                0.0                      0.0                      0.0                0.0                 0           0         0           0         1           0         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0          0            0          0            0          0              0            0              0          0            0          0            0            0          0          0            0          1            0          0            0          0              0            0          0            0          0            0          0              0            0          1            0            0          1            0          0          0            0          0            0          0           0         0         3           0         0           0         0           0         0            0          0            0                  0                0                  0                0                  0                0          0            0          0            0          0            0          0            0          0            0          0            0          0            0          0                   0                   0                  0                  0                   0                   0                  0                  0                   0                   0                  0                  0            0            0          0          0            0          3            0          0            0          0            0          0            0          0            0          0          0                   0            0          3            0            0          3            0          0          3            0          0            0          0            0          0.0         0.0         0.0         0.00        0.00         0.0                0.0                0                  0.0          0.0          0.0          0            0.0          0.00         0.00         0.00         0            0            0.0          0.00         0.0          0.0          0.0          0            0.00         0.0          0            0.00         0.0          0            99     0                          0                          0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0.0                        0.0                        0.0                        0.0                         0                          0                          0                          0                             0                              0                             0                              0.0                        0                      0.0                   0                      0.0                   0.0                    0.0                   0.0                    0.0                   0                      0                     0.0                 0.0                  0.0                     0.0                    0                      0.0                   0.0                    0.0                   0                      0                     0.0                  0.0                   0.0                       0.0                      0                          0.0                       0.0                       0.0                      0                          0                         0.0                    0.0                   0                   0                    0               0                  0                  0              0                    0                     0      0                0              0                      0                     0                      0                     0                      0                     0                   0                    0                       0                      0                   0                0                0               0               0                   0                   0                    0                    0                     0                           0                           0                           0                     0                     0                     2                         0                     0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                        0                      0                     0                      0                     0                      0                     0                   0                    0                     0                     0                         0                        0                          0                         0                         0                        0                          0                         0                      0                     0                0                0               0               0                0.00                    0.00                    0.0                    0.00                   0.00                    0.00                    0.00                   0.00                   0.00                     0.0                      0.00                    0.0                     0.0                            0.0                            0.0                           0.0                           0.0                            0.0                            0.0                           0.0                           0.0                            0                              0                             0.0                           0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     0.0                      0.0                      0.0                     0.0                     117310.979016    1\n",
              "Length: 76020, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the columns that have the same data repeated throughout the columns.\n",
        "cols_to_drop = data.columns[data.nunique()==1]\n",
        "data.drop(cols_to_drop, axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "E3r1ax7GXFKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Improt smote form the imblearn library to oversample the data since it is imbalanced\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "_ifDRiXnEMYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#oversample the data to create a more balanced data set.\n",
        "\n",
        "smote= SMOTE()\n",
        "\n",
        "smote_data, smote_labels = smote.fit_resample(data, labels)"
      ],
      "metadata": {
        "id": "UuDLTQQeEt9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the difference in the amount of the labels. \n",
        "fig = plt.figure(figsize = (10,8))\n",
        "\n",
        "plt.bar(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "mA0SGoPUGufg",
        "outputId": "90cdfa0f-f52f-44fe-9c10-3deb50410959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ff17af1bbb71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: bar() missing 1 required positional argument: 'height'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data 80/20 to get it ready to go in the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(data, labels, stratify=labels, \\\n",
        "                                                              test_size=0.2, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, \\\n",
        "                                                      random_state=42)"
      ],
      "metadata": {
        "id": "NrqxicwhzrNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the shape of the data\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)\n",
        "print(y_train_full.shape)\n",
        "print(X_valid.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "X_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKvdc0-423lv",
        "outputId": "24439309-e8ec-418d-ebac-8b7655e33824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15204,)\n",
            "(45612,)\n",
            "(15204,)\n",
            "(60816,)\n",
            "(15204, 336)\n",
            "(45612, 336)\n",
            "(15204, 336)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60816, 336)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler  = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid   = scaler.transform(X_valid)"
      ],
      "metadata": {
        "id": "czHuMLW1E-ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n"
      ],
      "metadata": {
        "id": "3jVVNsjhDHg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the model getting it as accurate as possible \n",
        "tf.random.set_seed(42)\n",
        "model = keras.models.Sequential([\n",
        "                                 \n",
        "    keras.layers.Dense(300, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(250, activation=\"relu\"),\n",
        "    keras.layers.Dense(200, activation=\"relu\"),\n",
        "    keras.layers.Dense(150, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "    \n",
        "    \n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MiEh-Bi4u1c",
        "outputId": "2e4da366-3bc0-4e6a-9d33-142db2e15edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 300)               101100    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 250)               75250     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               50200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 150)               30150     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 151       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,851\n",
            "Trainable params: 256,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=.2), loss=\"binary_crossentropy\", metrics=[\"AUC\"])"
      ],
      "metadata": {
        "id": "MLd_6f-m6xzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sat = model.fit(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid))\n",
        "plt.plot(pd.DataFrame(sat.history))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "bv_5PllT8qSt",
        "outputId": "9b60cdcd-e263-458d-b0eb-45886b07e8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1426/1426 [==============================] - 8s 5ms/step - loss: 0.1551 - auc: 0.7061 - val_loss: 0.1615 - val_auc: 0.7500\n",
            "Epoch 2/5\n",
            "1426/1426 [==============================] - 7s 5ms/step - loss: 0.1500 - auc: 0.7440 - val_loss: 0.1747 - val_auc: 0.7720\n",
            "Epoch 3/5\n",
            "1426/1426 [==============================] - 7s 5ms/step - loss: 0.1477 - auc: 0.7599 - val_loss: 0.1527 - val_auc: 0.7799\n",
            "Epoch 4/5\n",
            "1426/1426 [==============================] - 6s 4ms/step - loss: 0.1455 - auc: 0.7738 - val_loss: 0.1493 - val_auc: 0.7868\n",
            "Epoch 5/5\n",
            "1426/1426 [==============================] - 6s 4ms/step - loss: 0.1447 - auc: 0.7785 - val_loss: 0.1600 - val_auc: 0.7879\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trying to get it to over fit by making it more complex\n",
        "tf.random.set_seed(42)\n",
        "model = keras.models.Sequential([\n",
        "                                 \n",
        "    keras.layers.Dense(336, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(275, activation=\"relu\"),\n",
        "    keras.layers.Dense(250, activation=\"relu\"),\n",
        "    keras.layers.Dense(225, activation=\"relu\"),\n",
        "    keras.layers.Dense(200, activation=\"relu\"),\n",
        "    keras.layers.Dense(175, activation=\"relu\"),\n",
        "    keras.layers.Dense(150, activation=\"relu\"),\n",
        "    keras.layers.Dense(125, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(75, activation=\"relu\"),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(25, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "    \n",
        "    \n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pSVdxfVPB-nC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa24cf90-b994-4135-e488-16d32ff8871a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 336)               113232    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 300)               101100    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 275)               82775     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 250)               69000     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 225)               56475     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 200)               45200     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 175)               35175     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 150)               26400     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 125)               18875     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100)               12600     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 75)                7575      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 50)                3800      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 573,508\n",
            "Trainable params: 573,508\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=.15), loss=\"binary_crossentropy\", metrics=[\"AUC\"])"
      ],
      "metadata": {
        "id": "r---J4H_wXIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sat = model.fit(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid))\n",
        "plt.plot(pd.DataFrame(sat.history))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "iGO_AqfOwZJX",
        "outputId": "43ce9597-aa8f-4275-bf82-ac22ab416d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1426/1426 [==============================] - 13s 9ms/step - loss: 0.1587 - auc: 0.6823 - val_loss: 0.1615 - val_auc: 0.7210\n",
            "Epoch 2/5\n",
            "1426/1426 [==============================] - 12s 8ms/step - loss: 0.1536 - auc: 0.7125 - val_loss: 0.1720 - val_auc: 0.7276\n",
            "Epoch 3/5\n",
            "1426/1426 [==============================] - 12s 8ms/step - loss: 0.1514 - auc: 0.7331 - val_loss: 0.1556 - val_auc: 0.7696\n",
            "Epoch 4/5\n",
            "1426/1426 [==============================] - 11s 8ms/step - loss: 0.1498 - auc: 0.7480 - val_loss: 0.1565 - val_auc: 0.7444\n",
            "Epoch 5/5\n",
            "1426/1426 [==============================] - 11s 8ms/step - loss: 0.1481 - auc: 0.7587 - val_loss: 0.1637 - val_auc: 0.7768\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "fSwkGhrG4bW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use regularization with these models\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "model2 = keras.models.Sequential([\n",
        "        keras.layers.Dense(9, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "        keras.layers.Dropout(0.3), #drop 30% of the nuerons randomly\n",
        "        keras.layers.Dense(9, activation=\"relu\"),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),#output layer\n",
        " ]) \n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfCrz_W93UiU",
        "outputId": "e9b8cf2a-42ab-45e3-c0b6-95d1ecbde51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 9)                 3033      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 90        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,133\n",
            "Trainable params: 3,133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
        "              loss=\"binary_crossentropy\", \n",
        "              metrics=[\"AUC\"])\n"
      ],
      "metadata": {
        "id": "UkBRJ_BV5lsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_me= model2.fit(X_train, y_train, epochs=500,\\\n",
        "                    batch_size= 1000, validation_data=(X_valid, y_valid))\n",
        "\n",
        "\n",
        "plt.plot(pd.DataFrame(show_me.history))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m97IdC_v5ecA",
        "outputId": "61a9511b-3c90-4cf9-ccb5-2629a429a015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "46/46 [==============================] - 2s 11ms/step - loss: 0.4027 - auc: 0.5376 - val_loss: 0.2138 - val_auc: 0.6406\n",
            "Epoch 2/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1852 - auc: 0.5798 - val_loss: 0.1660 - val_auc: 0.6607\n",
            "Epoch 3/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1693 - auc: 0.6228 - val_loss: 0.1637 - val_auc: 0.6762\n",
            "Epoch 4/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1676 - auc: 0.6329 - val_loss: 0.1624 - val_auc: 0.6887\n",
            "Epoch 5/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1671 - auc: 0.6366 - val_loss: 0.1616 - val_auc: 0.6968\n",
            "Epoch 6/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1644 - auc: 0.6555 - val_loss: 0.1607 - val_auc: 0.7037\n",
            "Epoch 7/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1624 - auc: 0.6681 - val_loss: 0.1602 - val_auc: 0.7061\n",
            "Epoch 8/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1631 - auc: 0.6644 - val_loss: 0.1598 - val_auc: 0.7106\n",
            "Epoch 9/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1624 - auc: 0.6687 - val_loss: 0.1593 - val_auc: 0.7184\n",
            "Epoch 10/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1599 - auc: 0.6845 - val_loss: 0.1590 - val_auc: 0.7226\n",
            "Epoch 11/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1589 - auc: 0.6900 - val_loss: 0.1587 - val_auc: 0.7310\n",
            "Epoch 12/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1589 - auc: 0.6912 - val_loss: 0.1582 - val_auc: 0.7339\n",
            "Epoch 13/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1581 - auc: 0.6951 - val_loss: 0.1584 - val_auc: 0.7426\n",
            "Epoch 14/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1568 - auc: 0.7036 - val_loss: 0.1580 - val_auc: 0.7468\n",
            "Epoch 15/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.7054 - val_loss: 0.1573 - val_auc: 0.7510\n",
            "Epoch 16/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.7129 - val_loss: 0.1572 - val_auc: 0.7549\n",
            "Epoch 17/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.7135 - val_loss: 0.1577 - val_auc: 0.7612\n",
            "Epoch 18/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1537 - auc: 0.7226 - val_loss: 0.1570 - val_auc: 0.7626\n",
            "Epoch 19/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1545 - auc: 0.7173 - val_loss: 0.1571 - val_auc: 0.7662\n",
            "Epoch 20/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1530 - auc: 0.7270 - val_loss: 0.1565 - val_auc: 0.7686\n",
            "Epoch 21/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1531 - auc: 0.7273 - val_loss: 0.1581 - val_auc: 0.7701\n",
            "Epoch 22/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1522 - auc: 0.7333 - val_loss: 0.1565 - val_auc: 0.7734\n",
            "Epoch 23/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1514 - auc: 0.7386 - val_loss: 0.1573 - val_auc: 0.7731\n",
            "Epoch 24/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1515 - auc: 0.7385 - val_loss: 0.1565 - val_auc: 0.7776\n",
            "Epoch 25/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1508 - auc: 0.7440 - val_loss: 0.1556 - val_auc: 0.7768\n",
            "Epoch 26/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1508 - auc: 0.7429 - val_loss: 0.1554 - val_auc: 0.7770\n",
            "Epoch 27/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1498 - auc: 0.7504 - val_loss: 0.1552 - val_auc: 0.7806\n",
            "Epoch 28/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1502 - auc: 0.7465 - val_loss: 0.1553 - val_auc: 0.7797\n",
            "Epoch 29/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1489 - auc: 0.7565 - val_loss: 0.1558 - val_auc: 0.7822\n",
            "Epoch 30/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1487 - auc: 0.7559 - val_loss: 0.1546 - val_auc: 0.7822\n",
            "Epoch 31/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1489 - auc: 0.7552 - val_loss: 0.1548 - val_auc: 0.7806\n",
            "Epoch 32/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1482 - auc: 0.7609 - val_loss: 0.1535 - val_auc: 0.7824\n",
            "Epoch 33/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1475 - auc: 0.7631 - val_loss: 0.1550 - val_auc: 0.7811\n",
            "Epoch 34/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1475 - auc: 0.7634 - val_loss: 0.1543 - val_auc: 0.7836\n",
            "Epoch 35/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1474 - auc: 0.7644 - val_loss: 0.1548 - val_auc: 0.7839\n",
            "Epoch 36/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1465 - auc: 0.7694 - val_loss: 0.1517 - val_auc: 0.7854\n",
            "Epoch 37/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1469 - auc: 0.7676 - val_loss: 0.1520 - val_auc: 0.7859\n",
            "Epoch 38/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1466 - auc: 0.7695 - val_loss: 0.1522 - val_auc: 0.7871\n",
            "Epoch 39/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1460 - auc: 0.7727 - val_loss: 0.1515 - val_auc: 0.7903\n",
            "Epoch 40/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1456 - auc: 0.7751 - val_loss: 0.1509 - val_auc: 0.7859\n",
            "Epoch 41/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1454 - auc: 0.7762 - val_loss: 0.1507 - val_auc: 0.7882\n",
            "Epoch 42/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1458 - auc: 0.7733 - val_loss: 0.1518 - val_auc: 0.7906\n",
            "Epoch 43/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1451 - auc: 0.7790 - val_loss: 0.1508 - val_auc: 0.7917\n",
            "Epoch 44/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1448 - auc: 0.7800 - val_loss: 0.1502 - val_auc: 0.7916\n",
            "Epoch 45/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1446 - auc: 0.7812 - val_loss: 0.1497 - val_auc: 0.7935\n",
            "Epoch 46/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1445 - auc: 0.7821 - val_loss: 0.1497 - val_auc: 0.7940\n",
            "Epoch 47/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1440 - auc: 0.7846 - val_loss: 0.1500 - val_auc: 0.7970\n",
            "Epoch 48/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1437 - auc: 0.7861 - val_loss: 0.1502 - val_auc: 0.7967\n",
            "Epoch 49/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1437 - auc: 0.7851 - val_loss: 0.1493 - val_auc: 0.7971\n",
            "Epoch 50/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1438 - auc: 0.7854 - val_loss: 0.1493 - val_auc: 0.7990\n",
            "Epoch 51/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1440 - auc: 0.7843 - val_loss: 0.1497 - val_auc: 0.8005\n",
            "Epoch 52/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1439 - auc: 0.7848 - val_loss: 0.1500 - val_auc: 0.8010\n",
            "Epoch 53/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1435 - auc: 0.7871 - val_loss: 0.1492 - val_auc: 0.8014\n",
            "Epoch 54/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1429 - auc: 0.7903 - val_loss: 0.1501 - val_auc: 0.8015\n",
            "Epoch 55/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1433 - auc: 0.7883 - val_loss: 0.1490 - val_auc: 0.8014\n",
            "Epoch 56/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1428 - auc: 0.7908 - val_loss: 0.1483 - val_auc: 0.8010\n",
            "Epoch 57/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1423 - auc: 0.7928 - val_loss: 0.1493 - val_auc: 0.8027\n",
            "Epoch 58/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1427 - auc: 0.7911 - val_loss: 0.1496 - val_auc: 0.8019\n",
            "Epoch 59/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1424 - auc: 0.7934 - val_loss: 0.1484 - val_auc: 0.8035\n",
            "Epoch 60/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1424 - auc: 0.7923 - val_loss: 0.1485 - val_auc: 0.8034\n",
            "Epoch 61/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1420 - auc: 0.7950 - val_loss: 0.1482 - val_auc: 0.8030\n",
            "Epoch 62/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1416 - auc: 0.7975 - val_loss: 0.1480 - val_auc: 0.8046\n",
            "Epoch 63/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1418 - auc: 0.7962 - val_loss: 0.1475 - val_auc: 0.8042\n",
            "Epoch 64/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1420 - auc: 0.7947 - val_loss: 0.1481 - val_auc: 0.8039\n",
            "Epoch 65/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1417 - auc: 0.7965 - val_loss: 0.1486 - val_auc: 0.8057\n",
            "Epoch 66/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1416 - auc: 0.7978 - val_loss: 0.1477 - val_auc: 0.8043\n",
            "Epoch 67/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1413 - auc: 0.7990 - val_loss: 0.1480 - val_auc: 0.8045\n",
            "Epoch 68/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1412 - auc: 0.7994 - val_loss: 0.1485 - val_auc: 0.8053\n",
            "Epoch 69/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1412 - auc: 0.7993 - val_loss: 0.1479 - val_auc: 0.8054\n",
            "Epoch 70/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1413 - auc: 0.7980 - val_loss: 0.1489 - val_auc: 0.8051\n",
            "Epoch 71/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1406 - auc: 0.8024 - val_loss: 0.1491 - val_auc: 0.8066\n",
            "Epoch 72/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1411 - auc: 0.7999 - val_loss: 0.1479 - val_auc: 0.8075\n",
            "Epoch 73/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1409 - auc: 0.8014 - val_loss: 0.1484 - val_auc: 0.8077\n",
            "Epoch 74/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1404 - auc: 0.8038 - val_loss: 0.1480 - val_auc: 0.8068\n",
            "Epoch 75/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1408 - auc: 0.8005 - val_loss: 0.1469 - val_auc: 0.8062\n",
            "Epoch 76/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1409 - auc: 0.8008 - val_loss: 0.1473 - val_auc: 0.8072\n",
            "Epoch 77/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1406 - auc: 0.8019 - val_loss: 0.1479 - val_auc: 0.8071\n",
            "Epoch 78/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1406 - auc: 0.8017 - val_loss: 0.1471 - val_auc: 0.8078\n",
            "Epoch 79/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1402 - auc: 0.8046 - val_loss: 0.1467 - val_auc: 0.8069\n",
            "Epoch 80/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1403 - auc: 0.8031 - val_loss: 0.1466 - val_auc: 0.8083\n",
            "Epoch 81/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1402 - auc: 0.8046 - val_loss: 0.1473 - val_auc: 0.8074\n",
            "Epoch 82/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1399 - auc: 0.8058 - val_loss: 0.1469 - val_auc: 0.8077\n",
            "Epoch 83/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1403 - auc: 0.8047 - val_loss: 0.1467 - val_auc: 0.8092\n",
            "Epoch 84/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1401 - auc: 0.8035 - val_loss: 0.1474 - val_auc: 0.8087\n",
            "Epoch 85/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1403 - auc: 0.8028 - val_loss: 0.1473 - val_auc: 0.8097\n",
            "Epoch 86/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1405 - auc: 0.8019 - val_loss: 0.1480 - val_auc: 0.8093\n",
            "Epoch 87/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1403 - auc: 0.8033 - val_loss: 0.1491 - val_auc: 0.8092\n",
            "Epoch 88/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1402 - auc: 0.8038 - val_loss: 0.1483 - val_auc: 0.8093\n",
            "Epoch 89/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1400 - auc: 0.8048 - val_loss: 0.1482 - val_auc: 0.8101\n",
            "Epoch 90/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1398 - auc: 0.8050 - val_loss: 0.1480 - val_auc: 0.8112\n",
            "Epoch 91/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1399 - auc: 0.8056 - val_loss: 0.1466 - val_auc: 0.8089\n",
            "Epoch 92/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1395 - auc: 0.8071 - val_loss: 0.1474 - val_auc: 0.8105\n",
            "Epoch 93/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1395 - auc: 0.8076 - val_loss: 0.1477 - val_auc: 0.8120\n",
            "Epoch 94/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1391 - auc: 0.8110 - val_loss: 0.1472 - val_auc: 0.8097\n",
            "Epoch 95/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1397 - auc: 0.8063 - val_loss: 0.1475 - val_auc: 0.8103\n",
            "Epoch 96/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1395 - auc: 0.8087 - val_loss: 0.1471 - val_auc: 0.8097\n",
            "Epoch 97/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1394 - auc: 0.8070 - val_loss: 0.1471 - val_auc: 0.8110\n",
            "Epoch 98/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1390 - auc: 0.8088 - val_loss: 0.1470 - val_auc: 0.8105\n",
            "Epoch 99/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1389 - auc: 0.8110 - val_loss: 0.1477 - val_auc: 0.8123\n",
            "Epoch 100/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1394 - auc: 0.8088 - val_loss: 0.1463 - val_auc: 0.8094\n",
            "Epoch 101/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1395 - auc: 0.8079 - val_loss: 0.1465 - val_auc: 0.8122\n",
            "Epoch 102/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1389 - auc: 0.8110 - val_loss: 0.1474 - val_auc: 0.8114\n",
            "Epoch 103/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1392 - auc: 0.8088 - val_loss: 0.1471 - val_auc: 0.8115\n",
            "Epoch 104/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1391 - auc: 0.8100 - val_loss: 0.1464 - val_auc: 0.8098\n",
            "Epoch 105/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1389 - auc: 0.8109 - val_loss: 0.1483 - val_auc: 0.8124\n",
            "Epoch 106/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1388 - auc: 0.8107 - val_loss: 0.1463 - val_auc: 0.8114\n",
            "Epoch 107/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1388 - auc: 0.8092 - val_loss: 0.1474 - val_auc: 0.8107\n",
            "Epoch 108/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1386 - auc: 0.8122 - val_loss: 0.1467 - val_auc: 0.8107\n",
            "Epoch 109/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1383 - auc: 0.8133 - val_loss: 0.1465 - val_auc: 0.8129\n",
            "Epoch 110/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1386 - auc: 0.8121 - val_loss: 0.1520 - val_auc: 0.8126\n",
            "Epoch 111/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1389 - auc: 0.8091 - val_loss: 0.1466 - val_auc: 0.8124\n",
            "Epoch 112/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1387 - auc: 0.8113 - val_loss: 0.1465 - val_auc: 0.8092\n",
            "Epoch 113/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1382 - auc: 0.8131 - val_loss: 0.1460 - val_auc: 0.8116\n",
            "Epoch 114/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1385 - auc: 0.8128 - val_loss: 0.1476 - val_auc: 0.8142\n",
            "Epoch 115/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1386 - auc: 0.8117 - val_loss: 0.1477 - val_auc: 0.8137\n",
            "Epoch 116/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1386 - auc: 0.8112 - val_loss: 0.1464 - val_auc: 0.8123\n",
            "Epoch 117/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1389 - auc: 0.8103 - val_loss: 0.1479 - val_auc: 0.8147\n",
            "Epoch 118/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1385 - auc: 0.8123 - val_loss: 0.1479 - val_auc: 0.8136\n",
            "Epoch 119/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1382 - auc: 0.8138 - val_loss: 0.1476 - val_auc: 0.8110\n",
            "Epoch 120/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1382 - auc: 0.8140 - val_loss: 0.1473 - val_auc: 0.8126\n",
            "Epoch 121/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1387 - auc: 0.8100 - val_loss: 0.1471 - val_auc: 0.8126\n",
            "Epoch 122/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1380 - auc: 0.8146 - val_loss: 0.1477 - val_auc: 0.8114\n",
            "Epoch 123/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1382 - auc: 0.8142 - val_loss: 0.1467 - val_auc: 0.8115\n",
            "Epoch 124/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1381 - auc: 0.8139 - val_loss: 0.1471 - val_auc: 0.8126\n",
            "Epoch 125/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1383 - auc: 0.8129 - val_loss: 0.1466 - val_auc: 0.8128\n",
            "Epoch 126/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1381 - auc: 0.8135 - val_loss: 0.1465 - val_auc: 0.8125\n",
            "Epoch 127/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1388 - auc: 0.8102 - val_loss: 0.1480 - val_auc: 0.8143\n",
            "Epoch 128/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1381 - auc: 0.8141 - val_loss: 0.1468 - val_auc: 0.8129\n",
            "Epoch 129/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1377 - auc: 0.8160 - val_loss: 0.1467 - val_auc: 0.8133\n",
            "Epoch 130/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1383 - auc: 0.8123 - val_loss: 0.1469 - val_auc: 0.8125\n",
            "Epoch 131/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1382 - auc: 0.8144 - val_loss: 0.1476 - val_auc: 0.8132\n",
            "Epoch 132/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1377 - auc: 0.8166 - val_loss: 0.1468 - val_auc: 0.8124\n",
            "Epoch 133/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1384 - auc: 0.8125 - val_loss: 0.1463 - val_auc: 0.8128\n",
            "Epoch 134/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1383 - auc: 0.8127 - val_loss: 0.1479 - val_auc: 0.8131\n",
            "Epoch 135/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1379 - auc: 0.8153 - val_loss: 0.1480 - val_auc: 0.8126\n",
            "Epoch 136/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1379 - auc: 0.8150 - val_loss: 0.1470 - val_auc: 0.8119\n",
            "Epoch 137/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1378 - auc: 0.8149 - val_loss: 0.1469 - val_auc: 0.8148\n",
            "Epoch 138/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1378 - auc: 0.8150 - val_loss: 0.1470 - val_auc: 0.8110\n",
            "Epoch 139/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1378 - auc: 0.8155 - val_loss: 0.1489 - val_auc: 0.8143\n",
            "Epoch 140/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1378 - auc: 0.8156 - val_loss: 0.1485 - val_auc: 0.8121\n",
            "Epoch 141/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1382 - auc: 0.8134 - val_loss: 0.1470 - val_auc: 0.8116\n",
            "Epoch 142/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1377 - auc: 0.8169 - val_loss: 0.1481 - val_auc: 0.8141\n",
            "Epoch 143/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1381 - auc: 0.8139 - val_loss: 0.1466 - val_auc: 0.8128\n",
            "Epoch 144/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1375 - auc: 0.8172 - val_loss: 0.1470 - val_auc: 0.8131\n",
            "Epoch 145/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1377 - auc: 0.8160 - val_loss: 0.1482 - val_auc: 0.8132\n",
            "Epoch 146/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1379 - auc: 0.8151 - val_loss: 0.1465 - val_auc: 0.8116\n",
            "Epoch 147/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1376 - auc: 0.8156 - val_loss: 0.1471 - val_auc: 0.8126\n",
            "Epoch 148/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1373 - auc: 0.8191 - val_loss: 0.1465 - val_auc: 0.8134\n",
            "Epoch 149/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1376 - auc: 0.8171 - val_loss: 0.1471 - val_auc: 0.8135\n",
            "Epoch 150/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1378 - auc: 0.8154 - val_loss: 0.1488 - val_auc: 0.8133\n",
            "Epoch 151/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1374 - auc: 0.8180 - val_loss: 0.1473 - val_auc: 0.8148\n",
            "Epoch 152/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1381 - auc: 0.8149 - val_loss: 0.1479 - val_auc: 0.8134\n",
            "Epoch 153/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1378 - auc: 0.8146 - val_loss: 0.1470 - val_auc: 0.8125\n",
            "Epoch 154/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1378 - auc: 0.8147 - val_loss: 0.1475 - val_auc: 0.8129\n",
            "Epoch 155/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1375 - auc: 0.8172 - val_loss: 0.1470 - val_auc: 0.8130\n",
            "Epoch 156/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1378 - auc: 0.8161 - val_loss: 0.1493 - val_auc: 0.8126\n",
            "Epoch 157/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1376 - auc: 0.8171 - val_loss: 0.1474 - val_auc: 0.8141\n",
            "Epoch 158/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1374 - auc: 0.8181 - val_loss: 0.1483 - val_auc: 0.8118\n",
            "Epoch 159/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1375 - auc: 0.8167 - val_loss: 0.1485 - val_auc: 0.8125\n",
            "Epoch 160/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1374 - auc: 0.8177 - val_loss: 0.1478 - val_auc: 0.8133\n",
            "Epoch 161/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1371 - auc: 0.8189 - val_loss: 0.1490 - val_auc: 0.8131\n",
            "Epoch 162/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1375 - auc: 0.8160 - val_loss: 0.1485 - val_auc: 0.8130\n",
            "Epoch 163/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1372 - auc: 0.8188 - val_loss: 0.1480 - val_auc: 0.8118\n",
            "Epoch 164/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1375 - auc: 0.8168 - val_loss: 0.1485 - val_auc: 0.8119\n",
            "Epoch 165/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1371 - auc: 0.8190 - val_loss: 0.1470 - val_auc: 0.8118\n",
            "Epoch 166/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1370 - auc: 0.8200 - val_loss: 0.1470 - val_auc: 0.8133\n",
            "Epoch 167/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1375 - auc: 0.8172 - val_loss: 0.1486 - val_auc: 0.8130\n",
            "Epoch 168/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1376 - auc: 0.8166 - val_loss: 0.1473 - val_auc: 0.8129\n",
            "Epoch 169/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1372 - auc: 0.8180 - val_loss: 0.1479 - val_auc: 0.8105\n",
            "Epoch 170/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1365 - auc: 0.8221 - val_loss: 0.1489 - val_auc: 0.8133\n",
            "Epoch 171/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1372 - auc: 0.8185 - val_loss: 0.1480 - val_auc: 0.8131\n",
            "Epoch 172/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1371 - auc: 0.8203 - val_loss: 0.1476 - val_auc: 0.8145\n",
            "Epoch 173/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1374 - auc: 0.8171 - val_loss: 0.1481 - val_auc: 0.8122\n",
            "Epoch 174/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1370 - auc: 0.8196 - val_loss: 0.1477 - val_auc: 0.8124\n",
            "Epoch 175/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1371 - auc: 0.8200 - val_loss: 0.1482 - val_auc: 0.8114\n",
            "Epoch 176/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1372 - auc: 0.8191 - val_loss: 0.1488 - val_auc: 0.8128\n",
            "Epoch 177/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1369 - auc: 0.8209 - val_loss: 0.1470 - val_auc: 0.8147\n",
            "Epoch 178/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1371 - auc: 0.8185 - val_loss: 0.1495 - val_auc: 0.8136\n",
            "Epoch 179/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1371 - auc: 0.8194 - val_loss: 0.1480 - val_auc: 0.8113\n",
            "Epoch 180/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1369 - auc: 0.8211 - val_loss: 0.1479 - val_auc: 0.8107\n",
            "Epoch 181/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1365 - auc: 0.8214 - val_loss: 0.1496 - val_auc: 0.8137\n",
            "Epoch 182/500\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1370 - auc: 0.8210 - val_loss: 0.1475 - val_auc: 0.8125\n",
            "Epoch 183/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1373 - auc: 0.8181 - val_loss: 0.1498 - val_auc: 0.8140\n",
            "Epoch 184/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1368 - auc: 0.8207 - val_loss: 0.1480 - val_auc: 0.8104\n",
            "Epoch 185/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1368 - auc: 0.8209 - val_loss: 0.1480 - val_auc: 0.8122\n",
            "Epoch 186/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1371 - auc: 0.8194 - val_loss: 0.1480 - val_auc: 0.8151\n",
            "Epoch 187/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1366 - auc: 0.8224 - val_loss: 0.1469 - val_auc: 0.8143\n",
            "Epoch 188/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1366 - auc: 0.8226 - val_loss: 0.1492 - val_auc: 0.8114\n",
            "Epoch 189/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1368 - auc: 0.8209 - val_loss: 0.1475 - val_auc: 0.8119\n",
            "Epoch 190/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1369 - auc: 0.8216 - val_loss: 0.1477 - val_auc: 0.8128\n",
            "Epoch 191/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1364 - auc: 0.8234 - val_loss: 0.1480 - val_auc: 0.8143\n",
            "Epoch 192/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1371 - auc: 0.8205 - val_loss: 0.1486 - val_auc: 0.8125\n",
            "Epoch 193/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1369 - auc: 0.8210 - val_loss: 0.1482 - val_auc: 0.8127\n",
            "Epoch 194/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1367 - auc: 0.8216 - val_loss: 0.1491 - val_auc: 0.8117\n",
            "Epoch 195/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1367 - auc: 0.8208 - val_loss: 0.1485 - val_auc: 0.8136\n",
            "Epoch 196/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1369 - auc: 0.8205 - val_loss: 0.1482 - val_auc: 0.8137\n",
            "Epoch 197/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1371 - auc: 0.8207 - val_loss: 0.1493 - val_auc: 0.8134\n",
            "Epoch 198/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1365 - auc: 0.8216 - val_loss: 0.1483 - val_auc: 0.8130\n",
            "Epoch 199/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1370 - auc: 0.8203 - val_loss: 0.1477 - val_auc: 0.8116\n",
            "Epoch 200/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1374 - auc: 0.8175 - val_loss: 0.1498 - val_auc: 0.8144\n",
            "Epoch 201/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1362 - auc: 0.8236 - val_loss: 0.1477 - val_auc: 0.8142\n",
            "Epoch 202/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1363 - auc: 0.8237 - val_loss: 0.1477 - val_auc: 0.8114\n",
            "Epoch 203/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1371 - auc: 0.8182 - val_loss: 0.1489 - val_auc: 0.8137\n",
            "Epoch 204/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1369 - auc: 0.8215 - val_loss: 0.1486 - val_auc: 0.8120\n",
            "Epoch 205/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1371 - auc: 0.8202 - val_loss: 0.1494 - val_auc: 0.8128\n",
            "Epoch 206/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1370 - auc: 0.8206 - val_loss: 0.1489 - val_auc: 0.8128\n",
            "Epoch 207/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1366 - auc: 0.8217 - val_loss: 0.1480 - val_auc: 0.8129\n",
            "Epoch 208/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1367 - auc: 0.8227 - val_loss: 0.1479 - val_auc: 0.8149\n",
            "Epoch 209/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1366 - auc: 0.8216 - val_loss: 0.1493 - val_auc: 0.8139\n",
            "Epoch 210/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1365 - auc: 0.8221 - val_loss: 0.1492 - val_auc: 0.8136\n",
            "Epoch 211/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1369 - auc: 0.8210 - val_loss: 0.1511 - val_auc: 0.8125\n",
            "Epoch 212/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8248 - val_loss: 0.1491 - val_auc: 0.8130\n",
            "Epoch 213/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1361 - auc: 0.8257 - val_loss: 0.1493 - val_auc: 0.8131\n",
            "Epoch 214/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1366 - auc: 0.8227 - val_loss: 0.1479 - val_auc: 0.8121\n",
            "Epoch 215/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8240 - val_loss: 0.1493 - val_auc: 0.8132\n",
            "Epoch 216/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1362 - auc: 0.8243 - val_loss: 0.1493 - val_auc: 0.8117\n",
            "Epoch 217/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1364 - auc: 0.8237 - val_loss: 0.1493 - val_auc: 0.8123\n",
            "Epoch 218/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1368 - auc: 0.8211 - val_loss: 0.1496 - val_auc: 0.8130\n",
            "Epoch 219/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1363 - auc: 0.8229 - val_loss: 0.1489 - val_auc: 0.8140\n",
            "Epoch 220/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1364 - auc: 0.8234 - val_loss: 0.1495 - val_auc: 0.8125\n",
            "Epoch 221/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8248 - val_loss: 0.1490 - val_auc: 0.8147\n",
            "Epoch 222/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1368 - auc: 0.8208 - val_loss: 0.1490 - val_auc: 0.8131\n",
            "Epoch 223/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8250 - val_loss: 0.1497 - val_auc: 0.8122\n",
            "Epoch 224/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1365 - auc: 0.8231 - val_loss: 0.1498 - val_auc: 0.8121\n",
            "Epoch 225/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1366 - auc: 0.8221 - val_loss: 0.1501 - val_auc: 0.8118\n",
            "Epoch 226/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8253 - val_loss: 0.1501 - val_auc: 0.8136\n",
            "Epoch 227/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1366 - auc: 0.8218 - val_loss: 0.1487 - val_auc: 0.8148\n",
            "Epoch 228/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1362 - auc: 0.8241 - val_loss: 0.1509 - val_auc: 0.8108\n",
            "Epoch 229/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1361 - auc: 0.8245 - val_loss: 0.1493 - val_auc: 0.8111\n",
            "Epoch 230/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1362 - auc: 0.8243 - val_loss: 0.1503 - val_auc: 0.8132\n",
            "Epoch 231/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1363 - auc: 0.8228 - val_loss: 0.1498 - val_auc: 0.8125\n",
            "Epoch 232/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1362 - auc: 0.8242 - val_loss: 0.1498 - val_auc: 0.8120\n",
            "Epoch 233/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8263 - val_loss: 0.1499 - val_auc: 0.8116\n",
            "Epoch 234/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1363 - auc: 0.8233 - val_loss: 0.1495 - val_auc: 0.8123\n",
            "Epoch 235/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1362 - auc: 0.8238 - val_loss: 0.1493 - val_auc: 0.8130\n",
            "Epoch 236/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1368 - auc: 0.8222 - val_loss: 0.1506 - val_auc: 0.8126\n",
            "Epoch 237/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8238 - val_loss: 0.1492 - val_auc: 0.8114\n",
            "Epoch 238/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8259 - val_loss: 0.1489 - val_auc: 0.8133\n",
            "Epoch 239/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8252 - val_loss: 0.1502 - val_auc: 0.8111\n",
            "Epoch 240/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1360 - auc: 0.8253 - val_loss: 0.1490 - val_auc: 0.8136\n",
            "Epoch 241/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8257 - val_loss: 0.1491 - val_auc: 0.8133\n",
            "Epoch 242/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1362 - auc: 0.8232 - val_loss: 0.1512 - val_auc: 0.8131\n",
            "Epoch 243/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1366 - auc: 0.8229 - val_loss: 0.1497 - val_auc: 0.8120\n",
            "Epoch 244/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8258 - val_loss: 0.1502 - val_auc: 0.8123\n",
            "Epoch 245/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1365 - auc: 0.8227 - val_loss: 0.1491 - val_auc: 0.8126\n",
            "Epoch 246/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1359 - auc: 0.8248 - val_loss: 0.1491 - val_auc: 0.8118\n",
            "Epoch 247/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1364 - auc: 0.8221 - val_loss: 0.1495 - val_auc: 0.8113\n",
            "Epoch 248/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8260 - val_loss: 0.1503 - val_auc: 0.8125\n",
            "Epoch 249/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8265 - val_loss: 0.1515 - val_auc: 0.8122\n",
            "Epoch 250/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1363 - auc: 0.8237 - val_loss: 0.1502 - val_auc: 0.8119\n",
            "Epoch 251/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1369 - auc: 0.8199 - val_loss: 0.1501 - val_auc: 0.8117\n",
            "Epoch 252/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1360 - auc: 0.8257 - val_loss: 0.1503 - val_auc: 0.8119\n",
            "Epoch 253/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1364 - auc: 0.8238 - val_loss: 0.1488 - val_auc: 0.8121\n",
            "Epoch 254/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1365 - auc: 0.8226 - val_loss: 0.1495 - val_auc: 0.8125\n",
            "Epoch 255/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8261 - val_loss: 0.1498 - val_auc: 0.8124\n",
            "Epoch 256/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8244 - val_loss: 0.1502 - val_auc: 0.8097\n",
            "Epoch 257/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1359 - auc: 0.8254 - val_loss: 0.1508 - val_auc: 0.8129\n",
            "Epoch 258/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1357 - auc: 0.8274 - val_loss: 0.1509 - val_auc: 0.8126\n",
            "Epoch 259/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1358 - auc: 0.8251 - val_loss: 0.1496 - val_auc: 0.8120\n",
            "Epoch 260/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1359 - auc: 0.8256 - val_loss: 0.1490 - val_auc: 0.8112\n",
            "Epoch 261/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1358 - auc: 0.8256 - val_loss: 0.1494 - val_auc: 0.8125\n",
            "Epoch 262/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8259 - val_loss: 0.1509 - val_auc: 0.8137\n",
            "Epoch 263/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1365 - auc: 0.8221 - val_loss: 0.1506 - val_auc: 0.8111\n",
            "Epoch 264/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8256 - val_loss: 0.1499 - val_auc: 0.8121\n",
            "Epoch 265/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8248 - val_loss: 0.1503 - val_auc: 0.8114\n",
            "Epoch 266/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1361 - auc: 0.8259 - val_loss: 0.1506 - val_auc: 0.8116\n",
            "Epoch 267/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1363 - auc: 0.8242 - val_loss: 0.1509 - val_auc: 0.8129\n",
            "Epoch 268/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8271 - val_loss: 0.1511 - val_auc: 0.8119\n",
            "Epoch 269/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1356 - auc: 0.8268 - val_loss: 0.1499 - val_auc: 0.8119\n",
            "Epoch 270/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1363 - auc: 0.8238 - val_loss: 0.1501 - val_auc: 0.8120\n",
            "Epoch 271/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8244 - val_loss: 0.1500 - val_auc: 0.8104\n",
            "Epoch 272/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1360 - auc: 0.8242 - val_loss: 0.1502 - val_auc: 0.8129\n",
            "Epoch 273/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8251 - val_loss: 0.1494 - val_auc: 0.8125\n",
            "Epoch 274/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1361 - auc: 0.8253 - val_loss: 0.1511 - val_auc: 0.8127\n",
            "Epoch 275/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1360 - auc: 0.8259 - val_loss: 0.1503 - val_auc: 0.8121\n",
            "Epoch 276/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8278 - val_loss: 0.1508 - val_auc: 0.8124\n",
            "Epoch 277/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1362 - auc: 0.8245 - val_loss: 0.1534 - val_auc: 0.8126\n",
            "Epoch 278/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1357 - auc: 0.8265 - val_loss: 0.1515 - val_auc: 0.8131\n",
            "Epoch 279/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8273 - val_loss: 0.1508 - val_auc: 0.8127\n",
            "Epoch 280/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1361 - auc: 0.8248 - val_loss: 0.1494 - val_auc: 0.8135\n",
            "Epoch 281/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8255 - val_loss: 0.1515 - val_auc: 0.8131\n",
            "Epoch 282/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1361 - auc: 0.8255 - val_loss: 0.1508 - val_auc: 0.8124\n",
            "Epoch 283/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1362 - auc: 0.8249 - val_loss: 0.1511 - val_auc: 0.8132\n",
            "Epoch 284/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1359 - auc: 0.8258 - val_loss: 0.1495 - val_auc: 0.8135\n",
            "Epoch 285/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1358 - auc: 0.8268 - val_loss: 0.1510 - val_auc: 0.8126\n",
            "Epoch 286/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1364 - auc: 0.8235 - val_loss: 0.1496 - val_auc: 0.8127\n",
            "Epoch 287/500\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1362 - auc: 0.8238 - val_loss: 0.1517 - val_auc: 0.8125\n",
            "Epoch 288/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1352 - auc: 0.8284 - val_loss: 0.1513 - val_auc: 0.8125\n",
            "Epoch 289/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1361 - auc: 0.8244 - val_loss: 0.1496 - val_auc: 0.8143\n",
            "Epoch 290/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1362 - auc: 0.8240 - val_loss: 0.1505 - val_auc: 0.8111\n",
            "Epoch 291/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8280 - val_loss: 0.1504 - val_auc: 0.8138\n",
            "Epoch 292/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8286 - val_loss: 0.1504 - val_auc: 0.8141\n",
            "Epoch 293/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1364 - auc: 0.8229 - val_loss: 0.1510 - val_auc: 0.8138\n",
            "Epoch 294/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1353 - auc: 0.8276 - val_loss: 0.1511 - val_auc: 0.8127\n",
            "Epoch 295/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8256 - val_loss: 0.1508 - val_auc: 0.8128\n",
            "Epoch 296/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1355 - auc: 0.8275 - val_loss: 0.1507 - val_auc: 0.8121\n",
            "Epoch 297/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1362 - auc: 0.8229 - val_loss: 0.1522 - val_auc: 0.8123\n",
            "Epoch 298/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1357 - auc: 0.8258 - val_loss: 0.1498 - val_auc: 0.8125\n",
            "Epoch 299/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8248 - val_loss: 0.1489 - val_auc: 0.8132\n",
            "Epoch 300/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1359 - auc: 0.8249 - val_loss: 0.1503 - val_auc: 0.8130\n",
            "Epoch 301/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8276 - val_loss: 0.1503 - val_auc: 0.8135\n",
            "Epoch 302/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8281 - val_loss: 0.1511 - val_auc: 0.8125\n",
            "Epoch 303/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8246 - val_loss: 0.1495 - val_auc: 0.8130\n",
            "Epoch 304/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8273 - val_loss: 0.1515 - val_auc: 0.8128\n",
            "Epoch 305/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8272 - val_loss: 0.1510 - val_auc: 0.8122\n",
            "Epoch 306/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8286 - val_loss: 0.1508 - val_auc: 0.8114\n",
            "Epoch 307/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1352 - auc: 0.8284 - val_loss: 0.1503 - val_auc: 0.8130\n",
            "Epoch 308/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8281 - val_loss: 0.1511 - val_auc: 0.8112\n",
            "Epoch 309/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8266 - val_loss: 0.1502 - val_auc: 0.8123\n",
            "Epoch 310/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8253 - val_loss: 0.1500 - val_auc: 0.8116\n",
            "Epoch 311/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1355 - auc: 0.8273 - val_loss: 0.1521 - val_auc: 0.8124\n",
            "Epoch 312/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8257 - val_loss: 0.1517 - val_auc: 0.8121\n",
            "Epoch 313/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - auc: 0.8258 - val_loss: 0.1510 - val_auc: 0.8118\n",
            "Epoch 314/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8261 - val_loss: 0.1509 - val_auc: 0.8124\n",
            "Epoch 315/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8276 - val_loss: 0.1507 - val_auc: 0.8123\n",
            "Epoch 316/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1357 - auc: 0.8252 - val_loss: 0.1524 - val_auc: 0.8118\n",
            "Epoch 317/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1357 - auc: 0.8259 - val_loss: 0.1510 - val_auc: 0.8107\n",
            "Epoch 318/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8258 - val_loss: 0.1523 - val_auc: 0.8118\n",
            "Epoch 319/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1354 - auc: 0.8279 - val_loss: 0.1500 - val_auc: 0.8099\n",
            "Epoch 320/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1361 - auc: 0.8248 - val_loss: 0.1499 - val_auc: 0.8119\n",
            "Epoch 321/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8282 - val_loss: 0.1532 - val_auc: 0.8103\n",
            "Epoch 322/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1352 - auc: 0.8292 - val_loss: 0.1503 - val_auc: 0.8106\n",
            "Epoch 323/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8267 - val_loss: 0.1512 - val_auc: 0.8130\n",
            "Epoch 324/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8284 - val_loss: 0.1517 - val_auc: 0.8118\n",
            "Epoch 325/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8253 - val_loss: 0.1522 - val_auc: 0.8113\n",
            "Epoch 326/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8298 - val_loss: 0.1517 - val_auc: 0.8130\n",
            "Epoch 327/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8272 - val_loss: 0.1533 - val_auc: 0.8096\n",
            "Epoch 328/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1357 - auc: 0.8262 - val_loss: 0.1507 - val_auc: 0.8128\n",
            "Epoch 329/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1354 - auc: 0.8287 - val_loss: 0.1526 - val_auc: 0.8105\n",
            "Epoch 330/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1352 - auc: 0.8295 - val_loss: 0.1511 - val_auc: 0.8117\n",
            "Epoch 331/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1362 - auc: 0.8242 - val_loss: 0.1500 - val_auc: 0.8110\n",
            "Epoch 332/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1360 - auc: 0.8250 - val_loss: 0.1503 - val_auc: 0.8132\n",
            "Epoch 333/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8277 - val_loss: 0.1509 - val_auc: 0.8125\n",
            "Epoch 334/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1352 - auc: 0.8287 - val_loss: 0.1525 - val_auc: 0.8103\n",
            "Epoch 335/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8266 - val_loss: 0.1516 - val_auc: 0.8103\n",
            "Epoch 336/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8277 - val_loss: 0.1507 - val_auc: 0.8144\n",
            "Epoch 337/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8290 - val_loss: 0.1508 - val_auc: 0.8120\n",
            "Epoch 338/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8294 - val_loss: 0.1530 - val_auc: 0.8123\n",
            "Epoch 339/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1357 - auc: 0.8268 - val_loss: 0.1517 - val_auc: 0.8125\n",
            "Epoch 340/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1350 - auc: 0.8291 - val_loss: 0.1508 - val_auc: 0.8122\n",
            "Epoch 341/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8248 - val_loss: 0.1521 - val_auc: 0.8124\n",
            "Epoch 342/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1360 - auc: 0.8249 - val_loss: 0.1509 - val_auc: 0.8124\n",
            "Epoch 343/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1358 - auc: 0.8265 - val_loss: 0.1517 - val_auc: 0.8109\n",
            "Epoch 344/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8280 - val_loss: 0.1515 - val_auc: 0.8125\n",
            "Epoch 345/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1356 - auc: 0.8280 - val_loss: 0.1507 - val_auc: 0.8120\n",
            "Epoch 346/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1356 - auc: 0.8279 - val_loss: 0.1517 - val_auc: 0.8118\n",
            "Epoch 347/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8297 - val_loss: 0.1512 - val_auc: 0.8110\n",
            "Epoch 348/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1362 - auc: 0.8236 - val_loss: 0.1531 - val_auc: 0.8124\n",
            "Epoch 349/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1353 - auc: 0.8287 - val_loss: 0.1511 - val_auc: 0.8137\n",
            "Epoch 350/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8283 - val_loss: 0.1510 - val_auc: 0.8136\n",
            "Epoch 351/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8307 - val_loss: 0.1518 - val_auc: 0.8133\n",
            "Epoch 352/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8282 - val_loss: 0.1510 - val_auc: 0.8126\n",
            "Epoch 353/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8273 - val_loss: 0.1510 - val_auc: 0.8121\n",
            "Epoch 354/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8295 - val_loss: 0.1507 - val_auc: 0.8118\n",
            "Epoch 355/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8273 - val_loss: 0.1511 - val_auc: 0.8117\n",
            "Epoch 356/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8276 - val_loss: 0.1515 - val_auc: 0.8117\n",
            "Epoch 357/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8285 - val_loss: 0.1518 - val_auc: 0.8123\n",
            "Epoch 358/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8279 - val_loss: 0.1524 - val_auc: 0.8117\n",
            "Epoch 359/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1349 - auc: 0.8308 - val_loss: 0.1515 - val_auc: 0.8112\n",
            "Epoch 360/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1353 - auc: 0.8285 - val_loss: 0.1507 - val_auc: 0.8122\n",
            "Epoch 361/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8278 - val_loss: 0.1515 - val_auc: 0.8141\n",
            "Epoch 362/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1348 - auc: 0.8298 - val_loss: 0.1509 - val_auc: 0.8123\n",
            "Epoch 363/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8287 - val_loss: 0.1512 - val_auc: 0.8110\n",
            "Epoch 364/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1358 - auc: 0.8259 - val_loss: 0.1516 - val_auc: 0.8111\n",
            "Epoch 365/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1355 - auc: 0.8278 - val_loss: 0.1510 - val_auc: 0.8126\n",
            "Epoch 366/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8281 - val_loss: 0.1530 - val_auc: 0.8099\n",
            "Epoch 367/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1355 - auc: 0.8276 - val_loss: 0.1505 - val_auc: 0.8138\n",
            "Epoch 368/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8292 - val_loss: 0.1503 - val_auc: 0.8130\n",
            "Epoch 369/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1349 - auc: 0.8309 - val_loss: 0.1505 - val_auc: 0.8130\n",
            "Epoch 370/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8279 - val_loss: 0.1513 - val_auc: 0.8137\n",
            "Epoch 371/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8281 - val_loss: 0.1516 - val_auc: 0.8121\n",
            "Epoch 372/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8271 - val_loss: 0.1509 - val_auc: 0.8116\n",
            "Epoch 373/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8294 - val_loss: 0.1517 - val_auc: 0.8132\n",
            "Epoch 374/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8274 - val_loss: 0.1525 - val_auc: 0.8116\n",
            "Epoch 375/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1356 - auc: 0.8272 - val_loss: 0.1529 - val_auc: 0.8122\n",
            "Epoch 376/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8289 - val_loss: 0.1517 - val_auc: 0.8125\n",
            "Epoch 377/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1349 - auc: 0.8307 - val_loss: 0.1520 - val_auc: 0.8127\n",
            "Epoch 378/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8287 - val_loss: 0.1512 - val_auc: 0.8136\n",
            "Epoch 379/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8273 - val_loss: 0.1524 - val_auc: 0.8120\n",
            "Epoch 380/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1352 - auc: 0.8287 - val_loss: 0.1515 - val_auc: 0.8147\n",
            "Epoch 381/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8299 - val_loss: 0.1513 - val_auc: 0.8141\n",
            "Epoch 382/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1359 - auc: 0.8265 - val_loss: 0.1512 - val_auc: 0.8125\n",
            "Epoch 383/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8287 - val_loss: 0.1530 - val_auc: 0.8116\n",
            "Epoch 384/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8286 - val_loss: 0.1510 - val_auc: 0.8129\n",
            "Epoch 385/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8271 - val_loss: 0.1521 - val_auc: 0.8110\n",
            "Epoch 386/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1353 - auc: 0.8279 - val_loss: 0.1507 - val_auc: 0.8103\n",
            "Epoch 387/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8294 - val_loss: 0.1526 - val_auc: 0.8134\n",
            "Epoch 388/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8306 - val_loss: 0.1514 - val_auc: 0.8107\n",
            "Epoch 389/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1347 - auc: 0.8325 - val_loss: 0.1512 - val_auc: 0.8128\n",
            "Epoch 390/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1352 - auc: 0.8294 - val_loss: 0.1524 - val_auc: 0.8130\n",
            "Epoch 391/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1346 - auc: 0.8311 - val_loss: 0.1536 - val_auc: 0.8100\n",
            "Epoch 392/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1355 - auc: 0.8267 - val_loss: 0.1514 - val_auc: 0.8122\n",
            "Epoch 393/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8283 - val_loss: 0.1518 - val_auc: 0.8135\n",
            "Epoch 394/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1347 - auc: 0.8303 - val_loss: 0.1520 - val_auc: 0.8133\n",
            "Epoch 395/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1349 - auc: 0.8296 - val_loss: 0.1511 - val_auc: 0.8111\n",
            "Epoch 396/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1349 - auc: 0.8308 - val_loss: 0.1525 - val_auc: 0.8115\n",
            "Epoch 397/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1353 - auc: 0.8287 - val_loss: 0.1526 - val_auc: 0.8114\n",
            "Epoch 398/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8295 - val_loss: 0.1528 - val_auc: 0.8115\n",
            "Epoch 399/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1350 - auc: 0.8291 - val_loss: 0.1516 - val_auc: 0.8127\n",
            "Epoch 400/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8273 - val_loss: 0.1527 - val_auc: 0.8117\n",
            "Epoch 401/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8307 - val_loss: 0.1514 - val_auc: 0.8150\n",
            "Epoch 402/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8301 - val_loss: 0.1519 - val_auc: 0.8128\n",
            "Epoch 403/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1354 - auc: 0.8266 - val_loss: 0.1536 - val_auc: 0.8109\n",
            "Epoch 404/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1352 - auc: 0.8294 - val_loss: 0.1521 - val_auc: 0.8119\n",
            "Epoch 405/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1348 - auc: 0.8306 - val_loss: 0.1517 - val_auc: 0.8116\n",
            "Epoch 406/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8295 - val_loss: 0.1524 - val_auc: 0.8135\n",
            "Epoch 407/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1349 - auc: 0.8301 - val_loss: 0.1530 - val_auc: 0.8123\n",
            "Epoch 408/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8293 - val_loss: 0.1510 - val_auc: 0.8132\n",
            "Epoch 409/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8299 - val_loss: 0.1521 - val_auc: 0.8138\n",
            "Epoch 410/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1357 - auc: 0.8256 - val_loss: 0.1522 - val_auc: 0.8101\n",
            "Epoch 411/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8278 - val_loss: 0.1515 - val_auc: 0.8137\n",
            "Epoch 412/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1350 - auc: 0.8293 - val_loss: 0.1526 - val_auc: 0.8126\n",
            "Epoch 413/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8286 - val_loss: 0.1517 - val_auc: 0.8135\n",
            "Epoch 414/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1357 - auc: 0.8260 - val_loss: 0.1540 - val_auc: 0.8110\n",
            "Epoch 415/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8280 - val_loss: 0.1518 - val_auc: 0.8126\n",
            "Epoch 416/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8298 - val_loss: 0.1513 - val_auc: 0.8124\n",
            "Epoch 417/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8304 - val_loss: 0.1521 - val_auc: 0.8111\n",
            "Epoch 418/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1346 - auc: 0.8310 - val_loss: 0.1504 - val_auc: 0.8148\n",
            "Epoch 419/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1352 - auc: 0.8289 - val_loss: 0.1518 - val_auc: 0.8117\n",
            "Epoch 420/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1355 - auc: 0.8268 - val_loss: 0.1525 - val_auc: 0.8134\n",
            "Epoch 421/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8290 - val_loss: 0.1529 - val_auc: 0.8106\n",
            "Epoch 422/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8307 - val_loss: 0.1528 - val_auc: 0.8114\n",
            "Epoch 423/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1342 - auc: 0.8338 - val_loss: 0.1514 - val_auc: 0.8144\n",
            "Epoch 424/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1353 - auc: 0.8290 - val_loss: 0.1519 - val_auc: 0.8132\n",
            "Epoch 425/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1343 - auc: 0.8322 - val_loss: 0.1524 - val_auc: 0.8121\n",
            "Epoch 426/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8297 - val_loss: 0.1515 - val_auc: 0.8118\n",
            "Epoch 427/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1357 - auc: 0.8267 - val_loss: 0.1515 - val_auc: 0.8125\n",
            "Epoch 428/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1349 - auc: 0.8301 - val_loss: 0.1528 - val_auc: 0.8112\n",
            "Epoch 429/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1345 - auc: 0.8320 - val_loss: 0.1519 - val_auc: 0.8137\n",
            "Epoch 430/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8313 - val_loss: 0.1520 - val_auc: 0.8142\n",
            "Epoch 431/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8292 - val_loss: 0.1513 - val_auc: 0.8134\n",
            "Epoch 432/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1343 - auc: 0.8331 - val_loss: 0.1522 - val_auc: 0.8130\n",
            "Epoch 433/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1352 - auc: 0.8285 - val_loss: 0.1551 - val_auc: 0.8104\n",
            "Epoch 434/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1347 - auc: 0.8313 - val_loss: 0.1530 - val_auc: 0.8097\n",
            "Epoch 435/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1350 - auc: 0.8301 - val_loss: 0.1518 - val_auc: 0.8116\n",
            "Epoch 436/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1350 - auc: 0.8298 - val_loss: 0.1528 - val_auc: 0.8131\n",
            "Epoch 437/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1349 - auc: 0.8299 - val_loss: 0.1532 - val_auc: 0.8115\n",
            "Epoch 438/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1348 - auc: 0.8306 - val_loss: 0.1522 - val_auc: 0.8132\n",
            "Epoch 439/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1348 - auc: 0.8308 - val_loss: 0.1543 - val_auc: 0.8115\n",
            "Epoch 440/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1352 - auc: 0.8285 - val_loss: 0.1522 - val_auc: 0.8117\n",
            "Epoch 441/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1348 - auc: 0.8298 - val_loss: 0.1519 - val_auc: 0.8133\n",
            "Epoch 442/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8287 - val_loss: 0.1536 - val_auc: 0.8097\n",
            "Epoch 443/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1345 - auc: 0.8324 - val_loss: 0.1526 - val_auc: 0.8120\n",
            "Epoch 444/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1345 - auc: 0.8319 - val_loss: 0.1538 - val_auc: 0.8126\n",
            "Epoch 445/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8269 - val_loss: 0.1520 - val_auc: 0.8132\n",
            "Epoch 446/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8303 - val_loss: 0.1524 - val_auc: 0.8125\n",
            "Epoch 447/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1346 - auc: 0.8321 - val_loss: 0.1526 - val_auc: 0.8118\n",
            "Epoch 448/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1353 - auc: 0.8293 - val_loss: 0.1518 - val_auc: 0.8113\n",
            "Epoch 449/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8288 - val_loss: 0.1523 - val_auc: 0.8122\n",
            "Epoch 450/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8307 - val_loss: 0.1521 - val_auc: 0.8127\n",
            "Epoch 451/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1349 - auc: 0.8308 - val_loss: 0.1532 - val_auc: 0.8098\n",
            "Epoch 452/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1355 - auc: 0.8268 - val_loss: 0.1530 - val_auc: 0.8129\n",
            "Epoch 453/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1352 - auc: 0.8289 - val_loss: 0.1525 - val_auc: 0.8121\n",
            "Epoch 454/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1352 - auc: 0.8290 - val_loss: 0.1521 - val_auc: 0.8126\n",
            "Epoch 455/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1345 - auc: 0.8318 - val_loss: 0.1532 - val_auc: 0.8123\n",
            "Epoch 456/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8290 - val_loss: 0.1525 - val_auc: 0.8113\n",
            "Epoch 457/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1349 - auc: 0.8293 - val_loss: 0.1525 - val_auc: 0.8120\n",
            "Epoch 458/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1346 - auc: 0.8305 - val_loss: 0.1524 - val_auc: 0.8116\n",
            "Epoch 459/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1354 - auc: 0.8277 - val_loss: 0.1539 - val_auc: 0.8103\n",
            "Epoch 460/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1347 - auc: 0.8307 - val_loss: 0.1537 - val_auc: 0.8106\n",
            "Epoch 461/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1351 - auc: 0.8294 - val_loss: 0.1520 - val_auc: 0.8109\n",
            "Epoch 462/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1350 - auc: 0.8291 - val_loss: 0.1536 - val_auc: 0.8113\n",
            "Epoch 463/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1349 - auc: 0.8290 - val_loss: 0.1537 - val_auc: 0.8112\n",
            "Epoch 464/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8284 - val_loss: 0.1532 - val_auc: 0.8112\n",
            "Epoch 465/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1356 - auc: 0.8264 - val_loss: 0.1531 - val_auc: 0.8131\n",
            "Epoch 466/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1347 - auc: 0.8311 - val_loss: 0.1528 - val_auc: 0.8120\n",
            "Epoch 467/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8305 - val_loss: 0.1524 - val_auc: 0.8122\n",
            "Epoch 468/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1350 - auc: 0.8293 - val_loss: 0.1524 - val_auc: 0.8113\n",
            "Epoch 469/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1346 - auc: 0.8317 - val_loss: 0.1543 - val_auc: 0.8103\n",
            "Epoch 470/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1352 - auc: 0.8286 - val_loss: 0.1534 - val_auc: 0.8120\n",
            "Epoch 471/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1346 - auc: 0.8312 - val_loss: 0.1528 - val_auc: 0.8132\n",
            "Epoch 472/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1349 - auc: 0.8298 - val_loss: 0.1521 - val_auc: 0.8125\n",
            "Epoch 473/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1349 - auc: 0.8303 - val_loss: 0.1559 - val_auc: 0.8095\n",
            "Epoch 474/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1351 - auc: 0.8301 - val_loss: 0.1526 - val_auc: 0.8126\n",
            "Epoch 475/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1349 - auc: 0.8308 - val_loss: 0.1535 - val_auc: 0.8125\n",
            "Epoch 476/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1347 - auc: 0.8303 - val_loss: 0.1535 - val_auc: 0.8109\n",
            "Epoch 477/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8300 - val_loss: 0.1548 - val_auc: 0.8119\n",
            "Epoch 478/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1346 - auc: 0.8326 - val_loss: 0.1528 - val_auc: 0.8120\n",
            "Epoch 479/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1347 - auc: 0.8312 - val_loss: 0.1552 - val_auc: 0.8085\n",
            "Epoch 480/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1347 - auc: 0.8303 - val_loss: 0.1545 - val_auc: 0.8114\n",
            "Epoch 481/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1345 - auc: 0.8315 - val_loss: 0.1531 - val_auc: 0.8107\n",
            "Epoch 482/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1350 - auc: 0.8296 - val_loss: 0.1528 - val_auc: 0.8126\n",
            "Epoch 483/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1347 - auc: 0.8303 - val_loss: 0.1550 - val_auc: 0.8102\n",
            "Epoch 484/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1346 - auc: 0.8312 - val_loss: 0.1527 - val_auc: 0.8113\n",
            "Epoch 485/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1346 - auc: 0.8306 - val_loss: 0.1539 - val_auc: 0.8124\n",
            "Epoch 486/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1347 - auc: 0.8302 - val_loss: 0.1540 - val_auc: 0.8100\n",
            "Epoch 487/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1346 - auc: 0.8313 - val_loss: 0.1527 - val_auc: 0.8112\n",
            "Epoch 488/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8296 - val_loss: 0.1534 - val_auc: 0.8109\n",
            "Epoch 489/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1347 - auc: 0.8301 - val_loss: 0.1529 - val_auc: 0.8125\n",
            "Epoch 490/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1341 - auc: 0.8333 - val_loss: 0.1538 - val_auc: 0.8114\n",
            "Epoch 491/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1345 - auc: 0.8314 - val_loss: 0.1526 - val_auc: 0.8115\n",
            "Epoch 492/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1344 - auc: 0.8326 - val_loss: 0.1527 - val_auc: 0.8109\n",
            "Epoch 493/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1344 - auc: 0.8321 - val_loss: 0.1530 - val_auc: 0.8130\n",
            "Epoch 494/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8301 - val_loss: 0.1534 - val_auc: 0.8102\n",
            "Epoch 495/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1347 - auc: 0.8307 - val_loss: 0.1541 - val_auc: 0.8130\n",
            "Epoch 496/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8301 - val_loss: 0.1534 - val_auc: 0.8114\n",
            "Epoch 497/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1345 - auc: 0.8318 - val_loss: 0.1534 - val_auc: 0.8102\n",
            "Epoch 498/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1348 - auc: 0.8298 - val_loss: 0.1529 - val_auc: 0.8118\n",
            "Epoch 499/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1349 - auc: 0.8300 - val_loss: 0.1530 - val_auc: 0.8112\n",
            "Epoch 500/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1347 - auc: 0.8307 - val_loss: 0.1539 - val_auc: 0.8108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "HAkqvAWJ9gPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see the difference the dropout and the optimizer has on the data\n",
        "tf.random.set_seed(42)\n",
        "model2 = keras.models.Sequential([\n",
        "        keras.layers.Dense(9, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "        #keras.layers.Dropout(0.3), #drop 30% of the nuerons randomly\n",
        "        keras.layers.Dense(9, activation=\"relu\"),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),#output layer\n",
        " ]) \n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TyvdFLU9kBN",
        "outputId": "401ec88a-e68b-4e4b-b397-50009e9c997d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 9)                 3033      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 90        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,133\n",
            "Trainable params: 3,133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer=keras.optimizers.SGD(learning_rate=0.001), \n",
        "              loss=\"binary_crossentropy\", \n",
        "              metrics=[\"AUC\"])"
      ],
      "metadata": {
        "id": "H-B8c2G89rgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_me= model2.fit(X_train, y_train, epochs=500,\\\n",
        "                    batch_size= 1000, validation_data=(X_valid, y_valid))\n",
        "\n",
        "\n",
        "plt.plot(pd.DataFrame(show_me.history))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ecJYQxdk9tST",
        "outputId": "dd28a1d3-f0b3-4407-f720-5f73a9e8b856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.6208 - auc: 0.5895 - val_loss: 0.5940 - val_auc: 0.6318\n",
            "Epoch 2/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5674 - auc: 0.6344 - val_loss: 0.5398 - val_auc: 0.6496\n",
            "Epoch 3/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5139 - auc: 0.6511 - val_loss: 0.4889 - val_auc: 0.6611\n",
            "Epoch 4/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4655 - auc: 0.6602 - val_loss: 0.4435 - val_auc: 0.6667\n",
            "Epoch 5/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4216 - auc: 0.6614 - val_loss: 0.4013 - val_auc: 0.6683\n",
            "Epoch 6/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3801 - auc: 0.6683 - val_loss: 0.3619 - val_auc: 0.6713\n",
            "Epoch 7/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3432 - auc: 0.6737 - val_loss: 0.3284 - val_auc: 0.6726\n",
            "Epoch 8/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3120 - auc: 0.6745 - val_loss: 0.3003 - val_auc: 0.6737\n",
            "Epoch 9/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2861 - auc: 0.6744 - val_loss: 0.2772 - val_auc: 0.6732\n",
            "Epoch 10/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2649 - auc: 0.6783 - val_loss: 0.2583 - val_auc: 0.6732\n",
            "Epoch 11/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2475 - auc: 0.6752 - val_loss: 0.2429 - val_auc: 0.6739\n",
            "Epoch 12/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2333 - auc: 0.6744 - val_loss: 0.2303 - val_auc: 0.6739\n",
            "Epoch 13/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2216 - auc: 0.6724 - val_loss: 0.2200 - val_auc: 0.6720\n",
            "Epoch 14/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2120 - auc: 0.6730 - val_loss: 0.2114 - val_auc: 0.6723\n",
            "Epoch 15/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2040 - auc: 0.6742 - val_loss: 0.2043 - val_auc: 0.6737\n",
            "Epoch 16/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1974 - auc: 0.6744 - val_loss: 0.1984 - val_auc: 0.6722\n",
            "Epoch 17/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1918 - auc: 0.6729 - val_loss: 0.1935 - val_auc: 0.6704\n",
            "Epoch 18/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1871 - auc: 0.6725 - val_loss: 0.1893 - val_auc: 0.6728\n",
            "Epoch 19/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1831 - auc: 0.6735 - val_loss: 0.1858 - val_auc: 0.6732\n",
            "Epoch 20/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1798 - auc: 0.6726 - val_loss: 0.1828 - val_auc: 0.6712\n",
            "Epoch 21/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1769 - auc: 0.6735 - val_loss: 0.1803 - val_auc: 0.6722\n",
            "Epoch 22/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1745 - auc: 0.6714 - val_loss: 0.1782 - val_auc: 0.6716\n",
            "Epoch 23/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1724 - auc: 0.6716 - val_loss: 0.1764 - val_auc: 0.6719\n",
            "Epoch 24/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1706 - auc: 0.6722 - val_loss: 0.1748 - val_auc: 0.6717\n",
            "Epoch 25/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1691 - auc: 0.6728 - val_loss: 0.1734 - val_auc: 0.6725\n",
            "Epoch 26/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1677 - auc: 0.6726 - val_loss: 0.1723 - val_auc: 0.6708\n",
            "Epoch 27/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1666 - auc: 0.6724 - val_loss: 0.1713 - val_auc: 0.6725\n",
            "Epoch 28/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1655 - auc: 0.6725 - val_loss: 0.1704 - val_auc: 0.6724\n",
            "Epoch 29/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1647 - auc: 0.6720 - val_loss: 0.1696 - val_auc: 0.6706\n",
            "Epoch 30/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1639 - auc: 0.6729 - val_loss: 0.1690 - val_auc: 0.6718\n",
            "Epoch 31/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1632 - auc: 0.6728 - val_loss: 0.1684 - val_auc: 0.6725\n",
            "Epoch 32/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1626 - auc: 0.6723 - val_loss: 0.1679 - val_auc: 0.6740\n",
            "Epoch 33/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1621 - auc: 0.6716 - val_loss: 0.1675 - val_auc: 0.6714\n",
            "Epoch 34/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1617 - auc: 0.6722 - val_loss: 0.1671 - val_auc: 0.6729\n",
            "Epoch 35/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1612 - auc: 0.6718 - val_loss: 0.1667 - val_auc: 0.6725\n",
            "Epoch 36/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1609 - auc: 0.6739 - val_loss: 0.1664 - val_auc: 0.6737\n",
            "Epoch 37/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1606 - auc: 0.6732 - val_loss: 0.1662 - val_auc: 0.6750\n",
            "Epoch 38/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1603 - auc: 0.6704 - val_loss: 0.1659 - val_auc: 0.6732\n",
            "Epoch 39/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1600 - auc: 0.6724 - val_loss: 0.1657 - val_auc: 0.6715\n",
            "Epoch 40/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1598 - auc: 0.6727 - val_loss: 0.1656 - val_auc: 0.6729\n",
            "Epoch 41/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1596 - auc: 0.6738 - val_loss: 0.1654 - val_auc: 0.6722\n",
            "Epoch 42/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1594 - auc: 0.6732 - val_loss: 0.1653 - val_auc: 0.6752\n",
            "Epoch 43/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1593 - auc: 0.6737 - val_loss: 0.1651 - val_auc: 0.6743\n",
            "Epoch 44/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1591 - auc: 0.6735 - val_loss: 0.1650 - val_auc: 0.6744\n",
            "Epoch 45/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1590 - auc: 0.6734 - val_loss: 0.1649 - val_auc: 0.6743\n",
            "Epoch 46/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1589 - auc: 0.6707 - val_loss: 0.1648 - val_auc: 0.6732\n",
            "Epoch 47/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1588 - auc: 0.6728 - val_loss: 0.1647 - val_auc: 0.6731\n",
            "Epoch 48/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1587 - auc: 0.6736 - val_loss: 0.1647 - val_auc: 0.6727\n",
            "Epoch 49/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1586 - auc: 0.6728 - val_loss: 0.1646 - val_auc: 0.6738\n",
            "Epoch 50/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1585 - auc: 0.6733 - val_loss: 0.1645 - val_auc: 0.6739\n",
            "Epoch 51/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1584 - auc: 0.6729 - val_loss: 0.1645 - val_auc: 0.6751\n",
            "Epoch 52/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1583 - auc: 0.6748 - val_loss: 0.1644 - val_auc: 0.6749\n",
            "Epoch 53/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1583 - auc: 0.6747 - val_loss: 0.1644 - val_auc: 0.6755\n",
            "Epoch 54/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1582 - auc: 0.6748 - val_loss: 0.1643 - val_auc: 0.6745\n",
            "Epoch 55/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1582 - auc: 0.6756 - val_loss: 0.1643 - val_auc: 0.6752\n",
            "Epoch 56/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1581 - auc: 0.6748 - val_loss: 0.1643 - val_auc: 0.6763\n",
            "Epoch 57/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1581 - auc: 0.6751 - val_loss: 0.1642 - val_auc: 0.6766\n",
            "Epoch 58/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1580 - auc: 0.6754 - val_loss: 0.1642 - val_auc: 0.6761\n",
            "Epoch 59/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1580 - auc: 0.6754 - val_loss: 0.1642 - val_auc: 0.6756\n",
            "Epoch 60/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1579 - auc: 0.6744 - val_loss: 0.1641 - val_auc: 0.6757\n",
            "Epoch 61/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1579 - auc: 0.6741 - val_loss: 0.1641 - val_auc: 0.6762\n",
            "Epoch 62/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1579 - auc: 0.6735 - val_loss: 0.1641 - val_auc: 0.6749\n",
            "Epoch 63/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1578 - auc: 0.6730 - val_loss: 0.1641 - val_auc: 0.6754\n",
            "Epoch 64/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1578 - auc: 0.6741 - val_loss: 0.1640 - val_auc: 0.6751\n",
            "Epoch 65/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1578 - auc: 0.6737 - val_loss: 0.1640 - val_auc: 0.6748\n",
            "Epoch 66/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1577 - auc: 0.6736 - val_loss: 0.1640 - val_auc: 0.6747\n",
            "Epoch 67/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1577 - auc: 0.6736 - val_loss: 0.1640 - val_auc: 0.6760\n",
            "Epoch 68/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1577 - auc: 0.6731 - val_loss: 0.1639 - val_auc: 0.6764\n",
            "Epoch 69/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1577 - auc: 0.6733 - val_loss: 0.1639 - val_auc: 0.6747\n",
            "Epoch 70/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1576 - auc: 0.6733 - val_loss: 0.1639 - val_auc: 0.6756\n",
            "Epoch 71/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1576 - auc: 0.6733 - val_loss: 0.1639 - val_auc: 0.6759\n",
            "Epoch 72/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1576 - auc: 0.6736 - val_loss: 0.1639 - val_auc: 0.6766\n",
            "Epoch 73/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1576 - auc: 0.6742 - val_loss: 0.1638 - val_auc: 0.6765\n",
            "Epoch 74/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1576 - auc: 0.6747 - val_loss: 0.1638 - val_auc: 0.6764\n",
            "Epoch 75/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1575 - auc: 0.6750 - val_loss: 0.1638 - val_auc: 0.6753\n",
            "Epoch 76/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1575 - auc: 0.6757 - val_loss: 0.1638 - val_auc: 0.6749\n",
            "Epoch 77/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1575 - auc: 0.6752 - val_loss: 0.1638 - val_auc: 0.6748\n",
            "Epoch 78/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1575 - auc: 0.6752 - val_loss: 0.1638 - val_auc: 0.6752\n",
            "Epoch 79/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1574 - auc: 0.6756 - val_loss: 0.1637 - val_auc: 0.6758\n",
            "Epoch 80/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1574 - auc: 0.6758 - val_loss: 0.1637 - val_auc: 0.6761\n",
            "Epoch 81/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1574 - auc: 0.6759 - val_loss: 0.1637 - val_auc: 0.6773\n",
            "Epoch 82/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1574 - auc: 0.6763 - val_loss: 0.1637 - val_auc: 0.6771\n",
            "Epoch 83/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1574 - auc: 0.6761 - val_loss: 0.1637 - val_auc: 0.6768\n",
            "Epoch 84/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1574 - auc: 0.6765 - val_loss: 0.1637 - val_auc: 0.6768\n",
            "Epoch 85/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1573 - auc: 0.6765 - val_loss: 0.1636 - val_auc: 0.6768\n",
            "Epoch 86/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1573 - auc: 0.6762 - val_loss: 0.1636 - val_auc: 0.6772\n",
            "Epoch 87/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1573 - auc: 0.6765 - val_loss: 0.1636 - val_auc: 0.6778\n",
            "Epoch 88/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1573 - auc: 0.6761 - val_loss: 0.1636 - val_auc: 0.6773\n",
            "Epoch 89/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1573 - auc: 0.6763 - val_loss: 0.1636 - val_auc: 0.6773\n",
            "Epoch 90/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1573 - auc: 0.6767 - val_loss: 0.1636 - val_auc: 0.6778\n",
            "Epoch 91/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1572 - auc: 0.6775 - val_loss: 0.1635 - val_auc: 0.6766\n",
            "Epoch 92/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1572 - auc: 0.6776 - val_loss: 0.1635 - val_auc: 0.6767\n",
            "Epoch 93/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1572 - auc: 0.6773 - val_loss: 0.1635 - val_auc: 0.6777\n",
            "Epoch 94/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1572 - auc: 0.6772 - val_loss: 0.1635 - val_auc: 0.6778\n",
            "Epoch 95/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1572 - auc: 0.6775 - val_loss: 0.1635 - val_auc: 0.6775\n",
            "Epoch 96/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1572 - auc: 0.6773 - val_loss: 0.1635 - val_auc: 0.6773\n",
            "Epoch 97/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1571 - auc: 0.6779 - val_loss: 0.1634 - val_auc: 0.6778\n",
            "Epoch 98/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1571 - auc: 0.6778 - val_loss: 0.1634 - val_auc: 0.6780\n",
            "Epoch 99/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1571 - auc: 0.6781 - val_loss: 0.1634 - val_auc: 0.6783\n",
            "Epoch 100/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1571 - auc: 0.6783 - val_loss: 0.1634 - val_auc: 0.6784\n",
            "Epoch 101/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1571 - auc: 0.6783 - val_loss: 0.1634 - val_auc: 0.6789\n",
            "Epoch 102/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1571 - auc: 0.6782 - val_loss: 0.1634 - val_auc: 0.6783\n",
            "Epoch 103/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1571 - auc: 0.6786 - val_loss: 0.1634 - val_auc: 0.6783\n",
            "Epoch 104/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1570 - auc: 0.6786 - val_loss: 0.1633 - val_auc: 0.6783\n",
            "Epoch 105/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1570 - auc: 0.6786 - val_loss: 0.1633 - val_auc: 0.6792\n",
            "Epoch 106/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1570 - auc: 0.6788 - val_loss: 0.1633 - val_auc: 0.6797\n",
            "Epoch 107/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1570 - auc: 0.6792 - val_loss: 0.1633 - val_auc: 0.6793\n",
            "Epoch 108/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1570 - auc: 0.6790 - val_loss: 0.1633 - val_auc: 0.6795\n",
            "Epoch 109/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1570 - auc: 0.6796 - val_loss: 0.1633 - val_auc: 0.6803\n",
            "Epoch 110/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1570 - auc: 0.6788 - val_loss: 0.1633 - val_auc: 0.6805\n",
            "Epoch 111/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1569 - auc: 0.6791 - val_loss: 0.1632 - val_auc: 0.6816\n",
            "Epoch 112/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1569 - auc: 0.6791 - val_loss: 0.1632 - val_auc: 0.6814\n",
            "Epoch 113/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1569 - auc: 0.6795 - val_loss: 0.1632 - val_auc: 0.6803\n",
            "Epoch 114/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1569 - auc: 0.6797 - val_loss: 0.1632 - val_auc: 0.6803\n",
            "Epoch 115/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1569 - auc: 0.6801 - val_loss: 0.1632 - val_auc: 0.6804\n",
            "Epoch 116/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1569 - auc: 0.6798 - val_loss: 0.1632 - val_auc: 0.6812\n",
            "Epoch 117/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1569 - auc: 0.6792 - val_loss: 0.1632 - val_auc: 0.6818\n",
            "Epoch 118/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1568 - auc: 0.6791 - val_loss: 0.1631 - val_auc: 0.6820\n",
            "Epoch 119/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1568 - auc: 0.6795 - val_loss: 0.1631 - val_auc: 0.6817\n",
            "Epoch 120/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1568 - auc: 0.6795 - val_loss: 0.1631 - val_auc: 0.6818\n",
            "Epoch 121/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1568 - auc: 0.6796 - val_loss: 0.1631 - val_auc: 0.6821\n",
            "Epoch 122/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1568 - auc: 0.6794 - val_loss: 0.1631 - val_auc: 0.6821\n",
            "Epoch 123/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1568 - auc: 0.6795 - val_loss: 0.1631 - val_auc: 0.6818\n",
            "Epoch 124/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1568 - auc: 0.6794 - val_loss: 0.1631 - val_auc: 0.6823\n",
            "Epoch 125/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1568 - auc: 0.6793 - val_loss: 0.1630 - val_auc: 0.6823\n",
            "Epoch 126/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1568 - auc: 0.6793 - val_loss: 0.1630 - val_auc: 0.6826\n",
            "Epoch 127/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1567 - auc: 0.6793 - val_loss: 0.1630 - val_auc: 0.6823\n",
            "Epoch 128/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1567 - auc: 0.6792 - val_loss: 0.1630 - val_auc: 0.6828\n",
            "Epoch 129/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1567 - auc: 0.6793 - val_loss: 0.1630 - val_auc: 0.6821\n",
            "Epoch 130/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1567 - auc: 0.6790 - val_loss: 0.1630 - val_auc: 0.6823\n",
            "Epoch 131/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1567 - auc: 0.6791 - val_loss: 0.1630 - val_auc: 0.6823\n",
            "Epoch 132/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1567 - auc: 0.6791 - val_loss: 0.1630 - val_auc: 0.6821\n",
            "Epoch 133/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1567 - auc: 0.6793 - val_loss: 0.1629 - val_auc: 0.6824\n",
            "Epoch 134/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1567 - auc: 0.6797 - val_loss: 0.1629 - val_auc: 0.6819\n",
            "Epoch 135/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1566 - auc: 0.6792 - val_loss: 0.1629 - val_auc: 0.6811\n",
            "Epoch 136/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1566 - auc: 0.6794 - val_loss: 0.1629 - val_auc: 0.6819\n",
            "Epoch 137/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1566 - auc: 0.6794 - val_loss: 0.1629 - val_auc: 0.6820\n",
            "Epoch 138/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1566 - auc: 0.6791 - val_loss: 0.1629 - val_auc: 0.6824\n",
            "Epoch 139/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1566 - auc: 0.6793 - val_loss: 0.1629 - val_auc: 0.6825\n",
            "Epoch 140/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1566 - auc: 0.6793 - val_loss: 0.1629 - val_auc: 0.6825\n",
            "Epoch 141/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1566 - auc: 0.6792 - val_loss: 0.1628 - val_auc: 0.6824\n",
            "Epoch 142/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1566 - auc: 0.6794 - val_loss: 0.1628 - val_auc: 0.6827\n",
            "Epoch 143/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1566 - auc: 0.6796 - val_loss: 0.1628 - val_auc: 0.6828\n",
            "Epoch 144/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1565 - auc: 0.6794 - val_loss: 0.1628 - val_auc: 0.6831\n",
            "Epoch 145/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1565 - auc: 0.6797 - val_loss: 0.1628 - val_auc: 0.6829\n",
            "Epoch 146/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1565 - auc: 0.6797 - val_loss: 0.1628 - val_auc: 0.6827\n",
            "Epoch 147/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1565 - auc: 0.6801 - val_loss: 0.1628 - val_auc: 0.6835\n",
            "Epoch 148/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1565 - auc: 0.6802 - val_loss: 0.1628 - val_auc: 0.6826\n",
            "Epoch 149/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1565 - auc: 0.6799 - val_loss: 0.1628 - val_auc: 0.6826\n",
            "Epoch 150/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1565 - auc: 0.6800 - val_loss: 0.1627 - val_auc: 0.6822\n",
            "Epoch 151/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1565 - auc: 0.6799 - val_loss: 0.1627 - val_auc: 0.6822\n",
            "Epoch 152/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1565 - auc: 0.6798 - val_loss: 0.1627 - val_auc: 0.6820\n",
            "Epoch 153/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1565 - auc: 0.6800 - val_loss: 0.1627 - val_auc: 0.6814\n",
            "Epoch 154/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1564 - auc: 0.6798 - val_loss: 0.1627 - val_auc: 0.6818\n",
            "Epoch 155/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1564 - auc: 0.6798 - val_loss: 0.1627 - val_auc: 0.6821\n",
            "Epoch 156/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1564 - auc: 0.6800 - val_loss: 0.1627 - val_auc: 0.6812\n",
            "Epoch 157/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1564 - auc: 0.6802 - val_loss: 0.1627 - val_auc: 0.6813\n",
            "Epoch 158/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1564 - auc: 0.6800 - val_loss: 0.1627 - val_auc: 0.6814\n",
            "Epoch 159/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1564 - auc: 0.6801 - val_loss: 0.1627 - val_auc: 0.6816\n",
            "Epoch 160/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1564 - auc: 0.6794 - val_loss: 0.1627 - val_auc: 0.6811\n",
            "Epoch 161/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1564 - auc: 0.6801 - val_loss: 0.1627 - val_auc: 0.6812\n",
            "Epoch 162/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1564 - auc: 0.6800 - val_loss: 0.1626 - val_auc: 0.6815\n",
            "Epoch 163/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1564 - auc: 0.6802 - val_loss: 0.1626 - val_auc: 0.6818\n",
            "Epoch 164/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1564 - auc: 0.6805 - val_loss: 0.1626 - val_auc: 0.6819\n",
            "Epoch 165/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1564 - auc: 0.6807 - val_loss: 0.1626 - val_auc: 0.6821\n",
            "Epoch 166/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1564 - auc: 0.6806 - val_loss: 0.1626 - val_auc: 0.6822\n",
            "Epoch 167/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1563 - auc: 0.6802 - val_loss: 0.1626 - val_auc: 0.6824\n",
            "Epoch 168/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6800 - val_loss: 0.1626 - val_auc: 0.6822\n",
            "Epoch 169/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1563 - auc: 0.6798 - val_loss: 0.1626 - val_auc: 0.6821\n",
            "Epoch 170/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6796 - val_loss: 0.1626 - val_auc: 0.6823\n",
            "Epoch 171/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6797 - val_loss: 0.1626 - val_auc: 0.6822\n",
            "Epoch 172/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1563 - auc: 0.6798 - val_loss: 0.1626 - val_auc: 0.6826\n",
            "Epoch 173/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6802 - val_loss: 0.1626 - val_auc: 0.6826\n",
            "Epoch 174/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1563 - auc: 0.6803 - val_loss: 0.1626 - val_auc: 0.6823\n",
            "Epoch 175/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6804 - val_loss: 0.1625 - val_auc: 0.6827\n",
            "Epoch 176/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6800 - val_loss: 0.1625 - val_auc: 0.6829\n",
            "Epoch 177/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1563 - auc: 0.6800 - val_loss: 0.1625 - val_auc: 0.6825\n",
            "Epoch 178/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6793 - val_loss: 0.1625 - val_auc: 0.6829\n",
            "Epoch 179/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6796 - val_loss: 0.1625 - val_auc: 0.6828\n",
            "Epoch 180/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1563 - auc: 0.6794 - val_loss: 0.1625 - val_auc: 0.6826\n",
            "Epoch 181/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1562 - auc: 0.6793 - val_loss: 0.1625 - val_auc: 0.6828\n",
            "Epoch 182/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6795 - val_loss: 0.1625 - val_auc: 0.6836\n",
            "Epoch 183/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6795 - val_loss: 0.1625 - val_auc: 0.6837\n",
            "Epoch 184/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6793 - val_loss: 0.1625 - val_auc: 0.6840\n",
            "Epoch 185/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6795 - val_loss: 0.1625 - val_auc: 0.6833\n",
            "Epoch 186/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6795 - val_loss: 0.1625 - val_auc: 0.6837\n",
            "Epoch 187/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1562 - auc: 0.6792 - val_loss: 0.1625 - val_auc: 0.6838\n",
            "Epoch 188/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1562 - auc: 0.6792 - val_loss: 0.1625 - val_auc: 0.6842\n",
            "Epoch 189/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1562 - auc: 0.6792 - val_loss: 0.1625 - val_auc: 0.6843\n",
            "Epoch 190/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6794 - val_loss: 0.1624 - val_auc: 0.6847\n",
            "Epoch 191/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6788 - val_loss: 0.1624 - val_auc: 0.6849\n",
            "Epoch 192/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6789 - val_loss: 0.1624 - val_auc: 0.6846\n",
            "Epoch 193/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6789 - val_loss: 0.1624 - val_auc: 0.6842\n",
            "Epoch 194/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6790 - val_loss: 0.1624 - val_auc: 0.6846\n",
            "Epoch 195/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1562 - auc: 0.6790 - val_loss: 0.1624 - val_auc: 0.6839\n",
            "Epoch 196/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6793 - val_loss: 0.1624 - val_auc: 0.6841\n",
            "Epoch 197/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1561 - auc: 0.6787 - val_loss: 0.1624 - val_auc: 0.6836\n",
            "Epoch 198/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6787 - val_loss: 0.1624 - val_auc: 0.6832\n",
            "Epoch 199/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1561 - auc: 0.6793 - val_loss: 0.1624 - val_auc: 0.6833\n",
            "Epoch 200/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6788 - val_loss: 0.1624 - val_auc: 0.6835\n",
            "Epoch 201/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6788 - val_loss: 0.1624 - val_auc: 0.6841\n",
            "Epoch 202/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6789 - val_loss: 0.1624 - val_auc: 0.6842\n",
            "Epoch 203/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6795 - val_loss: 0.1624 - val_auc: 0.6847\n",
            "Epoch 204/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6793 - val_loss: 0.1624 - val_auc: 0.6839\n",
            "Epoch 205/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1561 - auc: 0.6794 - val_loss: 0.1623 - val_auc: 0.6843\n",
            "Epoch 206/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6798 - val_loss: 0.1623 - val_auc: 0.6844\n",
            "Epoch 207/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1561 - auc: 0.6797 - val_loss: 0.1623 - val_auc: 0.6845\n",
            "Epoch 208/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6799 - val_loss: 0.1623 - val_auc: 0.6846\n",
            "Epoch 209/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1561 - auc: 0.6797 - val_loss: 0.1623 - val_auc: 0.6848\n",
            "Epoch 210/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1561 - auc: 0.6798 - val_loss: 0.1623 - val_auc: 0.6845\n",
            "Epoch 211/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6795 - val_loss: 0.1623 - val_auc: 0.6851\n",
            "Epoch 212/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6797 - val_loss: 0.1623 - val_auc: 0.6851\n",
            "Epoch 213/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6797 - val_loss: 0.1623 - val_auc: 0.6851\n",
            "Epoch 214/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1560 - auc: 0.6795 - val_loss: 0.1623 - val_auc: 0.6855\n",
            "Epoch 215/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6795 - val_loss: 0.1623 - val_auc: 0.6857\n",
            "Epoch 216/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6799 - val_loss: 0.1623 - val_auc: 0.6858\n",
            "Epoch 217/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1560 - auc: 0.6796 - val_loss: 0.1623 - val_auc: 0.6859\n",
            "Epoch 218/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6797 - val_loss: 0.1623 - val_auc: 0.6860\n",
            "Epoch 219/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6797 - val_loss: 0.1623 - val_auc: 0.6861\n",
            "Epoch 220/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1560 - auc: 0.6795 - val_loss: 0.1623 - val_auc: 0.6855\n",
            "Epoch 221/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6794 - val_loss: 0.1623 - val_auc: 0.6853\n",
            "Epoch 222/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1560 - auc: 0.6795 - val_loss: 0.1622 - val_auc: 0.6853\n",
            "Epoch 223/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6794 - val_loss: 0.1622 - val_auc: 0.6853\n",
            "Epoch 224/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1560 - auc: 0.6794 - val_loss: 0.1622 - val_auc: 0.6848\n",
            "Epoch 225/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6798 - val_loss: 0.1622 - val_auc: 0.6849\n",
            "Epoch 226/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6799 - val_loss: 0.1622 - val_auc: 0.6848\n",
            "Epoch 227/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1560 - auc: 0.6798 - val_loss: 0.1622 - val_auc: 0.6850\n",
            "Epoch 228/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1559 - auc: 0.6794 - val_loss: 0.1622 - val_auc: 0.6849\n",
            "Epoch 229/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6798 - val_loss: 0.1622 - val_auc: 0.6851\n",
            "Epoch 230/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1559 - auc: 0.6800 - val_loss: 0.1622 - val_auc: 0.6851\n",
            "Epoch 231/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1559 - auc: 0.6796 - val_loss: 0.1622 - val_auc: 0.6853\n",
            "Epoch 232/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6802 - val_loss: 0.1622 - val_auc: 0.6853\n",
            "Epoch 233/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6800 - val_loss: 0.1622 - val_auc: 0.6843\n",
            "Epoch 234/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1559 - auc: 0.6801 - val_loss: 0.1622 - val_auc: 0.6845\n",
            "Epoch 235/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6801 - val_loss: 0.1622 - val_auc: 0.6847\n",
            "Epoch 236/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6807 - val_loss: 0.1622 - val_auc: 0.6851\n",
            "Epoch 237/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1559 - auc: 0.6806 - val_loss: 0.1622 - val_auc: 0.6853\n",
            "Epoch 238/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6810 - val_loss: 0.1622 - val_auc: 0.6855\n",
            "Epoch 239/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6811 - val_loss: 0.1621 - val_auc: 0.6856\n",
            "Epoch 240/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6813 - val_loss: 0.1621 - val_auc: 0.6857\n",
            "Epoch 241/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1559 - auc: 0.6814 - val_loss: 0.1621 - val_auc: 0.6862\n",
            "Epoch 242/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1559 - auc: 0.6814 - val_loss: 0.1621 - val_auc: 0.6861\n",
            "Epoch 243/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1559 - auc: 0.6817 - val_loss: 0.1621 - val_auc: 0.6857\n",
            "Epoch 244/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1559 - auc: 0.6813 - val_loss: 0.1621 - val_auc: 0.6854\n",
            "Epoch 245/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1558 - auc: 0.6815 - val_loss: 0.1621 - val_auc: 0.6856\n",
            "Epoch 246/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1558 - auc: 0.6818 - val_loss: 0.1621 - val_auc: 0.6856\n",
            "Epoch 247/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6812 - val_loss: 0.1621 - val_auc: 0.6856\n",
            "Epoch 248/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1558 - auc: 0.6815 - val_loss: 0.1621 - val_auc: 0.6857\n",
            "Epoch 249/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6812 - val_loss: 0.1621 - val_auc: 0.6858\n",
            "Epoch 250/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6812 - val_loss: 0.1621 - val_auc: 0.6860\n",
            "Epoch 251/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1558 - auc: 0.6812 - val_loss: 0.1621 - val_auc: 0.6863\n",
            "Epoch 252/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6814 - val_loss: 0.1621 - val_auc: 0.6863\n",
            "Epoch 253/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6815 - val_loss: 0.1621 - val_auc: 0.6865\n",
            "Epoch 254/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6813 - val_loss: 0.1621 - val_auc: 0.6866\n",
            "Epoch 255/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6815 - val_loss: 0.1621 - val_auc: 0.6871\n",
            "Epoch 256/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6816 - val_loss: 0.1621 - val_auc: 0.6870\n",
            "Epoch 257/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6818 - val_loss: 0.1621 - val_auc: 0.6868\n",
            "Epoch 258/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6816 - val_loss: 0.1620 - val_auc: 0.6869\n",
            "Epoch 259/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6818 - val_loss: 0.1620 - val_auc: 0.6870\n",
            "Epoch 260/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1558 - auc: 0.6818 - val_loss: 0.1620 - val_auc: 0.6872\n",
            "Epoch 261/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6818 - val_loss: 0.1620 - val_auc: 0.6874\n",
            "Epoch 262/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1558 - auc: 0.6818 - val_loss: 0.1620 - val_auc: 0.6876\n",
            "Epoch 263/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1558 - auc: 0.6819 - val_loss: 0.1620 - val_auc: 0.6879\n",
            "Epoch 264/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1557 - auc: 0.6820 - val_loss: 0.1620 - val_auc: 0.6876\n",
            "Epoch 265/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1557 - auc: 0.6821 - val_loss: 0.1620 - val_auc: 0.6875\n",
            "Epoch 266/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6818 - val_loss: 0.1620 - val_auc: 0.6875\n",
            "Epoch 267/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6818 - val_loss: 0.1620 - val_auc: 0.6876\n",
            "Epoch 268/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1557 - auc: 0.6817 - val_loss: 0.1620 - val_auc: 0.6873\n",
            "Epoch 269/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6821 - val_loss: 0.1620 - val_auc: 0.6876\n",
            "Epoch 270/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1557 - auc: 0.6820 - val_loss: 0.1620 - val_auc: 0.6871\n",
            "Epoch 271/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6821 - val_loss: 0.1620 - val_auc: 0.6862\n",
            "Epoch 272/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1557 - auc: 0.6819 - val_loss: 0.1620 - val_auc: 0.6864\n",
            "Epoch 273/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1557 - auc: 0.6820 - val_loss: 0.1620 - val_auc: 0.6864\n",
            "Epoch 274/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1557 - auc: 0.6819 - val_loss: 0.1620 - val_auc: 0.6859\n",
            "Epoch 275/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6820 - val_loss: 0.1620 - val_auc: 0.6859\n",
            "Epoch 276/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1557 - auc: 0.6821 - val_loss: 0.1620 - val_auc: 0.6857\n",
            "Epoch 277/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6822 - val_loss: 0.1619 - val_auc: 0.6859\n",
            "Epoch 278/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6823 - val_loss: 0.1619 - val_auc: 0.6855\n",
            "Epoch 279/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6827 - val_loss: 0.1619 - val_auc: 0.6855\n",
            "Epoch 280/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6825 - val_loss: 0.1619 - val_auc: 0.6853\n",
            "Epoch 281/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6827 - val_loss: 0.1619 - val_auc: 0.6853\n",
            "Epoch 282/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1557 - auc: 0.6827 - val_loss: 0.1619 - val_auc: 0.6855\n",
            "Epoch 283/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1557 - auc: 0.6824 - val_loss: 0.1619 - val_auc: 0.6855\n",
            "Epoch 284/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1556 - auc: 0.6826 - val_loss: 0.1619 - val_auc: 0.6855\n",
            "Epoch 285/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1556 - auc: 0.6829 - val_loss: 0.1619 - val_auc: 0.6851\n",
            "Epoch 286/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6826 - val_loss: 0.1619 - val_auc: 0.6851\n",
            "Epoch 287/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6824 - val_loss: 0.1619 - val_auc: 0.6852\n",
            "Epoch 288/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6825 - val_loss: 0.1619 - val_auc: 0.6854\n",
            "Epoch 289/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6828 - val_loss: 0.1619 - val_auc: 0.6855\n",
            "Epoch 290/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1556 - auc: 0.6828 - val_loss: 0.1619 - val_auc: 0.6856\n",
            "Epoch 291/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1556 - auc: 0.6832 - val_loss: 0.1619 - val_auc: 0.6858\n",
            "Epoch 292/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6830 - val_loss: 0.1619 - val_auc: 0.6859\n",
            "Epoch 293/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6835 - val_loss: 0.1619 - val_auc: 0.6859\n",
            "Epoch 294/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1556 - auc: 0.6833 - val_loss: 0.1619 - val_auc: 0.6863\n",
            "Epoch 295/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1556 - auc: 0.6834 - val_loss: 0.1619 - val_auc: 0.6867\n",
            "Epoch 296/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1556 - auc: 0.6836 - val_loss: 0.1619 - val_auc: 0.6869\n",
            "Epoch 297/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1556 - auc: 0.6839 - val_loss: 0.1619 - val_auc: 0.6869\n",
            "Epoch 298/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6839 - val_loss: 0.1618 - val_auc: 0.6871\n",
            "Epoch 299/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6839 - val_loss: 0.1618 - val_auc: 0.6872\n",
            "Epoch 300/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6837 - val_loss: 0.1618 - val_auc: 0.6867\n",
            "Epoch 301/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6839 - val_loss: 0.1618 - val_auc: 0.6867\n",
            "Epoch 302/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1556 - auc: 0.6838 - val_loss: 0.1618 - val_auc: 0.6867\n",
            "Epoch 303/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6835 - val_loss: 0.1618 - val_auc: 0.6863\n",
            "Epoch 304/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1556 - auc: 0.6839 - val_loss: 0.1618 - val_auc: 0.6864\n",
            "Epoch 305/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1555 - auc: 0.6839 - val_loss: 0.1618 - val_auc: 0.6865\n",
            "Epoch 306/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1555 - auc: 0.6837 - val_loss: 0.1618 - val_auc: 0.6861\n",
            "Epoch 307/500\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1555 - auc: 0.6839 - val_loss: 0.1618 - val_auc: 0.6862\n",
            "Epoch 308/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1555 - auc: 0.6839 - val_loss: 0.1618 - val_auc: 0.6862\n",
            "Epoch 309/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6839 - val_loss: 0.1618 - val_auc: 0.6864\n",
            "Epoch 310/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6840 - val_loss: 0.1618 - val_auc: 0.6862\n",
            "Epoch 311/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1555 - auc: 0.6840 - val_loss: 0.1618 - val_auc: 0.6858\n",
            "Epoch 312/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6841 - val_loss: 0.1618 - val_auc: 0.6860\n",
            "Epoch 313/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6841 - val_loss: 0.1618 - val_auc: 0.6861\n",
            "Epoch 314/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6844 - val_loss: 0.1618 - val_auc: 0.6862\n",
            "Epoch 315/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1555 - auc: 0.6845 - val_loss: 0.1618 - val_auc: 0.6864\n",
            "Epoch 316/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1555 - auc: 0.6843 - val_loss: 0.1618 - val_auc: 0.6864\n",
            "Epoch 317/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6845 - val_loss: 0.1618 - val_auc: 0.6865\n",
            "Epoch 318/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6847 - val_loss: 0.1618 - val_auc: 0.6866\n",
            "Epoch 319/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6846 - val_loss: 0.1618 - val_auc: 0.6869\n",
            "Epoch 320/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6844 - val_loss: 0.1618 - val_auc: 0.6870\n",
            "Epoch 321/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6848 - val_loss: 0.1617 - val_auc: 0.6872\n",
            "Epoch 322/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1555 - auc: 0.6849 - val_loss: 0.1617 - val_auc: 0.6872\n",
            "Epoch 323/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6850 - val_loss: 0.1617 - val_auc: 0.6872\n",
            "Epoch 324/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6849 - val_loss: 0.1617 - val_auc: 0.6873\n",
            "Epoch 325/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6851 - val_loss: 0.1617 - val_auc: 0.6870\n",
            "Epoch 326/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1555 - auc: 0.6849 - val_loss: 0.1617 - val_auc: 0.6874\n",
            "Epoch 327/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1555 - auc: 0.6850 - val_loss: 0.1617 - val_auc: 0.6873\n",
            "Epoch 328/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6850 - val_loss: 0.1617 - val_auc: 0.6873\n",
            "Epoch 329/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6849 - val_loss: 0.1617 - val_auc: 0.6873\n",
            "Epoch 330/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6852 - val_loss: 0.1617 - val_auc: 0.6877\n",
            "Epoch 331/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6854 - val_loss: 0.1617 - val_auc: 0.6880\n",
            "Epoch 332/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6853 - val_loss: 0.1617 - val_auc: 0.6877\n",
            "Epoch 333/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6854 - val_loss: 0.1617 - val_auc: 0.6879\n",
            "Epoch 334/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6855 - val_loss: 0.1617 - val_auc: 0.6881\n",
            "Epoch 335/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6858 - val_loss: 0.1617 - val_auc: 0.6876\n",
            "Epoch 336/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6860 - val_loss: 0.1617 - val_auc: 0.6883\n",
            "Epoch 337/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1554 - auc: 0.6858 - val_loss: 0.1617 - val_auc: 0.6886\n",
            "Epoch 338/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6859 - val_loss: 0.1617 - val_auc: 0.6888\n",
            "Epoch 339/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6858 - val_loss: 0.1617 - val_auc: 0.6883\n",
            "Epoch 340/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6862 - val_loss: 0.1617 - val_auc: 0.6883\n",
            "Epoch 341/500\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.1554 - auc: 0.6860 - val_loss: 0.1617 - val_auc: 0.6884\n",
            "Epoch 342/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1554 - auc: 0.6860 - val_loss: 0.1617 - val_auc: 0.6884\n",
            "Epoch 343/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6861 - val_loss: 0.1617 - val_auc: 0.6881\n",
            "Epoch 344/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6859 - val_loss: 0.1617 - val_auc: 0.6885\n",
            "Epoch 345/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6861 - val_loss: 0.1617 - val_auc: 0.6884\n",
            "Epoch 346/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6861 - val_loss: 0.1616 - val_auc: 0.6886\n",
            "Epoch 347/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6863 - val_loss: 0.1616 - val_auc: 0.6886\n",
            "Epoch 348/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6864 - val_loss: 0.1616 - val_auc: 0.6882\n",
            "Epoch 349/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6861 - val_loss: 0.1616 - val_auc: 0.6883\n",
            "Epoch 350/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1554 - auc: 0.6860 - val_loss: 0.1616 - val_auc: 0.6879\n",
            "Epoch 351/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1554 - auc: 0.6862 - val_loss: 0.1616 - val_auc: 0.6883\n",
            "Epoch 352/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1554 - auc: 0.6863 - val_loss: 0.1616 - val_auc: 0.6885\n",
            "Epoch 353/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6859 - val_loss: 0.1616 - val_auc: 0.6885\n",
            "Epoch 354/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1553 - auc: 0.6865 - val_loss: 0.1616 - val_auc: 0.6882\n",
            "Epoch 355/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6864 - val_loss: 0.1616 - val_auc: 0.6882\n",
            "Epoch 356/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6866 - val_loss: 0.1616 - val_auc: 0.6878\n",
            "Epoch 357/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1553 - auc: 0.6864 - val_loss: 0.1616 - val_auc: 0.6882\n",
            "Epoch 358/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6868 - val_loss: 0.1616 - val_auc: 0.6883\n",
            "Epoch 359/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1553 - auc: 0.6866 - val_loss: 0.1616 - val_auc: 0.6884\n",
            "Epoch 360/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6864 - val_loss: 0.1616 - val_auc: 0.6887\n",
            "Epoch 361/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6868 - val_loss: 0.1616 - val_auc: 0.6883\n",
            "Epoch 362/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6868 - val_loss: 0.1616 - val_auc: 0.6883\n",
            "Epoch 363/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1553 - auc: 0.6871 - val_loss: 0.1616 - val_auc: 0.6879\n",
            "Epoch 364/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6872 - val_loss: 0.1616 - val_auc: 0.6877\n",
            "Epoch 365/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1553 - auc: 0.6872 - val_loss: 0.1616 - val_auc: 0.6878\n",
            "Epoch 366/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6871 - val_loss: 0.1616 - val_auc: 0.6879\n",
            "Epoch 367/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1553 - auc: 0.6873 - val_loss: 0.1616 - val_auc: 0.6881\n",
            "Epoch 368/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6872 - val_loss: 0.1616 - val_auc: 0.6873\n",
            "Epoch 369/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1553 - auc: 0.6872 - val_loss: 0.1616 - val_auc: 0.6877\n",
            "Epoch 370/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6875 - val_loss: 0.1616 - val_auc: 0.6875\n",
            "Epoch 371/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1553 - auc: 0.6875 - val_loss: 0.1616 - val_auc: 0.6876\n",
            "Epoch 372/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6874 - val_loss: 0.1616 - val_auc: 0.6873\n",
            "Epoch 373/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6874 - val_loss: 0.1615 - val_auc: 0.6875\n",
            "Epoch 374/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6874 - val_loss: 0.1615 - val_auc: 0.6878\n",
            "Epoch 375/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6877 - val_loss: 0.1615 - val_auc: 0.6876\n",
            "Epoch 376/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6879 - val_loss: 0.1615 - val_auc: 0.6877\n",
            "Epoch 377/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1553 - auc: 0.6877 - val_loss: 0.1615 - val_auc: 0.6879\n",
            "Epoch 378/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6876 - val_loss: 0.1615 - val_auc: 0.6878\n",
            "Epoch 379/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1553 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6881\n",
            "Epoch 380/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6880 - val_loss: 0.1615 - val_auc: 0.6883\n",
            "Epoch 381/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6880 - val_loss: 0.1615 - val_auc: 0.6884\n",
            "Epoch 382/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6885\n",
            "Epoch 383/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6877 - val_loss: 0.1615 - val_auc: 0.6887\n",
            "Epoch 384/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1552 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6890\n",
            "Epoch 385/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6874 - val_loss: 0.1615 - val_auc: 0.6890\n",
            "Epoch 386/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6879 - val_loss: 0.1615 - val_auc: 0.6893\n",
            "Epoch 387/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6892\n",
            "Epoch 388/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6876 - val_loss: 0.1615 - val_auc: 0.6892\n",
            "Epoch 389/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6888\n",
            "Epoch 390/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6888\n",
            "Epoch 391/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1552 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6887\n",
            "Epoch 392/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6890\n",
            "Epoch 393/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1552 - auc: 0.6879 - val_loss: 0.1615 - val_auc: 0.6890\n",
            "Epoch 394/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6881 - val_loss: 0.1615 - val_auc: 0.6893\n",
            "Epoch 395/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6880 - val_loss: 0.1615 - val_auc: 0.6893\n",
            "Epoch 396/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6881 - val_loss: 0.1615 - val_auc: 0.6893\n",
            "Epoch 397/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6883 - val_loss: 0.1615 - val_auc: 0.6892\n",
            "Epoch 398/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6878 - val_loss: 0.1615 - val_auc: 0.6892\n",
            "Epoch 399/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6881 - val_loss: 0.1615 - val_auc: 0.6893\n",
            "Epoch 400/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6884 - val_loss: 0.1615 - val_auc: 0.6890\n",
            "Epoch 401/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6885 - val_loss: 0.1615 - val_auc: 0.6887\n",
            "Epoch 402/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6883 - val_loss: 0.1615 - val_auc: 0.6888\n",
            "Epoch 403/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6884 - val_loss: 0.1614 - val_auc: 0.6889\n",
            "Epoch 404/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6884 - val_loss: 0.1614 - val_auc: 0.6885\n",
            "Epoch 405/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1552 - auc: 0.6881 - val_loss: 0.1614 - val_auc: 0.6881\n",
            "Epoch 406/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6885 - val_loss: 0.1614 - val_auc: 0.6880\n",
            "Epoch 407/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1552 - auc: 0.6886 - val_loss: 0.1614 - val_auc: 0.6882\n",
            "Epoch 408/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1551 - auc: 0.6886 - val_loss: 0.1614 - val_auc: 0.6883\n",
            "Epoch 409/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6883 - val_loss: 0.1614 - val_auc: 0.6885\n",
            "Epoch 410/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6885 - val_loss: 0.1614 - val_auc: 0.6888\n",
            "Epoch 411/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6887 - val_loss: 0.1614 - val_auc: 0.6890\n",
            "Epoch 412/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6886 - val_loss: 0.1614 - val_auc: 0.6891\n",
            "Epoch 413/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6886 - val_loss: 0.1614 - val_auc: 0.6891\n",
            "Epoch 414/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6886 - val_loss: 0.1614 - val_auc: 0.6894\n",
            "Epoch 415/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6885 - val_loss: 0.1614 - val_auc: 0.6896\n",
            "Epoch 416/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6884 - val_loss: 0.1614 - val_auc: 0.6895\n",
            "Epoch 417/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6888 - val_loss: 0.1614 - val_auc: 0.6896\n",
            "Epoch 418/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1551 - auc: 0.6887 - val_loss: 0.1614 - val_auc: 0.6897\n",
            "Epoch 419/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6888 - val_loss: 0.1614 - val_auc: 0.6899\n",
            "Epoch 420/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6888 - val_loss: 0.1614 - val_auc: 0.6899\n",
            "Epoch 421/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6891 - val_loss: 0.1614 - val_auc: 0.6900\n",
            "Epoch 422/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6890 - val_loss: 0.1614 - val_auc: 0.6899\n",
            "Epoch 423/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6890 - val_loss: 0.1614 - val_auc: 0.6902\n",
            "Epoch 424/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6890 - val_loss: 0.1614 - val_auc: 0.6903\n",
            "Epoch 425/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1551 - auc: 0.6891 - val_loss: 0.1614 - val_auc: 0.6903\n",
            "Epoch 426/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1551 - auc: 0.6888 - val_loss: 0.1614 - val_auc: 0.6904\n",
            "Epoch 427/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1551 - auc: 0.6891 - val_loss: 0.1614 - val_auc: 0.6903\n",
            "Epoch 428/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1551 - auc: 0.6891 - val_loss: 0.1614 - val_auc: 0.6902\n",
            "Epoch 429/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6892 - val_loss: 0.1614 - val_auc: 0.6904\n",
            "Epoch 430/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6891 - val_loss: 0.1614 - val_auc: 0.6900\n",
            "Epoch 431/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6891 - val_loss: 0.1614 - val_auc: 0.6902\n",
            "Epoch 432/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6892 - val_loss: 0.1614 - val_auc: 0.6904\n",
            "Epoch 433/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6891 - val_loss: 0.1614 - val_auc: 0.6904\n",
            "Epoch 434/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6892 - val_loss: 0.1614 - val_auc: 0.6907\n",
            "Epoch 435/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1551 - auc: 0.6895 - val_loss: 0.1613 - val_auc: 0.6906\n",
            "Epoch 436/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1551 - auc: 0.6895 - val_loss: 0.1613 - val_auc: 0.6906\n",
            "Epoch 437/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6892 - val_loss: 0.1613 - val_auc: 0.6908\n",
            "Epoch 438/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1551 - auc: 0.6894 - val_loss: 0.1613 - val_auc: 0.6909\n",
            "Epoch 439/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6892 - val_loss: 0.1613 - val_auc: 0.6912\n",
            "Epoch 440/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6895 - val_loss: 0.1613 - val_auc: 0.6909\n",
            "Epoch 441/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6896 - val_loss: 0.1613 - val_auc: 0.6911\n",
            "Epoch 442/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6896 - val_loss: 0.1613 - val_auc: 0.6910\n",
            "Epoch 443/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6895 - val_loss: 0.1613 - val_auc: 0.6911\n",
            "Epoch 444/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6897 - val_loss: 0.1613 - val_auc: 0.6912\n",
            "Epoch 445/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6895 - val_loss: 0.1613 - val_auc: 0.6913\n",
            "Epoch 446/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1550 - auc: 0.6897 - val_loss: 0.1613 - val_auc: 0.6916\n",
            "Epoch 447/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6898 - val_loss: 0.1613 - val_auc: 0.6916\n",
            "Epoch 448/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6899 - val_loss: 0.1613 - val_auc: 0.6918\n",
            "Epoch 449/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6899 - val_loss: 0.1613 - val_auc: 0.6919\n",
            "Epoch 450/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1550 - auc: 0.6902 - val_loss: 0.1613 - val_auc: 0.6918\n",
            "Epoch 451/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6899 - val_loss: 0.1613 - val_auc: 0.6918\n",
            "Epoch 452/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6900 - val_loss: 0.1613 - val_auc: 0.6919\n",
            "Epoch 453/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6899 - val_loss: 0.1613 - val_auc: 0.6918\n",
            "Epoch 454/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6898 - val_loss: 0.1613 - val_auc: 0.6914\n",
            "Epoch 455/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6900 - val_loss: 0.1613 - val_auc: 0.6918\n",
            "Epoch 456/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6899 - val_loss: 0.1613 - val_auc: 0.6911\n",
            "Epoch 457/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6900 - val_loss: 0.1613 - val_auc: 0.6912\n",
            "Epoch 458/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6902 - val_loss: 0.1613 - val_auc: 0.6912\n",
            "Epoch 459/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1550 - auc: 0.6903 - val_loss: 0.1613 - val_auc: 0.6913\n",
            "Epoch 460/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1550 - auc: 0.6902 - val_loss: 0.1613 - val_auc: 0.6912\n",
            "Epoch 461/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1550 - auc: 0.6904 - val_loss: 0.1613 - val_auc: 0.6913\n",
            "Epoch 462/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1550 - auc: 0.6906 - val_loss: 0.1613 - val_auc: 0.6914\n",
            "Epoch 463/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1550 - auc: 0.6907 - val_loss: 0.1613 - val_auc: 0.6914\n",
            "Epoch 464/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6908 - val_loss: 0.1613 - val_auc: 0.6914\n",
            "Epoch 465/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6904 - val_loss: 0.1613 - val_auc: 0.6913\n",
            "Epoch 466/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6907 - val_loss: 0.1613 - val_auc: 0.6910\n",
            "Epoch 467/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6906 - val_loss: 0.1613 - val_auc: 0.6912\n",
            "Epoch 468/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6906 - val_loss: 0.1613 - val_auc: 0.6911\n",
            "Epoch 469/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6910 - val_loss: 0.1613 - val_auc: 0.6912\n",
            "Epoch 470/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6908 - val_loss: 0.1612 - val_auc: 0.6917\n",
            "Epoch 471/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - auc: 0.6906 - val_loss: 0.1612 - val_auc: 0.6916\n",
            "Epoch 472/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1550 - auc: 0.6906 - val_loss: 0.1612 - val_auc: 0.6917\n",
            "Epoch 473/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1549 - auc: 0.6903 - val_loss: 0.1612 - val_auc: 0.6917\n",
            "Epoch 474/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1549 - auc: 0.6904 - val_loss: 0.1612 - val_auc: 0.6916\n",
            "Epoch 475/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6902 - val_loss: 0.1612 - val_auc: 0.6911\n",
            "Epoch 476/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1549 - auc: 0.6909 - val_loss: 0.1612 - val_auc: 0.6908\n",
            "Epoch 477/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6904 - val_loss: 0.1612 - val_auc: 0.6908\n",
            "Epoch 478/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1549 - auc: 0.6905 - val_loss: 0.1612 - val_auc: 0.6908\n",
            "Epoch 479/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6908 - val_loss: 0.1612 - val_auc: 0.6904\n",
            "Epoch 480/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6907 - val_loss: 0.1612 - val_auc: 0.6905\n",
            "Epoch 481/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6907 - val_loss: 0.1612 - val_auc: 0.6907\n",
            "Epoch 482/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6910 - val_loss: 0.1612 - val_auc: 0.6907\n",
            "Epoch 483/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6910 - val_loss: 0.1612 - val_auc: 0.6908\n",
            "Epoch 484/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6908 - val_loss: 0.1612 - val_auc: 0.6909\n",
            "Epoch 485/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6910 - val_loss: 0.1612 - val_auc: 0.6910\n",
            "Epoch 486/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1549 - auc: 0.6912 - val_loss: 0.1612 - val_auc: 0.6912\n",
            "Epoch 487/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1549 - auc: 0.6912 - val_loss: 0.1612 - val_auc: 0.6916\n",
            "Epoch 488/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1549 - auc: 0.6912 - val_loss: 0.1612 - val_auc: 0.6915\n",
            "Epoch 489/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1549 - auc: 0.6912 - val_loss: 0.1612 - val_auc: 0.6916\n",
            "Epoch 490/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1549 - auc: 0.6913 - val_loss: 0.1612 - val_auc: 0.6917\n",
            "Epoch 491/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1549 - auc: 0.6915 - val_loss: 0.1612 - val_auc: 0.6918\n",
            "Epoch 492/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6916 - val_loss: 0.1612 - val_auc: 0.6919\n",
            "Epoch 493/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6913 - val_loss: 0.1612 - val_auc: 0.6921\n",
            "Epoch 494/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6915 - val_loss: 0.1612 - val_auc: 0.6921\n",
            "Epoch 495/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6918 - val_loss: 0.1612 - val_auc: 0.6921\n",
            "Epoch 496/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1549 - auc: 0.6916 - val_loss: 0.1612 - val_auc: 0.6923\n",
            "Epoch 497/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1549 - auc: 0.6916 - val_loss: 0.1612 - val_auc: 0.6922\n",
            "Epoch 498/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6918 - val_loss: 0.1612 - val_auc: 0.6924\n",
            "Epoch 499/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1549 - auc: 0.6920 - val_loss: 0.1612 - val_auc: 0.6925\n",
            "Epoch 500/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1549 - auc: 0.6920 - val_loss: 0.1612 - val_auc: 0.6926\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "WFNMnIL6ACgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make the model more complex to see how high we can get the accuracy to go with the new things we have learned\n",
        "tf.random.set_seed(42)\n",
        "model2 = keras.models.Sequential([\n",
        "        keras.layers.Dense(60, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "        keras.layers.Dropout(0.5), #drop 50% of the nuerons randomly\n",
        "        keras.layers.Dense(30, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.5), #drop 50% of the nuerons randomly\n",
        "        keras.layers.Dense(18, activation=\"relu\",),\n",
        "        keras.layers.Dropout(0.5), #drop 50% of the nuerons randomly\n",
        "        keras.layers.Dense(9, activation=\"relu\"),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),#output layer\n",
        " ]) \n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "212R3Pmd_gtW",
        "outputId": "c9748514-d3f1-426b-e4dc-9ade2d715474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 60)                20220     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 60)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                1830      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 18)                558       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 18)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 171       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,789\n",
            "Trainable params: 22,789\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
        "              loss=\"binary_crossentropy\", \n",
        "              metrics=[\"AUC\"])"
      ],
      "metadata": {
        "id": "ohKtQXW-_x0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_me= model2.fit(X_train, y_train, epochs=500,\\\n",
        "                    batch_size= 1000, validation_data=(X_valid, y_valid))\n",
        "\n",
        "\n",
        "plt.plot(pd.DataFrame(show_me.history))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_cyreRkf_2p7",
        "outputId": "9ac11cbe-a317-4603-a705-c5be165b451a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "46/46 [==============================] - 2s 15ms/step - loss: 0.3764 - auc: 0.5359 - val_loss: 0.1712 - val_auc: 0.6599\n",
            "Epoch 2/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2314 - auc: 0.5667 - val_loss: 0.1614 - val_auc: 0.6950\n",
            "Epoch 3/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.2046 - auc: 0.6007 - val_loss: 0.1604 - val_auc: 0.7202\n",
            "Epoch 4/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1903 - auc: 0.6388 - val_loss: 0.1593 - val_auc: 0.7516\n",
            "Epoch 5/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1851 - auc: 0.6493 - val_loss: 0.1584 - val_auc: 0.7601\n",
            "Epoch 6/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1777 - auc: 0.6667 - val_loss: 0.1570 - val_auc: 0.7643\n",
            "Epoch 7/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1735 - auc: 0.6756 - val_loss: 0.1553 - val_auc: 0.7712\n",
            "Epoch 8/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1686 - auc: 0.6907 - val_loss: 0.1543 - val_auc: 0.7695\n",
            "Epoch 9/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1679 - auc: 0.6907 - val_loss: 0.1534 - val_auc: 0.7746\n",
            "Epoch 10/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1641 - auc: 0.7019 - val_loss: 0.1526 - val_auc: 0.7758\n",
            "Epoch 11/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1625 - auc: 0.7039 - val_loss: 0.1518 - val_auc: 0.7787\n",
            "Epoch 12/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1587 - auc: 0.7234 - val_loss: 0.1518 - val_auc: 0.7864\n",
            "Epoch 13/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1580 - auc: 0.7224 - val_loss: 0.1502 - val_auc: 0.7881\n",
            "Epoch 14/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1558 - auc: 0.7332 - val_loss: 0.1500 - val_auc: 0.7908\n",
            "Epoch 15/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1543 - auc: 0.7386 - val_loss: 0.1499 - val_auc: 0.7928\n",
            "Epoch 16/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1535 - auc: 0.7452 - val_loss: 0.1502 - val_auc: 0.7942\n",
            "Epoch 17/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1528 - auc: 0.7499 - val_loss: 0.1492 - val_auc: 0.7965\n",
            "Epoch 18/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1522 - auc: 0.7524 - val_loss: 0.1492 - val_auc: 0.7967\n",
            "Epoch 19/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1500 - auc: 0.7633 - val_loss: 0.1483 - val_auc: 0.8013\n",
            "Epoch 20/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1502 - auc: 0.7606 - val_loss: 0.1485 - val_auc: 0.8001\n",
            "Epoch 21/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1501 - auc: 0.7632 - val_loss: 0.1483 - val_auc: 0.8027\n",
            "Epoch 22/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1478 - auc: 0.7754 - val_loss: 0.1487 - val_auc: 0.8016\n",
            "Epoch 23/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1485 - auc: 0.7723 - val_loss: 0.1485 - val_auc: 0.8006\n",
            "Epoch 24/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1475 - auc: 0.7743 - val_loss: 0.1480 - val_auc: 0.8020\n",
            "Epoch 25/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1464 - auc: 0.7811 - val_loss: 0.1480 - val_auc: 0.8018\n",
            "Epoch 26/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1476 - auc: 0.7727 - val_loss: 0.1477 - val_auc: 0.8039\n",
            "Epoch 27/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1464 - auc: 0.7797 - val_loss: 0.1482 - val_auc: 0.8033\n",
            "Epoch 28/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1471 - auc: 0.7755 - val_loss: 0.1476 - val_auc: 0.8050\n",
            "Epoch 29/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1452 - auc: 0.7845 - val_loss: 0.1492 - val_auc: 0.8011\n",
            "Epoch 30/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1449 - auc: 0.7858 - val_loss: 0.1482 - val_auc: 0.8024\n",
            "Epoch 31/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1444 - auc: 0.7895 - val_loss: 0.1478 - val_auc: 0.8055\n",
            "Epoch 32/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1451 - auc: 0.7869 - val_loss: 0.1472 - val_auc: 0.8069\n",
            "Epoch 33/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1446 - auc: 0.7859 - val_loss: 0.1478 - val_auc: 0.8052\n",
            "Epoch 34/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1450 - auc: 0.7878 - val_loss: 0.1481 - val_auc: 0.8032\n",
            "Epoch 35/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1441 - auc: 0.7884 - val_loss: 0.1471 - val_auc: 0.8064\n",
            "Epoch 36/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1433 - auc: 0.7950 - val_loss: 0.1471 - val_auc: 0.8073\n",
            "Epoch 37/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1425 - auc: 0.7988 - val_loss: 0.1481 - val_auc: 0.8029\n",
            "Epoch 38/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1437 - auc: 0.7909 - val_loss: 0.1482 - val_auc: 0.8045\n",
            "Epoch 39/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1434 - auc: 0.7932 - val_loss: 0.1475 - val_auc: 0.8047\n",
            "Epoch 40/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1435 - auc: 0.7929 - val_loss: 0.1473 - val_auc: 0.8051\n",
            "Epoch 41/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1423 - auc: 0.7979 - val_loss: 0.1482 - val_auc: 0.8035\n",
            "Epoch 42/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1425 - auc: 0.7984 - val_loss: 0.1476 - val_auc: 0.8040\n",
            "Epoch 43/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1413 - auc: 0.8042 - val_loss: 0.1474 - val_auc: 0.8081\n",
            "Epoch 44/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1419 - auc: 0.8004 - val_loss: 0.1473 - val_auc: 0.8048\n",
            "Epoch 45/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1416 - auc: 0.8025 - val_loss: 0.1469 - val_auc: 0.8074\n",
            "Epoch 46/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1407 - auc: 0.8054 - val_loss: 0.1474 - val_auc: 0.8066\n",
            "Epoch 47/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1424 - auc: 0.7986 - val_loss: 0.1474 - val_auc: 0.8081\n",
            "Epoch 48/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1412 - auc: 0.8047 - val_loss: 0.1473 - val_auc: 0.8060\n",
            "Epoch 49/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1420 - auc: 0.8013 - val_loss: 0.1477 - val_auc: 0.8037\n",
            "Epoch 50/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1402 - auc: 0.8083 - val_loss: 0.1471 - val_auc: 0.8076\n",
            "Epoch 51/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1412 - auc: 0.8021 - val_loss: 0.1473 - val_auc: 0.8099\n",
            "Epoch 52/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1407 - auc: 0.8048 - val_loss: 0.1478 - val_auc: 0.8065\n",
            "Epoch 53/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1409 - auc: 0.8041 - val_loss: 0.1481 - val_auc: 0.8049\n",
            "Epoch 54/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1404 - auc: 0.8065 - val_loss: 0.1479 - val_auc: 0.8063\n",
            "Epoch 55/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1401 - auc: 0.8082 - val_loss: 0.1472 - val_auc: 0.8083\n",
            "Epoch 56/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1398 - auc: 0.8100 - val_loss: 0.1474 - val_auc: 0.8071\n",
            "Epoch 57/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1403 - auc: 0.8059 - val_loss: 0.1477 - val_auc: 0.8070\n",
            "Epoch 58/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1403 - auc: 0.8071 - val_loss: 0.1475 - val_auc: 0.8079\n",
            "Epoch 59/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1404 - auc: 0.8080 - val_loss: 0.1470 - val_auc: 0.8084\n",
            "Epoch 60/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1397 - auc: 0.8097 - val_loss: 0.1475 - val_auc: 0.8080\n",
            "Epoch 61/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1400 - auc: 0.8062 - val_loss: 0.1474 - val_auc: 0.8065\n",
            "Epoch 62/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1406 - auc: 0.8054 - val_loss: 0.1491 - val_auc: 0.8067\n",
            "Epoch 63/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1407 - auc: 0.8041 - val_loss: 0.1474 - val_auc: 0.8062\n",
            "Epoch 64/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1406 - auc: 0.8062 - val_loss: 0.1489 - val_auc: 0.8053\n",
            "Epoch 65/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1407 - auc: 0.8051 - val_loss: 0.1478 - val_auc: 0.8051\n",
            "Epoch 66/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1405 - auc: 0.8059 - val_loss: 0.1482 - val_auc: 0.8095\n",
            "Epoch 67/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1398 - auc: 0.8097 - val_loss: 0.1472 - val_auc: 0.8081\n",
            "Epoch 68/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1401 - auc: 0.8072 - val_loss: 0.1499 - val_auc: 0.8018\n",
            "Epoch 69/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1407 - auc: 0.8052 - val_loss: 0.1492 - val_auc: 0.8045\n",
            "Epoch 70/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1399 - auc: 0.8102 - val_loss: 0.1485 - val_auc: 0.8097\n",
            "Epoch 71/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1394 - auc: 0.8113 - val_loss: 0.1476 - val_auc: 0.8061\n",
            "Epoch 72/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1389 - auc: 0.8133 - val_loss: 0.1470 - val_auc: 0.8087\n",
            "Epoch 73/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1402 - auc: 0.8082 - val_loss: 0.1490 - val_auc: 0.8054\n",
            "Epoch 74/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1389 - auc: 0.8138 - val_loss: 0.1473 - val_auc: 0.8075\n",
            "Epoch 75/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1389 - auc: 0.8139 - val_loss: 0.1474 - val_auc: 0.8060\n",
            "Epoch 76/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1390 - auc: 0.8127 - val_loss: 0.1480 - val_auc: 0.8066\n",
            "Epoch 77/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1388 - auc: 0.8124 - val_loss: 0.1475 - val_auc: 0.8079\n",
            "Epoch 78/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1390 - auc: 0.8137 - val_loss: 0.1485 - val_auc: 0.8067\n",
            "Epoch 79/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1396 - auc: 0.8104 - val_loss: 0.1483 - val_auc: 0.8036\n",
            "Epoch 80/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1385 - auc: 0.8146 - val_loss: 0.1478 - val_auc: 0.8073\n",
            "Epoch 81/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1394 - auc: 0.8096 - val_loss: 0.1476 - val_auc: 0.8062\n",
            "Epoch 82/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1390 - auc: 0.8145 - val_loss: 0.1483 - val_auc: 0.8051\n",
            "Epoch 83/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1380 - auc: 0.8175 - val_loss: 0.1483 - val_auc: 0.8034\n",
            "Epoch 84/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1384 - auc: 0.8142 - val_loss: 0.1485 - val_auc: 0.8057\n",
            "Epoch 85/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1393 - auc: 0.8122 - val_loss: 0.1485 - val_auc: 0.8036\n",
            "Epoch 86/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1383 - auc: 0.8159 - val_loss: 0.1482 - val_auc: 0.8059\n",
            "Epoch 87/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1385 - auc: 0.8149 - val_loss: 0.1530 - val_auc: 0.8040\n",
            "Epoch 88/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1385 - auc: 0.8158 - val_loss: 0.1497 - val_auc: 0.8079\n",
            "Epoch 89/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1380 - auc: 0.8182 - val_loss: 0.1494 - val_auc: 0.8061\n",
            "Epoch 90/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1391 - auc: 0.8125 - val_loss: 0.1477 - val_auc: 0.8065\n",
            "Epoch 91/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1384 - auc: 0.8155 - val_loss: 0.1480 - val_auc: 0.8053\n",
            "Epoch 92/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1388 - auc: 0.8143 - val_loss: 0.1497 - val_auc: 0.8053\n",
            "Epoch 93/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1383 - auc: 0.8152 - val_loss: 0.1500 - val_auc: 0.8053\n",
            "Epoch 94/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1379 - auc: 0.8171 - val_loss: 0.1494 - val_auc: 0.8070\n",
            "Epoch 95/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1385 - auc: 0.8147 - val_loss: 0.1509 - val_auc: 0.8045\n",
            "Epoch 96/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1375 - auc: 0.8191 - val_loss: 0.1479 - val_auc: 0.8063\n",
            "Epoch 97/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1382 - auc: 0.8177 - val_loss: 0.1496 - val_auc: 0.8042\n",
            "Epoch 98/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1380 - auc: 0.8180 - val_loss: 0.1489 - val_auc: 0.8052\n",
            "Epoch 99/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1375 - auc: 0.8193 - val_loss: 0.1501 - val_auc: 0.8042\n",
            "Epoch 100/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1381 - auc: 0.8155 - val_loss: 0.1481 - val_auc: 0.8054\n",
            "Epoch 101/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1389 - auc: 0.8131 - val_loss: 0.1504 - val_auc: 0.8068\n",
            "Epoch 102/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1382 - auc: 0.8159 - val_loss: 0.1507 - val_auc: 0.8057\n",
            "Epoch 103/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1388 - auc: 0.8150 - val_loss: 0.1514 - val_auc: 0.8062\n",
            "Epoch 104/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1381 - auc: 0.8169 - val_loss: 0.1496 - val_auc: 0.8081\n",
            "Epoch 105/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1372 - auc: 0.8210 - val_loss: 0.1508 - val_auc: 0.8057\n",
            "Epoch 106/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1379 - auc: 0.8178 - val_loss: 0.1491 - val_auc: 0.8056\n",
            "Epoch 107/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1382 - auc: 0.8141 - val_loss: 0.1521 - val_auc: 0.8038\n",
            "Epoch 108/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1376 - auc: 0.8187 - val_loss: 0.1489 - val_auc: 0.8030\n",
            "Epoch 109/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1370 - auc: 0.8215 - val_loss: 0.1498 - val_auc: 0.8031\n",
            "Epoch 110/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1373 - auc: 0.8214 - val_loss: 0.1516 - val_auc: 0.8027\n",
            "Epoch 111/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1374 - auc: 0.8183 - val_loss: 0.1492 - val_auc: 0.8054\n",
            "Epoch 112/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1372 - auc: 0.8206 - val_loss: 0.1494 - val_auc: 0.8017\n",
            "Epoch 113/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1379 - auc: 0.8151 - val_loss: 0.1495 - val_auc: 0.8005\n",
            "Epoch 114/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1374 - auc: 0.8181 - val_loss: 0.1518 - val_auc: 0.8041\n",
            "Epoch 115/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1369 - auc: 0.8206 - val_loss: 0.1503 - val_auc: 0.8040\n",
            "Epoch 116/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1365 - auc: 0.8210 - val_loss: 0.1490 - val_auc: 0.8056\n",
            "Epoch 117/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1372 - auc: 0.8208 - val_loss: 0.1518 - val_auc: 0.8031\n",
            "Epoch 118/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1363 - auc: 0.8228 - val_loss: 0.1490 - val_auc: 0.8052\n",
            "Epoch 119/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1369 - auc: 0.8206 - val_loss: 0.1497 - val_auc: 0.8042\n",
            "Epoch 120/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1358 - auc: 0.8267 - val_loss: 0.1492 - val_auc: 0.8028\n",
            "Epoch 121/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1370 - auc: 0.8202 - val_loss: 0.1510 - val_auc: 0.8006\n",
            "Epoch 122/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1359 - auc: 0.8240 - val_loss: 0.1501 - val_auc: 0.8022\n",
            "Epoch 123/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1368 - auc: 0.8218 - val_loss: 0.1498 - val_auc: 0.8025\n",
            "Epoch 124/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1373 - auc: 0.8186 - val_loss: 0.1489 - val_auc: 0.8021\n",
            "Epoch 125/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1368 - auc: 0.8207 - val_loss: 0.1489 - val_auc: 0.8023\n",
            "Epoch 126/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1366 - auc: 0.8226 - val_loss: 0.1504 - val_auc: 0.8011\n",
            "Epoch 127/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1364 - auc: 0.8225 - val_loss: 0.1506 - val_auc: 0.8033\n",
            "Epoch 128/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1361 - auc: 0.8235 - val_loss: 0.1510 - val_auc: 0.8041\n",
            "Epoch 129/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1367 - auc: 0.8190 - val_loss: 0.1491 - val_auc: 0.8031\n",
            "Epoch 130/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1372 - auc: 0.8193 - val_loss: 0.1492 - val_auc: 0.8034\n",
            "Epoch 131/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1366 - auc: 0.8228 - val_loss: 0.1512 - val_auc: 0.8020\n",
            "Epoch 132/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1362 - auc: 0.8240 - val_loss: 0.1498 - val_auc: 0.8056\n",
            "Epoch 133/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1359 - auc: 0.8251 - val_loss: 0.1497 - val_auc: 0.8031\n",
            "Epoch 134/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1362 - auc: 0.8233 - val_loss: 0.1514 - val_auc: 0.8026\n",
            "Epoch 135/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1364 - auc: 0.8223 - val_loss: 0.1505 - val_auc: 0.8010\n",
            "Epoch 136/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1363 - auc: 0.8249 - val_loss: 0.1501 - val_auc: 0.8017\n",
            "Epoch 137/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1356 - auc: 0.8268 - val_loss: 0.1497 - val_auc: 0.8030\n",
            "Epoch 138/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1357 - auc: 0.8238 - val_loss: 0.1506 - val_auc: 0.8029\n",
            "Epoch 139/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1354 - auc: 0.8246 - val_loss: 0.1531 - val_auc: 0.8013\n",
            "Epoch 140/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1358 - auc: 0.8267 - val_loss: 0.1532 - val_auc: 0.8010\n",
            "Epoch 141/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1355 - auc: 0.8249 - val_loss: 0.1494 - val_auc: 0.8044\n",
            "Epoch 142/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1356 - auc: 0.8255 - val_loss: 0.1523 - val_auc: 0.8061\n",
            "Epoch 143/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1360 - auc: 0.8252 - val_loss: 0.1502 - val_auc: 0.8032\n",
            "Epoch 144/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1352 - auc: 0.8267 - val_loss: 0.1495 - val_auc: 0.8033\n",
            "Epoch 145/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1354 - auc: 0.8259 - val_loss: 0.1517 - val_auc: 0.8007\n",
            "Epoch 146/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1351 - auc: 0.8252 - val_loss: 0.1492 - val_auc: 0.8023\n",
            "Epoch 147/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1346 - auc: 0.8286 - val_loss: 0.1505 - val_auc: 0.8011\n",
            "Epoch 148/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1357 - auc: 0.8235 - val_loss: 0.1494 - val_auc: 0.8023\n",
            "Epoch 149/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1356 - auc: 0.8242 - val_loss: 0.1496 - val_auc: 0.8035\n",
            "Epoch 150/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1347 - auc: 0.8303 - val_loss: 0.1506 - val_auc: 0.8032\n",
            "Epoch 151/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1360 - auc: 0.8221 - val_loss: 0.1504 - val_auc: 0.8028\n",
            "Epoch 152/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1356 - auc: 0.8250 - val_loss: 0.1501 - val_auc: 0.7996\n",
            "Epoch 153/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1352 - auc: 0.8269 - val_loss: 0.1503 - val_auc: 0.7992\n",
            "Epoch 154/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1352 - auc: 0.8258 - val_loss: 0.1505 - val_auc: 0.8010\n",
            "Epoch 155/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1352 - auc: 0.8272 - val_loss: 0.1501 - val_auc: 0.8022\n",
            "Epoch 156/500\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.1360 - auc: 0.8234 - val_loss: 0.1509 - val_auc: 0.8007\n",
            "Epoch 157/500\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.1353 - auc: 0.8267 - val_loss: 0.1506 - val_auc: 0.7990\n",
            "Epoch 158/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1343 - auc: 0.8307 - val_loss: 0.1494 - val_auc: 0.8031\n",
            "Epoch 159/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1354 - auc: 0.8261 - val_loss: 0.1519 - val_auc: 0.8001\n",
            "Epoch 160/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1348 - auc: 0.8277 - val_loss: 0.1502 - val_auc: 0.8019\n",
            "Epoch 161/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1356 - auc: 0.8247 - val_loss: 0.1523 - val_auc: 0.8011\n",
            "Epoch 162/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1346 - auc: 0.8298 - val_loss: 0.1513 - val_auc: 0.8014\n",
            "Epoch 163/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1356 - auc: 0.8235 - val_loss: 0.1499 - val_auc: 0.8009\n",
            "Epoch 164/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1352 - auc: 0.8261 - val_loss: 0.1524 - val_auc: 0.8003\n",
            "Epoch 165/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1356 - auc: 0.8238 - val_loss: 0.1498 - val_auc: 0.8004\n",
            "Epoch 166/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1353 - auc: 0.8258 - val_loss: 0.1501 - val_auc: 0.7967\n",
            "Epoch 167/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1341 - auc: 0.8305 - val_loss: 0.1525 - val_auc: 0.7973\n",
            "Epoch 168/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1353 - auc: 0.8276 - val_loss: 0.1495 - val_auc: 0.8019\n",
            "Epoch 169/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1361 - auc: 0.8216 - val_loss: 0.1503 - val_auc: 0.8024\n",
            "Epoch 170/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1349 - auc: 0.8281 - val_loss: 0.1507 - val_auc: 0.8025\n",
            "Epoch 171/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1348 - auc: 0.8273 - val_loss: 0.1510 - val_auc: 0.8022\n",
            "Epoch 172/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1352 - auc: 0.8260 - val_loss: 0.1510 - val_auc: 0.8001\n",
            "Epoch 173/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1347 - auc: 0.8302 - val_loss: 0.1508 - val_auc: 0.7997\n",
            "Epoch 174/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1350 - auc: 0.8261 - val_loss: 0.1518 - val_auc: 0.8019\n",
            "Epoch 175/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1339 - auc: 0.8314 - val_loss: 0.1502 - val_auc: 0.8004\n",
            "Epoch 176/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1342 - auc: 0.8303 - val_loss: 0.1500 - val_auc: 0.7995\n",
            "Epoch 177/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1347 - auc: 0.8279 - val_loss: 0.1506 - val_auc: 0.7985\n",
            "Epoch 178/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1356 - auc: 0.8253 - val_loss: 0.1534 - val_auc: 0.7995\n",
            "Epoch 179/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1345 - auc: 0.8281 - val_loss: 0.1501 - val_auc: 0.8019\n",
            "Epoch 180/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1350 - auc: 0.8291 - val_loss: 0.1504 - val_auc: 0.8003\n",
            "Epoch 181/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1335 - auc: 0.8341 - val_loss: 0.1523 - val_auc: 0.7962\n",
            "Epoch 182/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1345 - auc: 0.8277 - val_loss: 0.1521 - val_auc: 0.7997\n",
            "Epoch 183/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1341 - auc: 0.8313 - val_loss: 0.1525 - val_auc: 0.7974\n",
            "Epoch 184/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1347 - auc: 0.8290 - val_loss: 0.1508 - val_auc: 0.8018\n",
            "Epoch 185/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1345 - auc: 0.8300 - val_loss: 0.1493 - val_auc: 0.8006\n",
            "Epoch 186/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1351 - auc: 0.8255 - val_loss: 0.1497 - val_auc: 0.8010\n",
            "Epoch 187/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1352 - auc: 0.8254 - val_loss: 0.1500 - val_auc: 0.7995\n",
            "Epoch 188/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1346 - auc: 0.8290 - val_loss: 0.1513 - val_auc: 0.7964\n",
            "Epoch 189/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1340 - auc: 0.8314 - val_loss: 0.1503 - val_auc: 0.8000\n",
            "Epoch 190/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1342 - auc: 0.8313 - val_loss: 0.1505 - val_auc: 0.7997\n",
            "Epoch 191/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1345 - auc: 0.8297 - val_loss: 0.1511 - val_auc: 0.7979\n",
            "Epoch 192/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1347 - auc: 0.8297 - val_loss: 0.1501 - val_auc: 0.7997\n",
            "Epoch 193/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1343 - auc: 0.8292 - val_loss: 0.1506 - val_auc: 0.7985\n",
            "Epoch 194/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1346 - auc: 0.8287 - val_loss: 0.1521 - val_auc: 0.7985\n",
            "Epoch 195/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1340 - auc: 0.8325 - val_loss: 0.1528 - val_auc: 0.7995\n",
            "Epoch 196/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1343 - auc: 0.8290 - val_loss: 0.1524 - val_auc: 0.8000\n",
            "Epoch 197/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1344 - auc: 0.8295 - val_loss: 0.1536 - val_auc: 0.7934\n",
            "Epoch 198/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1341 - auc: 0.8300 - val_loss: 0.1522 - val_auc: 0.7977\n",
            "Epoch 199/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1337 - auc: 0.8337 - val_loss: 0.1502 - val_auc: 0.7998\n",
            "Epoch 200/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1342 - auc: 0.8282 - val_loss: 0.1542 - val_auc: 0.7959\n",
            "Epoch 201/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1337 - auc: 0.8325 - val_loss: 0.1510 - val_auc: 0.7994\n",
            "Epoch 202/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1337 - auc: 0.8340 - val_loss: 0.1511 - val_auc: 0.8015\n",
            "Epoch 203/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1339 - auc: 0.8295 - val_loss: 0.1531 - val_auc: 0.7990\n",
            "Epoch 204/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1343 - auc: 0.8304 - val_loss: 0.1528 - val_auc: 0.7976\n",
            "Epoch 205/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1337 - auc: 0.8331 - val_loss: 0.1521 - val_auc: 0.8006\n",
            "Epoch 206/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - auc: 0.8325 - val_loss: 0.1508 - val_auc: 0.7966\n",
            "Epoch 207/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1339 - auc: 0.8312 - val_loss: 0.1513 - val_auc: 0.8015\n",
            "Epoch 208/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1338 - auc: 0.8323 - val_loss: 0.1520 - val_auc: 0.7968\n",
            "Epoch 209/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1338 - auc: 0.8305 - val_loss: 0.1533 - val_auc: 0.7989\n",
            "Epoch 210/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1340 - auc: 0.8293 - val_loss: 0.1520 - val_auc: 0.7964\n",
            "Epoch 211/500\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1347 - auc: 0.8271 - val_loss: 0.1531 - val_auc: 0.7950\n",
            "Epoch 212/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1338 - auc: 0.8332 - val_loss: 0.1525 - val_auc: 0.8007\n",
            "Epoch 213/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1339 - auc: 0.8308 - val_loss: 0.1521 - val_auc: 0.8005\n",
            "Epoch 214/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1343 - auc: 0.8287 - val_loss: 0.1522 - val_auc: 0.7989\n",
            "Epoch 215/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1332 - auc: 0.8346 - val_loss: 0.1520 - val_auc: 0.7973\n",
            "Epoch 216/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1345 - auc: 0.8297 - val_loss: 0.1538 - val_auc: 0.7982\n",
            "Epoch 217/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1335 - auc: 0.8333 - val_loss: 0.1503 - val_auc: 0.8003\n",
            "Epoch 218/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1336 - auc: 0.8323 - val_loss: 0.1527 - val_auc: 0.7928\n",
            "Epoch 219/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1331 - auc: 0.8346 - val_loss: 0.1517 - val_auc: 0.7994\n",
            "Epoch 220/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - auc: 0.8316 - val_loss: 0.1509 - val_auc: 0.8008\n",
            "Epoch 221/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1331 - auc: 0.8354 - val_loss: 0.1510 - val_auc: 0.8002\n",
            "Epoch 222/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1341 - auc: 0.8302 - val_loss: 0.1530 - val_auc: 0.7952\n",
            "Epoch 223/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1342 - auc: 0.8299 - val_loss: 0.1522 - val_auc: 0.7980\n",
            "Epoch 224/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1341 - auc: 0.8304 - val_loss: 0.1530 - val_auc: 0.7979\n",
            "Epoch 225/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1337 - auc: 0.8307 - val_loss: 0.1538 - val_auc: 0.7986\n",
            "Epoch 226/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1339 - auc: 0.8307 - val_loss: 0.1529 - val_auc: 0.7977\n",
            "Epoch 227/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1337 - auc: 0.8326 - val_loss: 0.1514 - val_auc: 0.7962\n",
            "Epoch 228/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1341 - auc: 0.8319 - val_loss: 0.1535 - val_auc: 0.7977\n",
            "Epoch 229/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1329 - auc: 0.8348 - val_loss: 0.1527 - val_auc: 0.7982\n",
            "Epoch 230/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1338 - auc: 0.8324 - val_loss: 0.1541 - val_auc: 0.7976\n",
            "Epoch 231/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1333 - auc: 0.8352 - val_loss: 0.1520 - val_auc: 0.7985\n",
            "Epoch 232/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1328 - auc: 0.8359 - val_loss: 0.1529 - val_auc: 0.7949\n",
            "Epoch 233/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1342 - auc: 0.8285 - val_loss: 0.1537 - val_auc: 0.8000\n",
            "Epoch 234/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1337 - auc: 0.8296 - val_loss: 0.1532 - val_auc: 0.7991\n",
            "Epoch 235/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1337 - auc: 0.8327 - val_loss: 0.1539 - val_auc: 0.7968\n",
            "Epoch 236/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1331 - auc: 0.8339 - val_loss: 0.1554 - val_auc: 0.7957\n",
            "Epoch 237/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - auc: 0.8314 - val_loss: 0.1538 - val_auc: 0.7965\n",
            "Epoch 238/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1336 - auc: 0.8317 - val_loss: 0.1547 - val_auc: 0.7974\n",
            "Epoch 239/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1338 - auc: 0.8323 - val_loss: 0.1538 - val_auc: 0.8006\n",
            "Epoch 240/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1340 - auc: 0.8289 - val_loss: 0.1520 - val_auc: 0.7975\n",
            "Epoch 241/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1332 - auc: 0.8350 - val_loss: 0.1536 - val_auc: 0.7936\n",
            "Epoch 242/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1340 - auc: 0.8316 - val_loss: 0.1556 - val_auc: 0.7959\n",
            "Epoch 243/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - auc: 0.8325 - val_loss: 0.1548 - val_auc: 0.7969\n",
            "Epoch 244/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1335 - auc: 0.8333 - val_loss: 0.1545 - val_auc: 0.7963\n",
            "Epoch 245/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1339 - auc: 0.8313 - val_loss: 0.1539 - val_auc: 0.7992\n",
            "Epoch 246/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1333 - auc: 0.8323 - val_loss: 0.1534 - val_auc: 0.7941\n",
            "Epoch 247/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1329 - auc: 0.8318 - val_loss: 0.1537 - val_auc: 0.7962\n",
            "Epoch 248/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1330 - auc: 0.8341 - val_loss: 0.1554 - val_auc: 0.7930\n",
            "Epoch 249/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1339 - auc: 0.8321 - val_loss: 0.1545 - val_auc: 0.7950\n",
            "Epoch 250/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - auc: 0.8312 - val_loss: 0.1535 - val_auc: 0.7985\n",
            "Epoch 251/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1331 - auc: 0.8331 - val_loss: 0.1556 - val_auc: 0.7981\n",
            "Epoch 252/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1333 - auc: 0.8322 - val_loss: 0.1530 - val_auc: 0.7985\n",
            "Epoch 253/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1327 - auc: 0.8361 - val_loss: 0.1520 - val_auc: 0.7961\n",
            "Epoch 254/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1341 - auc: 0.8302 - val_loss: 0.1536 - val_auc: 0.7982\n",
            "Epoch 255/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - auc: 0.8331 - val_loss: 0.1528 - val_auc: 0.7972\n",
            "Epoch 256/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1330 - auc: 0.8345 - val_loss: 0.1537 - val_auc: 0.7953\n",
            "Epoch 257/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1332 - auc: 0.8328 - val_loss: 0.1543 - val_auc: 0.7965\n",
            "Epoch 258/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1336 - auc: 0.8294 - val_loss: 0.1555 - val_auc: 0.7955\n",
            "Epoch 259/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1338 - auc: 0.8299 - val_loss: 0.1530 - val_auc: 0.7997\n",
            "Epoch 260/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1341 - auc: 0.8272 - val_loss: 0.1526 - val_auc: 0.7992\n",
            "Epoch 261/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1344 - auc: 0.8292 - val_loss: 0.1518 - val_auc: 0.7992\n",
            "Epoch 262/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1330 - auc: 0.8323 - val_loss: 0.1533 - val_auc: 0.7975\n",
            "Epoch 263/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1342 - auc: 0.8283 - val_loss: 0.1537 - val_auc: 0.7983\n",
            "Epoch 264/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1338 - auc: 0.8317 - val_loss: 0.1526 - val_auc: 0.7965\n",
            "Epoch 265/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1340 - auc: 0.8319 - val_loss: 0.1530 - val_auc: 0.7992\n",
            "Epoch 266/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1336 - auc: 0.8331 - val_loss: 0.1530 - val_auc: 0.7970\n",
            "Epoch 267/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1335 - auc: 0.8317 - val_loss: 0.1544 - val_auc: 0.7946\n",
            "Epoch 268/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1331 - auc: 0.8329 - val_loss: 0.1536 - val_auc: 0.7971\n",
            "Epoch 269/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1326 - auc: 0.8368 - val_loss: 0.1526 - val_auc: 0.7974\n",
            "Epoch 270/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1339 - auc: 0.8319 - val_loss: 0.1538 - val_auc: 0.7968\n",
            "Epoch 271/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1329 - auc: 0.8342 - val_loss: 0.1548 - val_auc: 0.7933\n",
            "Epoch 272/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1328 - auc: 0.8339 - val_loss: 0.1542 - val_auc: 0.7979\n",
            "Epoch 273/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1330 - auc: 0.8330 - val_loss: 0.1541 - val_auc: 0.7963\n",
            "Epoch 274/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1324 - auc: 0.8372 - val_loss: 0.1538 - val_auc: 0.7930\n",
            "Epoch 275/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1328 - auc: 0.8353 - val_loss: 0.1539 - val_auc: 0.7979\n",
            "Epoch 276/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1329 - auc: 0.8328 - val_loss: 0.1530 - val_auc: 0.7967\n",
            "Epoch 277/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1336 - auc: 0.8299 - val_loss: 0.1552 - val_auc: 0.7969\n",
            "Epoch 278/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1332 - auc: 0.8306 - val_loss: 0.1573 - val_auc: 0.7952\n",
            "Epoch 279/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1330 - auc: 0.8351 - val_loss: 0.1541 - val_auc: 0.7949\n",
            "Epoch 280/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1332 - auc: 0.8353 - val_loss: 0.1539 - val_auc: 0.7953\n",
            "Epoch 281/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1333 - auc: 0.8324 - val_loss: 0.1553 - val_auc: 0.7928\n",
            "Epoch 282/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1331 - auc: 0.8321 - val_loss: 0.1546 - val_auc: 0.7959\n",
            "Epoch 283/500\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1331 - auc: 0.8349 - val_loss: 0.1534 - val_auc: 0.7972\n",
            "Epoch 284/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1329 - auc: 0.8352 - val_loss: 0.1532 - val_auc: 0.7973\n",
            "Epoch 285/500\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.1332 - auc: 0.8336 - val_loss: 0.1549 - val_auc: 0.7897\n",
            "Epoch 286/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1332 - auc: 0.8335 - val_loss: 0.1540 - val_auc: 0.7938\n",
            "Epoch 287/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1335 - auc: 0.8346 - val_loss: 0.1545 - val_auc: 0.7970\n",
            "Epoch 288/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1327 - auc: 0.8347 - val_loss: 0.1549 - val_auc: 0.7961\n",
            "Epoch 289/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1327 - auc: 0.8333 - val_loss: 0.1549 - val_auc: 0.7944\n",
            "Epoch 290/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1333 - auc: 0.8341 - val_loss: 0.1539 - val_auc: 0.7974\n",
            "Epoch 291/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - auc: 0.8321 - val_loss: 0.1564 - val_auc: 0.7972\n",
            "Epoch 292/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1328 - auc: 0.8368 - val_loss: 0.1535 - val_auc: 0.7969\n",
            "Epoch 293/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1331 - auc: 0.8344 - val_loss: 0.1556 - val_auc: 0.7950\n",
            "Epoch 294/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1338 - auc: 0.8299 - val_loss: 0.1545 - val_auc: 0.7948\n",
            "Epoch 295/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1332 - auc: 0.8361 - val_loss: 0.1531 - val_auc: 0.7975\n",
            "Epoch 296/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1331 - auc: 0.8335 - val_loss: 0.1533 - val_auc: 0.7974\n",
            "Epoch 297/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1334 - auc: 0.8333 - val_loss: 0.1577 - val_auc: 0.7920\n",
            "Epoch 298/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1327 - auc: 0.8341 - val_loss: 0.1542 - val_auc: 0.7961\n",
            "Epoch 299/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1324 - auc: 0.8381 - val_loss: 0.1530 - val_auc: 0.7966\n",
            "Epoch 300/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1323 - auc: 0.8360 - val_loss: 0.1545 - val_auc: 0.7930\n",
            "Epoch 301/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1332 - auc: 0.8339 - val_loss: 0.1528 - val_auc: 0.7978\n",
            "Epoch 302/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1333 - auc: 0.8342 - val_loss: 0.1541 - val_auc: 0.7960\n",
            "Epoch 303/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1335 - auc: 0.8292 - val_loss: 0.1525 - val_auc: 0.7969\n",
            "Epoch 304/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1326 - auc: 0.8349 - val_loss: 0.1542 - val_auc: 0.7931\n",
            "Epoch 305/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1325 - auc: 0.8363 - val_loss: 0.1544 - val_auc: 0.7943\n",
            "Epoch 306/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - auc: 0.8316 - val_loss: 0.1549 - val_auc: 0.7939\n",
            "Epoch 307/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1334 - auc: 0.8314 - val_loss: 0.1540 - val_auc: 0.7964\n",
            "Epoch 308/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1328 - auc: 0.8349 - val_loss: 0.1533 - val_auc: 0.7955\n",
            "Epoch 309/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1330 - auc: 0.8355 - val_loss: 0.1544 - val_auc: 0.7943\n",
            "Epoch 310/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1326 - auc: 0.8356 - val_loss: 0.1555 - val_auc: 0.7937\n",
            "Epoch 311/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1327 - auc: 0.8354 - val_loss: 0.1573 - val_auc: 0.7909\n",
            "Epoch 312/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1319 - auc: 0.8391 - val_loss: 0.1553 - val_auc: 0.7917\n",
            "Epoch 313/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1321 - auc: 0.8395 - val_loss: 0.1558 - val_auc: 0.7941\n",
            "Epoch 314/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8359 - val_loss: 0.1547 - val_auc: 0.7953\n",
            "Epoch 315/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1323 - auc: 0.8366 - val_loss: 0.1543 - val_auc: 0.7941\n",
            "Epoch 316/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8372 - val_loss: 0.1565 - val_auc: 0.7944\n",
            "Epoch 317/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1319 - auc: 0.8386 - val_loss: 0.1541 - val_auc: 0.7932\n",
            "Epoch 318/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1330 - auc: 0.8325 - val_loss: 0.1550 - val_auc: 0.7955\n",
            "Epoch 319/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1329 - auc: 0.8334 - val_loss: 0.1532 - val_auc: 0.7948\n",
            "Epoch 320/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1327 - auc: 0.8342 - val_loss: 0.1519 - val_auc: 0.7960\n",
            "Epoch 321/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1330 - auc: 0.8353 - val_loss: 0.1551 - val_auc: 0.7975\n",
            "Epoch 322/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1325 - auc: 0.8354 - val_loss: 0.1531 - val_auc: 0.7965\n",
            "Epoch 323/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1324 - auc: 0.8351 - val_loss: 0.1534 - val_auc: 0.7963\n",
            "Epoch 324/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1321 - auc: 0.8378 - val_loss: 0.1547 - val_auc: 0.7951\n",
            "Epoch 325/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1326 - auc: 0.8349 - val_loss: 0.1554 - val_auc: 0.7926\n",
            "Epoch 326/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1329 - auc: 0.8345 - val_loss: 0.1553 - val_auc: 0.7918\n",
            "Epoch 327/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1333 - auc: 0.8324 - val_loss: 0.1554 - val_auc: 0.7944\n",
            "Epoch 328/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1312 - auc: 0.8400 - val_loss: 0.1537 - val_auc: 0.7952\n",
            "Epoch 329/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1323 - auc: 0.8372 - val_loss: 0.1551 - val_auc: 0.7954\n",
            "Epoch 330/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1326 - auc: 0.8354 - val_loss: 0.1543 - val_auc: 0.7956\n",
            "Epoch 331/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1327 - auc: 0.8364 - val_loss: 0.1525 - val_auc: 0.7986\n",
            "Epoch 332/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8361 - val_loss: 0.1534 - val_auc: 0.7974\n",
            "Epoch 333/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1327 - auc: 0.8361 - val_loss: 0.1547 - val_auc: 0.7971\n",
            "Epoch 334/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1326 - auc: 0.8347 - val_loss: 0.1540 - val_auc: 0.7982\n",
            "Epoch 335/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1326 - auc: 0.8338 - val_loss: 0.1555 - val_auc: 0.7921\n",
            "Epoch 336/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1318 - auc: 0.8380 - val_loss: 0.1532 - val_auc: 0.7951\n",
            "Epoch 337/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1317 - auc: 0.8405 - val_loss: 0.1538 - val_auc: 0.7921\n",
            "Epoch 338/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1316 - auc: 0.8391 - val_loss: 0.1558 - val_auc: 0.7910\n",
            "Epoch 339/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1323 - auc: 0.8355 - val_loss: 0.1549 - val_auc: 0.7975\n",
            "Epoch 340/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8382 - val_loss: 0.1531 - val_auc: 0.7943\n",
            "Epoch 341/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1327 - auc: 0.8359 - val_loss: 0.1569 - val_auc: 0.7921\n",
            "Epoch 342/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8383 - val_loss: 0.1544 - val_auc: 0.7965\n",
            "Epoch 343/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1322 - auc: 0.8365 - val_loss: 0.1559 - val_auc: 0.7946\n",
            "Epoch 344/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1326 - auc: 0.8360 - val_loss: 0.1570 - val_auc: 0.7904\n",
            "Epoch 345/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1328 - auc: 0.8349 - val_loss: 0.1552 - val_auc: 0.7987\n",
            "Epoch 346/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1325 - auc: 0.8355 - val_loss: 0.1560 - val_auc: 0.7953\n",
            "Epoch 347/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1328 - auc: 0.8333 - val_loss: 0.1561 - val_auc: 0.7900\n",
            "Epoch 348/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1326 - auc: 0.8358 - val_loss: 0.1575 - val_auc: 0.7920\n",
            "Epoch 349/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1328 - auc: 0.8350 - val_loss: 0.1547 - val_auc: 0.7964\n",
            "Epoch 350/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1327 - auc: 0.8345 - val_loss: 0.1537 - val_auc: 0.7990\n",
            "Epoch 351/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1333 - auc: 0.8333 - val_loss: 0.1557 - val_auc: 0.7958\n",
            "Epoch 352/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1327 - auc: 0.8345 - val_loss: 0.1539 - val_auc: 0.7966\n",
            "Epoch 353/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1332 - auc: 0.8355 - val_loss: 0.1544 - val_auc: 0.7981\n",
            "Epoch 354/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1315 - auc: 0.8389 - val_loss: 0.1528 - val_auc: 0.7979\n",
            "Epoch 355/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1319 - auc: 0.8386 - val_loss: 0.1545 - val_auc: 0.7961\n",
            "Epoch 356/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1331 - auc: 0.8340 - val_loss: 0.1544 - val_auc: 0.7937\n",
            "Epoch 357/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1326 - auc: 0.8335 - val_loss: 0.1537 - val_auc: 0.7933\n",
            "Epoch 358/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1326 - auc: 0.8366 - val_loss: 0.1556 - val_auc: 0.7899\n",
            "Epoch 359/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8398 - val_loss: 0.1564 - val_auc: 0.7944\n",
            "Epoch 360/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1312 - auc: 0.8403 - val_loss: 0.1540 - val_auc: 0.7943\n",
            "Epoch 361/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8365 - val_loss: 0.1559 - val_auc: 0.7890\n",
            "Epoch 362/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8365 - val_loss: 0.1550 - val_auc: 0.7922\n",
            "Epoch 363/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8361 - val_loss: 0.1546 - val_auc: 0.7899\n",
            "Epoch 364/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1321 - auc: 0.8360 - val_loss: 0.1554 - val_auc: 0.7948\n",
            "Epoch 365/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8383 - val_loss: 0.1544 - val_auc: 0.7948\n",
            "Epoch 366/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1324 - auc: 0.8362 - val_loss: 0.1548 - val_auc: 0.7936\n",
            "Epoch 367/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1325 - auc: 0.8362 - val_loss: 0.1550 - val_auc: 0.7924\n",
            "Epoch 368/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1323 - auc: 0.8351 - val_loss: 0.1538 - val_auc: 0.7948\n",
            "Epoch 369/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1321 - auc: 0.8366 - val_loss: 0.1548 - val_auc: 0.7940\n",
            "Epoch 370/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8398 - val_loss: 0.1534 - val_auc: 0.7971\n",
            "Epoch 371/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1324 - auc: 0.8372 - val_loss: 0.1534 - val_auc: 0.7984\n",
            "Epoch 372/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1320 - auc: 0.8376 - val_loss: 0.1543 - val_auc: 0.7967\n",
            "Epoch 373/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1319 - auc: 0.8385 - val_loss: 0.1549 - val_auc: 0.7931\n",
            "Epoch 374/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1316 - auc: 0.8385 - val_loss: 0.1571 - val_auc: 0.7921\n",
            "Epoch 375/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1319 - auc: 0.8392 - val_loss: 0.1566 - val_auc: 0.7895\n",
            "Epoch 376/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1321 - auc: 0.8366 - val_loss: 0.1577 - val_auc: 0.7897\n",
            "Epoch 377/500\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1317 - auc: 0.8387 - val_loss: 0.1559 - val_auc: 0.7898\n",
            "Epoch 378/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1321 - auc: 0.8363 - val_loss: 0.1542 - val_auc: 0.7909\n",
            "Epoch 379/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1322 - auc: 0.8367 - val_loss: 0.1543 - val_auc: 0.7952\n",
            "Epoch 380/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1321 - auc: 0.8352 - val_loss: 0.1556 - val_auc: 0.7921\n",
            "Epoch 381/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1312 - auc: 0.8414 - val_loss: 0.1572 - val_auc: 0.7862\n",
            "Epoch 382/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1325 - auc: 0.8370 - val_loss: 0.1558 - val_auc: 0.7926\n",
            "Epoch 383/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1311 - auc: 0.8406 - val_loss: 0.1574 - val_auc: 0.7862\n",
            "Epoch 384/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1326 - auc: 0.8341 - val_loss: 0.1562 - val_auc: 0.7930\n",
            "Epoch 385/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1328 - auc: 0.8360 - val_loss: 0.1538 - val_auc: 0.7959\n",
            "Epoch 386/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1320 - auc: 0.8366 - val_loss: 0.1534 - val_auc: 0.7953\n",
            "Epoch 387/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1319 - auc: 0.8380 - val_loss: 0.1535 - val_auc: 0.7971\n",
            "Epoch 388/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8367 - val_loss: 0.1538 - val_auc: 0.7947\n",
            "Epoch 389/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1317 - auc: 0.8388 - val_loss: 0.1550 - val_auc: 0.7930\n",
            "Epoch 390/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8379 - val_loss: 0.1543 - val_auc: 0.7946\n",
            "Epoch 391/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1319 - auc: 0.8389 - val_loss: 0.1570 - val_auc: 0.7905\n",
            "Epoch 392/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1314 - auc: 0.8387 - val_loss: 0.1549 - val_auc: 0.7916\n",
            "Epoch 393/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1320 - auc: 0.8380 - val_loss: 0.1556 - val_auc: 0.7920\n",
            "Epoch 394/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1316 - auc: 0.8393 - val_loss: 0.1548 - val_auc: 0.7948\n",
            "Epoch 395/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1321 - auc: 0.8381 - val_loss: 0.1551 - val_auc: 0.7906\n",
            "Epoch 396/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1319 - auc: 0.8369 - val_loss: 0.1553 - val_auc: 0.7904\n",
            "Epoch 397/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1319 - auc: 0.8383 - val_loss: 0.1564 - val_auc: 0.7918\n",
            "Epoch 398/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1315 - auc: 0.8381 - val_loss: 0.1560 - val_auc: 0.7945\n",
            "Epoch 399/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8380 - val_loss: 0.1553 - val_auc: 0.7900\n",
            "Epoch 400/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1315 - auc: 0.8396 - val_loss: 0.1565 - val_auc: 0.7907\n",
            "Epoch 401/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1312 - auc: 0.8393 - val_loss: 0.1545 - val_auc: 0.7903\n",
            "Epoch 402/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1311 - auc: 0.8381 - val_loss: 0.1559 - val_auc: 0.7901\n",
            "Epoch 403/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1315 - auc: 0.8403 - val_loss: 0.1555 - val_auc: 0.7926\n",
            "Epoch 404/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1317 - auc: 0.8385 - val_loss: 0.1544 - val_auc: 0.7941\n",
            "Epoch 405/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1324 - auc: 0.8354 - val_loss: 0.1562 - val_auc: 0.7935\n",
            "Epoch 406/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1319 - auc: 0.8383 - val_loss: 0.1566 - val_auc: 0.7902\n",
            "Epoch 407/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1320 - auc: 0.8357 - val_loss: 0.1572 - val_auc: 0.7902\n",
            "Epoch 408/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8400 - val_loss: 0.1530 - val_auc: 0.7962\n",
            "Epoch 409/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1313 - auc: 0.8396 - val_loss: 0.1544 - val_auc: 0.7951\n",
            "Epoch 410/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1319 - auc: 0.8390 - val_loss: 0.1555 - val_auc: 0.7938\n",
            "Epoch 411/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1318 - auc: 0.8379 - val_loss: 0.1534 - val_auc: 0.7932\n",
            "Epoch 412/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8392 - val_loss: 0.1546 - val_auc: 0.7914\n",
            "Epoch 413/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1310 - auc: 0.8418 - val_loss: 0.1555 - val_auc: 0.7911\n",
            "Epoch 414/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1316 - auc: 0.8389 - val_loss: 0.1581 - val_auc: 0.7877\n",
            "Epoch 415/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1318 - auc: 0.8378 - val_loss: 0.1551 - val_auc: 0.7944\n",
            "Epoch 416/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1308 - auc: 0.8419 - val_loss: 0.1551 - val_auc: 0.7928\n",
            "Epoch 417/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1317 - auc: 0.8391 - val_loss: 0.1552 - val_auc: 0.7962\n",
            "Epoch 418/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1312 - auc: 0.8394 - val_loss: 0.1549 - val_auc: 0.7944\n",
            "Epoch 419/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1309 - auc: 0.8427 - val_loss: 0.1570 - val_auc: 0.7945\n",
            "Epoch 420/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1307 - auc: 0.8393 - val_loss: 0.1567 - val_auc: 0.7924\n",
            "Epoch 421/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1322 - auc: 0.8360 - val_loss: 0.1571 - val_auc: 0.7934\n",
            "Epoch 422/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1315 - auc: 0.8406 - val_loss: 0.1558 - val_auc: 0.7923\n",
            "Epoch 423/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1308 - auc: 0.8409 - val_loss: 0.1558 - val_auc: 0.7921\n",
            "Epoch 424/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1317 - auc: 0.8377 - val_loss: 0.1550 - val_auc: 0.7965\n",
            "Epoch 425/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1315 - auc: 0.8380 - val_loss: 0.1566 - val_auc: 0.7937\n",
            "Epoch 426/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1310 - auc: 0.8390 - val_loss: 0.1547 - val_auc: 0.7944\n",
            "Epoch 427/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1318 - auc: 0.8375 - val_loss: 0.1569 - val_auc: 0.7938\n",
            "Epoch 428/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1319 - auc: 0.8370 - val_loss: 0.1568 - val_auc: 0.7951\n",
            "Epoch 429/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8352 - val_loss: 0.1552 - val_auc: 0.7930\n",
            "Epoch 430/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1318 - auc: 0.8365 - val_loss: 0.1556 - val_auc: 0.7929\n",
            "Epoch 431/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1314 - auc: 0.8371 - val_loss: 0.1545 - val_auc: 0.7936\n",
            "Epoch 432/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1315 - auc: 0.8385 - val_loss: 0.1561 - val_auc: 0.7938\n",
            "Epoch 433/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8401 - val_loss: 0.1575 - val_auc: 0.7877\n",
            "Epoch 434/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1315 - auc: 0.8386 - val_loss: 0.1563 - val_auc: 0.7929\n",
            "Epoch 435/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1317 - auc: 0.8393 - val_loss: 0.1564 - val_auc: 0.7922\n",
            "Epoch 436/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1315 - auc: 0.8393 - val_loss: 0.1572 - val_auc: 0.7911\n",
            "Epoch 437/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1319 - auc: 0.8373 - val_loss: 0.1568 - val_auc: 0.7913\n",
            "Epoch 438/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1311 - auc: 0.8406 - val_loss: 0.1566 - val_auc: 0.7915\n",
            "Epoch 439/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1311 - auc: 0.8396 - val_loss: 0.1564 - val_auc: 0.7905\n",
            "Epoch 440/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8389 - val_loss: 0.1564 - val_auc: 0.7919\n",
            "Epoch 441/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1321 - auc: 0.8360 - val_loss: 0.1549 - val_auc: 0.7896\n",
            "Epoch 442/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1320 - auc: 0.8347 - val_loss: 0.1586 - val_auc: 0.7872\n",
            "Epoch 443/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1315 - auc: 0.8375 - val_loss: 0.1561 - val_auc: 0.7879\n",
            "Epoch 444/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1326 - auc: 0.8366 - val_loss: 0.1568 - val_auc: 0.7927\n",
            "Epoch 445/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1313 - auc: 0.8380 - val_loss: 0.1560 - val_auc: 0.7934\n",
            "Epoch 446/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1325 - auc: 0.8368 - val_loss: 0.1556 - val_auc: 0.7891\n",
            "Epoch 447/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8382 - val_loss: 0.1545 - val_auc: 0.7918\n",
            "Epoch 448/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8372 - val_loss: 0.1535 - val_auc: 0.7966\n",
            "Epoch 449/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1314 - auc: 0.8395 - val_loss: 0.1549 - val_auc: 0.7931\n",
            "Epoch 450/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8385 - val_loss: 0.1555 - val_auc: 0.7910\n",
            "Epoch 451/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1318 - auc: 0.8362 - val_loss: 0.1563 - val_auc: 0.7913\n",
            "Epoch 452/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8375 - val_loss: 0.1570 - val_auc: 0.7916\n",
            "Epoch 453/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1320 - auc: 0.8376 - val_loss: 0.1577 - val_auc: 0.7876\n",
            "Epoch 454/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1318 - auc: 0.8384 - val_loss: 0.1558 - val_auc: 0.7923\n",
            "Epoch 455/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1311 - auc: 0.8397 - val_loss: 0.1573 - val_auc: 0.7928\n",
            "Epoch 456/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1317 - auc: 0.8377 - val_loss: 0.1554 - val_auc: 0.7953\n",
            "Epoch 457/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1316 - auc: 0.8372 - val_loss: 0.1573 - val_auc: 0.7924\n",
            "Epoch 458/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1311 - auc: 0.8392 - val_loss: 0.1578 - val_auc: 0.7894\n",
            "Epoch 459/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1314 - auc: 0.8389 - val_loss: 0.1574 - val_auc: 0.7893\n",
            "Epoch 460/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1308 - auc: 0.8393 - val_loss: 0.1592 - val_auc: 0.7848\n",
            "Epoch 461/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8381 - val_loss: 0.1551 - val_auc: 0.7946\n",
            "Epoch 462/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1315 - auc: 0.8374 - val_loss: 0.1568 - val_auc: 0.7909\n",
            "Epoch 463/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1317 - auc: 0.8386 - val_loss: 0.1571 - val_auc: 0.7911\n",
            "Epoch 464/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1314 - auc: 0.8394 - val_loss: 0.1552 - val_auc: 0.7942\n",
            "Epoch 465/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1300 - auc: 0.8468 - val_loss: 0.1571 - val_auc: 0.7916\n",
            "Epoch 466/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1310 - auc: 0.8411 - val_loss: 0.1561 - val_auc: 0.7913\n",
            "Epoch 467/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1311 - auc: 0.8397 - val_loss: 0.1567 - val_auc: 0.7907\n",
            "Epoch 468/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1308 - auc: 0.8434 - val_loss: 0.1561 - val_auc: 0.7920\n",
            "Epoch 469/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1308 - auc: 0.8414 - val_loss: 0.1580 - val_auc: 0.7869\n",
            "Epoch 470/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8369 - val_loss: 0.1584 - val_auc: 0.7899\n",
            "Epoch 471/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1314 - auc: 0.8407 - val_loss: 0.1554 - val_auc: 0.7935\n",
            "Epoch 472/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1315 - auc: 0.8380 - val_loss: 0.1552 - val_auc: 0.7957\n",
            "Epoch 473/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1317 - auc: 0.8391 - val_loss: 0.1582 - val_auc: 0.7898\n",
            "Epoch 474/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1318 - auc: 0.8360 - val_loss: 0.1572 - val_auc: 0.7931\n",
            "Epoch 475/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1312 - auc: 0.8386 - val_loss: 0.1578 - val_auc: 0.7950\n",
            "Epoch 476/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8383 - val_loss: 0.1564 - val_auc: 0.7957\n",
            "Epoch 477/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1311 - auc: 0.8406 - val_loss: 0.1592 - val_auc: 0.7892\n",
            "Epoch 478/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - auc: 0.8377 - val_loss: 0.1569 - val_auc: 0.7914\n",
            "Epoch 479/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8409 - val_loss: 0.1603 - val_auc: 0.7853\n",
            "Epoch 480/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1315 - auc: 0.8403 - val_loss: 0.1578 - val_auc: 0.7892\n",
            "Epoch 481/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1324 - auc: 0.8390 - val_loss: 0.1565 - val_auc: 0.7919\n",
            "Epoch 482/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1314 - auc: 0.8405 - val_loss: 0.1570 - val_auc: 0.7933\n",
            "Epoch 483/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1311 - auc: 0.8405 - val_loss: 0.1571 - val_auc: 0.7911\n",
            "Epoch 484/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1319 - auc: 0.8355 - val_loss: 0.1581 - val_auc: 0.7915\n",
            "Epoch 485/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1317 - auc: 0.8396 - val_loss: 0.1574 - val_auc: 0.7935\n",
            "Epoch 486/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1311 - auc: 0.8404 - val_loss: 0.1585 - val_auc: 0.7900\n",
            "Epoch 487/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1317 - auc: 0.8370 - val_loss: 0.1570 - val_auc: 0.7896\n",
            "Epoch 488/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1305 - auc: 0.8420 - val_loss: 0.1575 - val_auc: 0.7907\n",
            "Epoch 489/500\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.1302 - auc: 0.8421 - val_loss: 0.1565 - val_auc: 0.7912\n",
            "Epoch 490/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1314 - auc: 0.8392 - val_loss: 0.1564 - val_auc: 0.7898\n",
            "Epoch 491/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1314 - auc: 0.8383 - val_loss: 0.1565 - val_auc: 0.7933\n",
            "Epoch 492/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1316 - auc: 0.8386 - val_loss: 0.1561 - val_auc: 0.7920\n",
            "Epoch 493/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1306 - auc: 0.8408 - val_loss: 0.1559 - val_auc: 0.7929\n",
            "Epoch 494/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1315 - auc: 0.8375 - val_loss: 0.1563 - val_auc: 0.7937\n",
            "Epoch 495/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1311 - auc: 0.8412 - val_loss: 0.1571 - val_auc: 0.7904\n",
            "Epoch 496/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1321 - auc: 0.8386 - val_loss: 0.1583 - val_auc: 0.7866\n",
            "Epoch 497/500\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.1314 - auc: 0.8396 - val_loss: 0.1557 - val_auc: 0.7920\n",
            "Epoch 498/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.1315 - auc: 0.8393 - val_loss: 0.1561 - val_auc: 0.7936\n",
            "Epoch 499/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1315 - auc: 0.8384 - val_loss: 0.1568 - val_auc: 0.7931\n",
            "Epoch 500/500\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.1302 - auc: 0.8437 - val_loss: 0.1554 - val_auc: 0.7936\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use smote to deal with the imbalance. \n",
        "\n",
        "from sklearn.model_selection import train_test_split #split the smote data\n",
        "\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(smote_data, smote_labels, \\\n",
        "                                                      test_size= 0.2, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler #scale the smote data\n",
        "scaler  = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid   = scaler.transform(X_valid)\n"
      ],
      "metadata": {
        "id": "crYoRC5yBob7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "Pg5JvKuMIhPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "smote_model2 = keras.models.Sequential([\n",
        "        keras.layers.Dense(60, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "        keras.layers.Dropout(0.5), #drop 50% of the nuerons randomly\n",
        "        keras.layers.Dense(30, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.5), #drop 50% of the nuerons randomly\n",
        "        keras.layers.Dense(18, activation=\"relu\",),\n",
        "        keras.layers.Dropout(0.5), #drop 50% of the nuerons randomly\n",
        "        keras.layers.Dense(9, activation=\"relu\"),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),#output layer\n",
        " ]) \n",
        "smote_model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RVtmcAIuWy",
        "outputId": "1801d7c1-bb6e-4bd8-b379-e5eafd8bedc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 60)                20220     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 60)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                1830      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 18)                558       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 18)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 171       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,789\n",
            "Trainable params: 22,789\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote_model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
        "              loss=\"binary_crossentropy\", \n",
        "              metrics=[\"AUC\"])"
      ],
      "metadata": {
        "id": "jBkVtaFGI09p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote_history= smote_model2.fit(X_train, y_train, epochs=500,\\\n",
        "                    batch_size= 1000, validation_data=(X_valid, y_valid))\n",
        "\n",
        "\n",
        "plt.plot(pd.DataFrame(smote_history.history))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nUTMFbjMI9Kv",
        "outputId": "9ad49121-11e3-4c35-bb55-6e656e71b9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "117/117 [==============================] - 4s 15ms/step - loss: 0.5803 - auc: 0.7794 - val_loss: 0.4561 - val_auc: 0.8812\n",
            "Epoch 2/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.4504 - auc: 0.8742 - val_loss: 0.3558 - val_auc: 0.9227\n",
            "Epoch 3/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.3897 - auc: 0.9059 - val_loss: 0.3338 - val_auc: 0.9332\n",
            "Epoch 4/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.3618 - auc: 0.9182 - val_loss: 0.3158 - val_auc: 0.9403\n",
            "Epoch 5/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.3421 - auc: 0.9269 - val_loss: 0.2981 - val_auc: 0.9448\n",
            "Epoch 6/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.3278 - auc: 0.9326 - val_loss: 0.2934 - val_auc: 0.9493\n",
            "Epoch 7/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.3210 - auc: 0.9352 - val_loss: 0.2841 - val_auc: 0.9516\n",
            "Epoch 8/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.3141 - auc: 0.9381 - val_loss: 0.2817 - val_auc: 0.9510\n",
            "Epoch 9/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.3083 - auc: 0.9408 - val_loss: 0.2747 - val_auc: 0.9531\n",
            "Epoch 10/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.3040 - auc: 0.9417 - val_loss: 0.2707 - val_auc: 0.9540\n",
            "Epoch 11/500\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.3002 - auc: 0.9430 - val_loss: 0.2699 - val_auc: 0.9551\n",
            "Epoch 12/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2961 - auc: 0.9446 - val_loss: 0.2667 - val_auc: 0.9558\n",
            "Epoch 13/500\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.2967 - auc: 0.9445 - val_loss: 0.2704 - val_auc: 0.9564\n",
            "Epoch 14/500\n",
            "117/117 [==============================] - 2s 14ms/step - loss: 0.2924 - auc: 0.9456 - val_loss: 0.2627 - val_auc: 0.9576\n",
            "Epoch 15/500\n",
            "117/117 [==============================] - 2s 13ms/step - loss: 0.2920 - auc: 0.9460 - val_loss: 0.2645 - val_auc: 0.9570\n",
            "Epoch 16/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2894 - auc: 0.9467 - val_loss: 0.2609 - val_auc: 0.9585\n",
            "Epoch 17/500\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.2884 - auc: 0.9470 - val_loss: 0.2648 - val_auc: 0.9573\n",
            "Epoch 18/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2843 - auc: 0.9483 - val_loss: 0.2594 - val_auc: 0.9589\n",
            "Epoch 19/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2840 - auc: 0.9489 - val_loss: 0.2588 - val_auc: 0.9583\n",
            "Epoch 20/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2816 - auc: 0.9493 - val_loss: 0.2580 - val_auc: 0.9584\n",
            "Epoch 21/500\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.2804 - auc: 0.9496 - val_loss: 0.2569 - val_auc: 0.9591\n",
            "Epoch 22/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2806 - auc: 0.9493 - val_loss: 0.2536 - val_auc: 0.9601\n",
            "Epoch 23/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2793 - auc: 0.9497 - val_loss: 0.2561 - val_auc: 0.9598\n",
            "Epoch 24/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2768 - auc: 0.9506 - val_loss: 0.2594 - val_auc: 0.9599\n",
            "Epoch 25/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2789 - auc: 0.9502 - val_loss: 0.2548 - val_auc: 0.9596\n",
            "Epoch 26/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2781 - auc: 0.9503 - val_loss: 0.2525 - val_auc: 0.9607\n",
            "Epoch 27/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2769 - auc: 0.9505 - val_loss: 0.2547 - val_auc: 0.9596\n",
            "Epoch 28/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2753 - auc: 0.9513 - val_loss: 0.2613 - val_auc: 0.9593\n",
            "Epoch 29/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2759 - auc: 0.9511 - val_loss: 0.2552 - val_auc: 0.9607\n",
            "Epoch 30/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2713 - auc: 0.9527 - val_loss: 0.2505 - val_auc: 0.9610\n",
            "Epoch 31/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2720 - auc: 0.9524 - val_loss: 0.2580 - val_auc: 0.9599\n",
            "Epoch 32/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2702 - auc: 0.9529 - val_loss: 0.2543 - val_auc: 0.9614\n",
            "Epoch 33/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2719 - auc: 0.9523 - val_loss: 0.2593 - val_auc: 0.9586\n",
            "Epoch 34/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2723 - auc: 0.9521 - val_loss: 0.2562 - val_auc: 0.9612\n",
            "Epoch 35/500\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.2692 - auc: 0.9535 - val_loss: 0.2505 - val_auc: 0.9612\n",
            "Epoch 36/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2704 - auc: 0.9529 - val_loss: 0.2515 - val_auc: 0.9618\n",
            "Epoch 37/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2669 - auc: 0.9538 - val_loss: 0.2593 - val_auc: 0.9610\n",
            "Epoch 38/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2669 - auc: 0.9537 - val_loss: 0.2484 - val_auc: 0.9622\n",
            "Epoch 39/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2677 - auc: 0.9536 - val_loss: 0.2534 - val_auc: 0.9619\n",
            "Epoch 40/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2661 - auc: 0.9542 - val_loss: 0.2549 - val_auc: 0.9613\n",
            "Epoch 41/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2663 - auc: 0.9542 - val_loss: 0.2526 - val_auc: 0.9623\n",
            "Epoch 42/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2652 - auc: 0.9543 - val_loss: 0.2497 - val_auc: 0.9620\n",
            "Epoch 43/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2665 - auc: 0.9540 - val_loss: 0.2515 - val_auc: 0.9618\n",
            "Epoch 44/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2655 - auc: 0.9542 - val_loss: 0.2526 - val_auc: 0.9625\n",
            "Epoch 45/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2672 - auc: 0.9535 - val_loss: 0.2568 - val_auc: 0.9627\n",
            "Epoch 46/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2655 - auc: 0.9544 - val_loss: 0.2526 - val_auc: 0.9628\n",
            "Epoch 47/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2631 - auc: 0.9550 - val_loss: 0.2530 - val_auc: 0.9628\n",
            "Epoch 48/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2652 - auc: 0.9541 - val_loss: 0.2541 - val_auc: 0.9630\n",
            "Epoch 49/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2634 - auc: 0.9548 - val_loss: 0.2577 - val_auc: 0.9622\n",
            "Epoch 50/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2617 - auc: 0.9553 - val_loss: 0.2528 - val_auc: 0.9631\n",
            "Epoch 51/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2621 - auc: 0.9553 - val_loss: 0.2537 - val_auc: 0.9634\n",
            "Epoch 52/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2632 - auc: 0.9546 - val_loss: 0.2524 - val_auc: 0.9620\n",
            "Epoch 53/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2637 - auc: 0.9546 - val_loss: 0.2551 - val_auc: 0.9615\n",
            "Epoch 54/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2634 - auc: 0.9547 - val_loss: 0.2524 - val_auc: 0.9635\n",
            "Epoch 55/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2615 - auc: 0.9556 - val_loss: 0.2505 - val_auc: 0.9625\n",
            "Epoch 56/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2613 - auc: 0.9552 - val_loss: 0.2518 - val_auc: 0.9632\n",
            "Epoch 57/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2635 - auc: 0.9544 - val_loss: 0.2541 - val_auc: 0.9635\n",
            "Epoch 58/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2611 - auc: 0.9558 - val_loss: 0.2493 - val_auc: 0.9643\n",
            "Epoch 59/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2623 - auc: 0.9553 - val_loss: 0.2526 - val_auc: 0.9636\n",
            "Epoch 60/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2600 - auc: 0.9559 - val_loss: 0.2502 - val_auc: 0.9637\n",
            "Epoch 61/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2587 - auc: 0.9564 - val_loss: 0.2535 - val_auc: 0.9630\n",
            "Epoch 62/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2618 - auc: 0.9550 - val_loss: 0.2558 - val_auc: 0.9633\n",
            "Epoch 63/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2597 - auc: 0.9557 - val_loss: 0.2536 - val_auc: 0.9617\n",
            "Epoch 64/500\n",
            "117/117 [==============================] - 2s 15ms/step - loss: 0.2647 - auc: 0.9542 - val_loss: 0.2522 - val_auc: 0.9635\n",
            "Epoch 65/500\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.2615 - auc: 0.9553 - val_loss: 0.2489 - val_auc: 0.9633\n",
            "Epoch 66/500\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.2595 - auc: 0.9557 - val_loss: 0.2503 - val_auc: 0.9629\n",
            "Epoch 67/500\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.2612 - auc: 0.9558 - val_loss: 0.2527 - val_auc: 0.9651\n",
            "Epoch 68/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2599 - auc: 0.9556 - val_loss: 0.2522 - val_auc: 0.9624\n",
            "Epoch 69/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2635 - auc: 0.9548 - val_loss: 0.2487 - val_auc: 0.9633\n",
            "Epoch 70/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2593 - auc: 0.9555 - val_loss: 0.2466 - val_auc: 0.9642\n",
            "Epoch 71/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2575 - auc: 0.9565 - val_loss: 0.2487 - val_auc: 0.9629\n",
            "Epoch 72/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2576 - auc: 0.9565 - val_loss: 0.2509 - val_auc: 0.9638\n",
            "Epoch 73/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2569 - auc: 0.9566 - val_loss: 0.2484 - val_auc: 0.9642\n",
            "Epoch 74/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2562 - auc: 0.9570 - val_loss: 0.2481 - val_auc: 0.9639\n",
            "Epoch 75/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2587 - auc: 0.9561 - val_loss: 0.2471 - val_auc: 0.9641\n",
            "Epoch 76/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2578 - auc: 0.9566 - val_loss: 0.2485 - val_auc: 0.9647\n",
            "Epoch 77/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2562 - auc: 0.9570 - val_loss: 0.2511 - val_auc: 0.9632\n",
            "Epoch 78/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2569 - auc: 0.9566 - val_loss: 0.2471 - val_auc: 0.9637\n",
            "Epoch 79/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2565 - auc: 0.9564 - val_loss: 0.2497 - val_auc: 0.9637\n",
            "Epoch 80/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2563 - auc: 0.9569 - val_loss: 0.2480 - val_auc: 0.9651\n",
            "Epoch 81/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2562 - auc: 0.9568 - val_loss: 0.2460 - val_auc: 0.9646\n",
            "Epoch 82/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2582 - auc: 0.9558 - val_loss: 0.2489 - val_auc: 0.9643\n",
            "Epoch 83/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2573 - auc: 0.9566 - val_loss: 0.2461 - val_auc: 0.9648\n",
            "Epoch 84/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2579 - auc: 0.9561 - val_loss: 0.2450 - val_auc: 0.9652\n",
            "Epoch 85/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2574 - auc: 0.9567 - val_loss: 0.2467 - val_auc: 0.9647\n",
            "Epoch 86/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2568 - auc: 0.9567 - val_loss: 0.2478 - val_auc: 0.9636\n",
            "Epoch 87/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2546 - auc: 0.9571 - val_loss: 0.2478 - val_auc: 0.9639\n",
            "Epoch 88/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2585 - auc: 0.9559 - val_loss: 0.2478 - val_auc: 0.9639\n",
            "Epoch 89/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2565 - auc: 0.9566 - val_loss: 0.2497 - val_auc: 0.9635\n",
            "Epoch 90/500\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.2529 - auc: 0.9579 - val_loss: 0.2496 - val_auc: 0.9633\n",
            "Epoch 91/500\n",
            "117/117 [==============================] - 1s 10ms/step - loss: 0.2563 - auc: 0.9564 - val_loss: 0.2515 - val_auc: 0.9637\n",
            "Epoch 92/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2573 - auc: 0.9565 - val_loss: 0.2437 - val_auc: 0.9651\n",
            "Epoch 93/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2542 - auc: 0.9576 - val_loss: 0.2456 - val_auc: 0.9644\n",
            "Epoch 94/500\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.2529 - auc: 0.9577 - val_loss: 0.2441 - val_auc: 0.9651\n",
            "Epoch 95/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2538 - auc: 0.9573 - val_loss: 0.2482 - val_auc: 0.9646\n",
            "Epoch 96/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2542 - auc: 0.9573 - val_loss: 0.2493 - val_auc: 0.9637\n",
            "Epoch 97/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2550 - auc: 0.9568 - val_loss: 0.2539 - val_auc: 0.9637\n",
            "Epoch 98/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2557 - auc: 0.9569 - val_loss: 0.2506 - val_auc: 0.9630\n",
            "Epoch 99/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2555 - auc: 0.9567 - val_loss: 0.2492 - val_auc: 0.9635\n",
            "Epoch 100/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2549 - auc: 0.9570 - val_loss: 0.2466 - val_auc: 0.9649\n",
            "Epoch 101/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2537 - auc: 0.9572 - val_loss: 0.2459 - val_auc: 0.9648\n",
            "Epoch 102/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2515 - auc: 0.9582 - val_loss: 0.2429 - val_auc: 0.9643\n",
            "Epoch 103/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2518 - auc: 0.9578 - val_loss: 0.2481 - val_auc: 0.9629\n",
            "Epoch 104/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2528 - auc: 0.9576 - val_loss: 0.2430 - val_auc: 0.9649\n",
            "Epoch 105/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2536 - auc: 0.9577 - val_loss: 0.2457 - val_auc: 0.9652\n",
            "Epoch 106/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2531 - auc: 0.9580 - val_loss: 0.2448 - val_auc: 0.9652\n",
            "Epoch 107/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2535 - auc: 0.9574 - val_loss: 0.2501 - val_auc: 0.9631\n",
            "Epoch 108/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2549 - auc: 0.9570 - val_loss: 0.2488 - val_auc: 0.9645\n",
            "Epoch 109/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2534 - auc: 0.9577 - val_loss: 0.2455 - val_auc: 0.9650\n",
            "Epoch 110/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2513 - auc: 0.9584 - val_loss: 0.2480 - val_auc: 0.9646\n",
            "Epoch 111/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2499 - auc: 0.9589 - val_loss: 0.2422 - val_auc: 0.9644\n",
            "Epoch 112/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2531 - auc: 0.9576 - val_loss: 0.2472 - val_auc: 0.9643\n",
            "Epoch 113/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2522 - auc: 0.9581 - val_loss: 0.2477 - val_auc: 0.9645\n",
            "Epoch 114/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2520 - auc: 0.9580 - val_loss: 0.2472 - val_auc: 0.9643\n",
            "Epoch 115/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2527 - auc: 0.9578 - val_loss: 0.2489 - val_auc: 0.9638\n",
            "Epoch 116/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2525 - auc: 0.9575 - val_loss: 0.2515 - val_auc: 0.9631\n",
            "Epoch 117/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2520 - auc: 0.9581 - val_loss: 0.2484 - val_auc: 0.9642\n",
            "Epoch 118/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2510 - auc: 0.9584 - val_loss: 0.2443 - val_auc: 0.9651\n",
            "Epoch 119/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2523 - auc: 0.9578 - val_loss: 0.2481 - val_auc: 0.9636\n",
            "Epoch 120/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2534 - auc: 0.9574 - val_loss: 0.2407 - val_auc: 0.9650\n",
            "Epoch 121/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2509 - auc: 0.9581 - val_loss: 0.2438 - val_auc: 0.9654\n",
            "Epoch 122/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2530 - auc: 0.9576 - val_loss: 0.2508 - val_auc: 0.9637\n",
            "Epoch 123/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2510 - auc: 0.9581 - val_loss: 0.2511 - val_auc: 0.9647\n",
            "Epoch 124/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2529 - auc: 0.9572 - val_loss: 0.2457 - val_auc: 0.9645\n",
            "Epoch 125/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2515 - auc: 0.9582 - val_loss: 0.2464 - val_auc: 0.9647\n",
            "Epoch 126/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2509 - auc: 0.9581 - val_loss: 0.2457 - val_auc: 0.9642\n",
            "Epoch 127/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2510 - auc: 0.9581 - val_loss: 0.2472 - val_auc: 0.9637\n",
            "Epoch 128/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2506 - auc: 0.9583 - val_loss: 0.2434 - val_auc: 0.9654\n",
            "Epoch 129/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2505 - auc: 0.9583 - val_loss: 0.2485 - val_auc: 0.9649\n",
            "Epoch 130/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2509 - auc: 0.9581 - val_loss: 0.2437 - val_auc: 0.9646\n",
            "Epoch 131/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2512 - auc: 0.9582 - val_loss: 0.2419 - val_auc: 0.9648\n",
            "Epoch 132/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2503 - auc: 0.9584 - val_loss: 0.2469 - val_auc: 0.9645\n",
            "Epoch 133/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2523 - auc: 0.9579 - val_loss: 0.2455 - val_auc: 0.9640\n",
            "Epoch 134/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2517 - auc: 0.9581 - val_loss: 0.2498 - val_auc: 0.9635\n",
            "Epoch 135/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2504 - auc: 0.9586 - val_loss: 0.2391 - val_auc: 0.9658\n",
            "Epoch 136/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2508 - auc: 0.9584 - val_loss: 0.2386 - val_auc: 0.9648\n",
            "Epoch 137/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2526 - auc: 0.9575 - val_loss: 0.2482 - val_auc: 0.9634\n",
            "Epoch 138/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2508 - auc: 0.9582 - val_loss: 0.2455 - val_auc: 0.9648\n",
            "Epoch 139/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2494 - auc: 0.9587 - val_loss: 0.2435 - val_auc: 0.9646\n",
            "Epoch 140/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2526 - auc: 0.9576 - val_loss: 0.2472 - val_auc: 0.9642\n",
            "Epoch 141/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2513 - auc: 0.9579 - val_loss: 0.2477 - val_auc: 0.9642\n",
            "Epoch 142/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2519 - auc: 0.9579 - val_loss: 0.2454 - val_auc: 0.9644\n",
            "Epoch 143/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2512 - auc: 0.9585 - val_loss: 0.2435 - val_auc: 0.9650\n",
            "Epoch 144/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2515 - auc: 0.9583 - val_loss: 0.2418 - val_auc: 0.9655\n",
            "Epoch 145/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2514 - auc: 0.9586 - val_loss: 0.2446 - val_auc: 0.9651\n",
            "Epoch 146/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2492 - auc: 0.9590 - val_loss: 0.2395 - val_auc: 0.9650\n",
            "Epoch 147/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2489 - auc: 0.9590 - val_loss: 0.2426 - val_auc: 0.9644\n",
            "Epoch 148/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2510 - auc: 0.9581 - val_loss: 0.2502 - val_auc: 0.9624\n",
            "Epoch 149/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2509 - auc: 0.9584 - val_loss: 0.2426 - val_auc: 0.9653\n",
            "Epoch 150/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2468 - auc: 0.9597 - val_loss: 0.2403 - val_auc: 0.9651\n",
            "Epoch 151/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2482 - auc: 0.9590 - val_loss: 0.2386 - val_auc: 0.9652\n",
            "Epoch 152/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2480 - auc: 0.9590 - val_loss: 0.2414 - val_auc: 0.9656\n",
            "Epoch 153/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2498 - auc: 0.9589 - val_loss: 0.2399 - val_auc: 0.9652\n",
            "Epoch 154/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2490 - auc: 0.9588 - val_loss: 0.2446 - val_auc: 0.9642\n",
            "Epoch 155/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2473 - auc: 0.9595 - val_loss: 0.2392 - val_auc: 0.9656\n",
            "Epoch 156/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2482 - auc: 0.9591 - val_loss: 0.2435 - val_auc: 0.9651\n",
            "Epoch 157/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2493 - auc: 0.9584 - val_loss: 0.2410 - val_auc: 0.9653\n",
            "Epoch 158/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2510 - auc: 0.9585 - val_loss: 0.2389 - val_auc: 0.9655\n",
            "Epoch 159/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2482 - auc: 0.9591 - val_loss: 0.2393 - val_auc: 0.9647\n",
            "Epoch 160/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2505 - auc: 0.9584 - val_loss: 0.2435 - val_auc: 0.9647\n",
            "Epoch 161/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2496 - auc: 0.9585 - val_loss: 0.2408 - val_auc: 0.9645\n",
            "Epoch 162/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2489 - auc: 0.9588 - val_loss: 0.2387 - val_auc: 0.9649\n",
            "Epoch 163/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2485 - auc: 0.9591 - val_loss: 0.2412 - val_auc: 0.9654\n",
            "Epoch 164/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2459 - auc: 0.9599 - val_loss: 0.2397 - val_auc: 0.9655\n",
            "Epoch 165/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2498 - auc: 0.9585 - val_loss: 0.2449 - val_auc: 0.9636\n",
            "Epoch 166/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2506 - auc: 0.9584 - val_loss: 0.2404 - val_auc: 0.9657\n",
            "Epoch 167/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2471 - auc: 0.9589 - val_loss: 0.2446 - val_auc: 0.9640\n",
            "Epoch 168/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2477 - auc: 0.9591 - val_loss: 0.2411 - val_auc: 0.9651\n",
            "Epoch 169/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2475 - auc: 0.9591 - val_loss: 0.2405 - val_auc: 0.9660\n",
            "Epoch 170/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2495 - auc: 0.9587 - val_loss: 0.2411 - val_auc: 0.9654\n",
            "Epoch 171/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2480 - auc: 0.9591 - val_loss: 0.2428 - val_auc: 0.9643\n",
            "Epoch 172/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2497 - auc: 0.9583 - val_loss: 0.2415 - val_auc: 0.9641\n",
            "Epoch 173/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2485 - auc: 0.9591 - val_loss: 0.2383 - val_auc: 0.9656\n",
            "Epoch 174/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2495 - auc: 0.9585 - val_loss: 0.2410 - val_auc: 0.9654\n",
            "Epoch 175/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2457 - auc: 0.9599 - val_loss: 0.2416 - val_auc: 0.9656\n",
            "Epoch 176/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2490 - auc: 0.9586 - val_loss: 0.2389 - val_auc: 0.9648\n",
            "Epoch 177/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2482 - auc: 0.9590 - val_loss: 0.2384 - val_auc: 0.9653\n",
            "Epoch 178/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2486 - auc: 0.9589 - val_loss: 0.2435 - val_auc: 0.9654\n",
            "Epoch 179/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2485 - auc: 0.9588 - val_loss: 0.2407 - val_auc: 0.9654\n",
            "Epoch 180/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2475 - auc: 0.9590 - val_loss: 0.2407 - val_auc: 0.9656\n",
            "Epoch 181/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2471 - auc: 0.9592 - val_loss: 0.2448 - val_auc: 0.9629\n",
            "Epoch 182/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2481 - auc: 0.9592 - val_loss: 0.2387 - val_auc: 0.9659\n",
            "Epoch 183/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2459 - auc: 0.9600 - val_loss: 0.2359 - val_auc: 0.9668\n",
            "Epoch 184/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2449 - auc: 0.9601 - val_loss: 0.2398 - val_auc: 0.9653\n",
            "Epoch 185/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2437 - auc: 0.9607 - val_loss: 0.2381 - val_auc: 0.9654\n",
            "Epoch 186/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2457 - auc: 0.9598 - val_loss: 0.2389 - val_auc: 0.9654\n",
            "Epoch 187/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2473 - auc: 0.9594 - val_loss: 0.2441 - val_auc: 0.9649\n",
            "Epoch 188/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2467 - auc: 0.9598 - val_loss: 0.2394 - val_auc: 0.9649\n",
            "Epoch 189/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2455 - auc: 0.9601 - val_loss: 0.2386 - val_auc: 0.9651\n",
            "Epoch 190/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2487 - auc: 0.9588 - val_loss: 0.2476 - val_auc: 0.9641\n",
            "Epoch 191/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2499 - auc: 0.9584 - val_loss: 0.2468 - val_auc: 0.9631\n",
            "Epoch 192/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2492 - auc: 0.9587 - val_loss: 0.2454 - val_auc: 0.9635\n",
            "Epoch 193/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2483 - auc: 0.9592 - val_loss: 0.2401 - val_auc: 0.9650\n",
            "Epoch 194/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2500 - auc: 0.9586 - val_loss: 0.2403 - val_auc: 0.9656\n",
            "Epoch 195/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2470 - auc: 0.9595 - val_loss: 0.2369 - val_auc: 0.9654\n",
            "Epoch 196/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2443 - auc: 0.9606 - val_loss: 0.2397 - val_auc: 0.9662\n",
            "Epoch 197/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2459 - auc: 0.9599 - val_loss: 0.2392 - val_auc: 0.9659\n",
            "Epoch 198/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2460 - auc: 0.9597 - val_loss: 0.2415 - val_auc: 0.9654\n",
            "Epoch 199/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2443 - auc: 0.9603 - val_loss: 0.2365 - val_auc: 0.9668\n",
            "Epoch 200/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2466 - auc: 0.9595 - val_loss: 0.2426 - val_auc: 0.9645\n",
            "Epoch 201/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2463 - auc: 0.9598 - val_loss: 0.2386 - val_auc: 0.9653\n",
            "Epoch 202/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2475 - auc: 0.9593 - val_loss: 0.2386 - val_auc: 0.9653\n",
            "Epoch 203/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2464 - auc: 0.9598 - val_loss: 0.2383 - val_auc: 0.9652\n",
            "Epoch 204/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2467 - auc: 0.9596 - val_loss: 0.2413 - val_auc: 0.9660\n",
            "Epoch 205/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2450 - auc: 0.9603 - val_loss: 0.2403 - val_auc: 0.9646\n",
            "Epoch 206/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2451 - auc: 0.9603 - val_loss: 0.2457 - val_auc: 0.9649\n",
            "Epoch 207/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2453 - auc: 0.9603 - val_loss: 0.2373 - val_auc: 0.9669\n",
            "Epoch 208/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2466 - auc: 0.9595 - val_loss: 0.2452 - val_auc: 0.9637\n",
            "Epoch 209/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2481 - auc: 0.9589 - val_loss: 0.2453 - val_auc: 0.9649\n",
            "Epoch 210/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2470 - auc: 0.9598 - val_loss: 0.2406 - val_auc: 0.9655\n",
            "Epoch 211/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2458 - auc: 0.9602 - val_loss: 0.2407 - val_auc: 0.9656\n",
            "Epoch 212/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2457 - auc: 0.9598 - val_loss: 0.2401 - val_auc: 0.9664\n",
            "Epoch 213/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2460 - auc: 0.9599 - val_loss: 0.2427 - val_auc: 0.9656\n",
            "Epoch 214/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2452 - auc: 0.9601 - val_loss: 0.2418 - val_auc: 0.9655\n",
            "Epoch 215/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2457 - auc: 0.9599 - val_loss: 0.2390 - val_auc: 0.9658\n",
            "Epoch 216/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2450 - auc: 0.9603 - val_loss: 0.2443 - val_auc: 0.9656\n",
            "Epoch 217/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2458 - auc: 0.9598 - val_loss: 0.2425 - val_auc: 0.9650\n",
            "Epoch 218/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2475 - auc: 0.9591 - val_loss: 0.2408 - val_auc: 0.9653\n",
            "Epoch 219/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2452 - auc: 0.9602 - val_loss: 0.2403 - val_auc: 0.9656\n",
            "Epoch 220/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2452 - auc: 0.9597 - val_loss: 0.2399 - val_auc: 0.9661\n",
            "Epoch 221/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2454 - auc: 0.9599 - val_loss: 0.2406 - val_auc: 0.9662\n",
            "Epoch 222/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2442 - auc: 0.9605 - val_loss: 0.2376 - val_auc: 0.9667\n",
            "Epoch 223/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2442 - auc: 0.9606 - val_loss: 0.2375 - val_auc: 0.9666\n",
            "Epoch 224/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2455 - auc: 0.9599 - val_loss: 0.2420 - val_auc: 0.9650\n",
            "Epoch 225/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2459 - auc: 0.9595 - val_loss: 0.2450 - val_auc: 0.9654\n",
            "Epoch 226/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2450 - auc: 0.9603 - val_loss: 0.2386 - val_auc: 0.9658\n",
            "Epoch 227/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2433 - auc: 0.9603 - val_loss: 0.2391 - val_auc: 0.9658\n",
            "Epoch 228/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2454 - auc: 0.9601 - val_loss: 0.2412 - val_auc: 0.9656\n",
            "Epoch 229/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2445 - auc: 0.9598 - val_loss: 0.2376 - val_auc: 0.9664\n",
            "Epoch 230/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2456 - auc: 0.9599 - val_loss: 0.2419 - val_auc: 0.9656\n",
            "Epoch 231/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2483 - auc: 0.9593 - val_loss: 0.2412 - val_auc: 0.9651\n",
            "Epoch 232/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2450 - auc: 0.9603 - val_loss: 0.2389 - val_auc: 0.9650\n",
            "Epoch 233/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2456 - auc: 0.9596 - val_loss: 0.2398 - val_auc: 0.9666\n",
            "Epoch 234/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2437 - auc: 0.9605 - val_loss: 0.2402 - val_auc: 0.9652\n",
            "Epoch 235/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2433 - auc: 0.9605 - val_loss: 0.2411 - val_auc: 0.9659\n",
            "Epoch 236/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2447 - auc: 0.9600 - val_loss: 0.2393 - val_auc: 0.9651\n",
            "Epoch 237/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2480 - auc: 0.9587 - val_loss: 0.2404 - val_auc: 0.9659\n",
            "Epoch 238/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2468 - auc: 0.9593 - val_loss: 0.2451 - val_auc: 0.9654\n",
            "Epoch 239/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2444 - auc: 0.9603 - val_loss: 0.2399 - val_auc: 0.9648\n",
            "Epoch 240/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2461 - auc: 0.9598 - val_loss: 0.2458 - val_auc: 0.9648\n",
            "Epoch 241/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2459 - auc: 0.9599 - val_loss: 0.2384 - val_auc: 0.9646\n",
            "Epoch 242/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2434 - auc: 0.9605 - val_loss: 0.2391 - val_auc: 0.9656\n",
            "Epoch 243/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2437 - auc: 0.9603 - val_loss: 0.2369 - val_auc: 0.9667\n",
            "Epoch 244/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2423 - auc: 0.9608 - val_loss: 0.2419 - val_auc: 0.9664\n",
            "Epoch 245/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2425 - auc: 0.9608 - val_loss: 0.2411 - val_auc: 0.9663\n",
            "Epoch 246/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2462 - auc: 0.9593 - val_loss: 0.2470 - val_auc: 0.9644\n",
            "Epoch 247/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2454 - auc: 0.9601 - val_loss: 0.2427 - val_auc: 0.9648\n",
            "Epoch 248/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2451 - auc: 0.9599 - val_loss: 0.2433 - val_auc: 0.9662\n",
            "Epoch 249/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2443 - auc: 0.9600 - val_loss: 0.2399 - val_auc: 0.9655\n",
            "Epoch 250/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2459 - auc: 0.9599 - val_loss: 0.2373 - val_auc: 0.9661\n",
            "Epoch 251/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2447 - auc: 0.9599 - val_loss: 0.2409 - val_auc: 0.9663\n",
            "Epoch 252/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2418 - auc: 0.9608 - val_loss: 0.2387 - val_auc: 0.9652\n",
            "Epoch 253/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2431 - auc: 0.9604 - val_loss: 0.2457 - val_auc: 0.9649\n",
            "Epoch 254/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2430 - auc: 0.9606 - val_loss: 0.2406 - val_auc: 0.9661\n",
            "Epoch 255/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2434 - auc: 0.9606 - val_loss: 0.2434 - val_auc: 0.9651\n",
            "Epoch 256/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2427 - auc: 0.9609 - val_loss: 0.2411 - val_auc: 0.9662\n",
            "Epoch 257/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2420 - auc: 0.9611 - val_loss: 0.2400 - val_auc: 0.9661\n",
            "Epoch 258/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2432 - auc: 0.9608 - val_loss: 0.2369 - val_auc: 0.9669\n",
            "Epoch 259/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2433 - auc: 0.9608 - val_loss: 0.2453 - val_auc: 0.9651\n",
            "Epoch 260/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2464 - auc: 0.9596 - val_loss: 0.2387 - val_auc: 0.9661\n",
            "Epoch 261/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2456 - auc: 0.9598 - val_loss: 0.2442 - val_auc: 0.9654\n",
            "Epoch 262/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2438 - auc: 0.9606 - val_loss: 0.2375 - val_auc: 0.9671\n",
            "Epoch 263/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2431 - auc: 0.9606 - val_loss: 0.2381 - val_auc: 0.9665\n",
            "Epoch 264/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2433 - auc: 0.9605 - val_loss: 0.2419 - val_auc: 0.9649\n",
            "Epoch 265/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2459 - auc: 0.9594 - val_loss: 0.2388 - val_auc: 0.9669\n",
            "Epoch 266/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2434 - auc: 0.9602 - val_loss: 0.2362 - val_auc: 0.9664\n",
            "Epoch 267/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2443 - auc: 0.9601 - val_loss: 0.2439 - val_auc: 0.9662\n",
            "Epoch 268/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2428 - auc: 0.9604 - val_loss: 0.2402 - val_auc: 0.9656\n",
            "Epoch 269/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2454 - auc: 0.9596 - val_loss: 0.2433 - val_auc: 0.9650\n",
            "Epoch 270/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2421 - auc: 0.9609 - val_loss: 0.2415 - val_auc: 0.9656\n",
            "Epoch 271/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2437 - auc: 0.9606 - val_loss: 0.2417 - val_auc: 0.9662\n",
            "Epoch 272/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2420 - auc: 0.9610 - val_loss: 0.2373 - val_auc: 0.9661\n",
            "Epoch 273/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2418 - auc: 0.9610 - val_loss: 0.2359 - val_auc: 0.9667\n",
            "Epoch 274/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2441 - auc: 0.9600 - val_loss: 0.2395 - val_auc: 0.9679\n",
            "Epoch 275/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2418 - auc: 0.9611 - val_loss: 0.2433 - val_auc: 0.9650\n",
            "Epoch 276/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2431 - auc: 0.9607 - val_loss: 0.2392 - val_auc: 0.9660\n",
            "Epoch 277/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2408 - auc: 0.9612 - val_loss: 0.2389 - val_auc: 0.9660\n",
            "Epoch 278/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2412 - auc: 0.9614 - val_loss: 0.2411 - val_auc: 0.9657\n",
            "Epoch 279/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2444 - auc: 0.9601 - val_loss: 0.2414 - val_auc: 0.9660\n",
            "Epoch 280/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2447 - auc: 0.9600 - val_loss: 0.2420 - val_auc: 0.9665\n",
            "Epoch 281/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2426 - auc: 0.9606 - val_loss: 0.2400 - val_auc: 0.9657\n",
            "Epoch 282/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2417 - auc: 0.9608 - val_loss: 0.2431 - val_auc: 0.9655\n",
            "Epoch 283/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2413 - auc: 0.9608 - val_loss: 0.2394 - val_auc: 0.9664\n",
            "Epoch 284/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2440 - auc: 0.9603 - val_loss: 0.2409 - val_auc: 0.9658\n",
            "Epoch 285/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2440 - auc: 0.9602 - val_loss: 0.2422 - val_auc: 0.9656\n",
            "Epoch 286/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2422 - auc: 0.9609 - val_loss: 0.2402 - val_auc: 0.9653\n",
            "Epoch 287/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2425 - auc: 0.9607 - val_loss: 0.2374 - val_auc: 0.9665\n",
            "Epoch 288/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2406 - auc: 0.9613 - val_loss: 0.2388 - val_auc: 0.9661\n",
            "Epoch 289/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2417 - auc: 0.9610 - val_loss: 0.2422 - val_auc: 0.9667\n",
            "Epoch 290/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2413 - auc: 0.9608 - val_loss: 0.2395 - val_auc: 0.9664\n",
            "Epoch 291/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2438 - auc: 0.9602 - val_loss: 0.2398 - val_auc: 0.9669\n",
            "Epoch 292/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2450 - auc: 0.9600 - val_loss: 0.2411 - val_auc: 0.9660\n",
            "Epoch 293/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2447 - auc: 0.9599 - val_loss: 0.2390 - val_auc: 0.9664\n",
            "Epoch 294/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2434 - auc: 0.9604 - val_loss: 0.2399 - val_auc: 0.9651\n",
            "Epoch 295/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2472 - auc: 0.9593 - val_loss: 0.2406 - val_auc: 0.9659\n",
            "Epoch 296/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2435 - auc: 0.9601 - val_loss: 0.2426 - val_auc: 0.9656\n",
            "Epoch 297/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2446 - auc: 0.9602 - val_loss: 0.2444 - val_auc: 0.9652\n",
            "Epoch 298/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2439 - auc: 0.9603 - val_loss: 0.2356 - val_auc: 0.9669\n",
            "Epoch 299/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2423 - auc: 0.9613 - val_loss: 0.2390 - val_auc: 0.9664\n",
            "Epoch 300/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2423 - auc: 0.9606 - val_loss: 0.2395 - val_auc: 0.9662\n",
            "Epoch 301/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2427 - auc: 0.9605 - val_loss: 0.2399 - val_auc: 0.9663\n",
            "Epoch 302/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2438 - auc: 0.9603 - val_loss: 0.2361 - val_auc: 0.9660\n",
            "Epoch 303/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2412 - auc: 0.9610 - val_loss: 0.2393 - val_auc: 0.9657\n",
            "Epoch 304/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2437 - auc: 0.9605 - val_loss: 0.2397 - val_auc: 0.9659\n",
            "Epoch 305/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2423 - auc: 0.9605 - val_loss: 0.2412 - val_auc: 0.9657\n",
            "Epoch 306/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2410 - auc: 0.9611 - val_loss: 0.2370 - val_auc: 0.9660\n",
            "Epoch 307/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2419 - auc: 0.9605 - val_loss: 0.2401 - val_auc: 0.9645\n",
            "Epoch 308/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2437 - auc: 0.9602 - val_loss: 0.2385 - val_auc: 0.9661\n",
            "Epoch 309/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2425 - auc: 0.9605 - val_loss: 0.2363 - val_auc: 0.9663\n",
            "Epoch 310/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2438 - auc: 0.9601 - val_loss: 0.2393 - val_auc: 0.9650\n",
            "Epoch 311/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2427 - auc: 0.9606 - val_loss: 0.2383 - val_auc: 0.9668\n",
            "Epoch 312/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2424 - auc: 0.9607 - val_loss: 0.2351 - val_auc: 0.9661\n",
            "Epoch 313/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2410 - auc: 0.9612 - val_loss: 0.2432 - val_auc: 0.9664\n",
            "Epoch 314/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2422 - auc: 0.9608 - val_loss: 0.2368 - val_auc: 0.9669\n",
            "Epoch 315/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2403 - auc: 0.9616 - val_loss: 0.2350 - val_auc: 0.9678\n",
            "Epoch 316/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2397 - auc: 0.9615 - val_loss: 0.2411 - val_auc: 0.9660\n",
            "Epoch 317/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2418 - auc: 0.9608 - val_loss: 0.2382 - val_auc: 0.9661\n",
            "Epoch 318/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2428 - auc: 0.9606 - val_loss: 0.2385 - val_auc: 0.9653\n",
            "Epoch 319/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2411 - auc: 0.9612 - val_loss: 0.2365 - val_auc: 0.9655\n",
            "Epoch 320/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2406 - auc: 0.9614 - val_loss: 0.2341 - val_auc: 0.9666\n",
            "Epoch 321/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2417 - auc: 0.9608 - val_loss: 0.2367 - val_auc: 0.9664\n",
            "Epoch 322/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2424 - auc: 0.9609 - val_loss: 0.2366 - val_auc: 0.9653\n",
            "Epoch 323/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2429 - auc: 0.9604 - val_loss: 0.2361 - val_auc: 0.9663\n",
            "Epoch 324/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2428 - auc: 0.9604 - val_loss: 0.2387 - val_auc: 0.9654\n",
            "Epoch 325/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2410 - auc: 0.9613 - val_loss: 0.2397 - val_auc: 0.9657\n",
            "Epoch 326/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2424 - auc: 0.9609 - val_loss: 0.2398 - val_auc: 0.9662\n",
            "Epoch 327/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2422 - auc: 0.9610 - val_loss: 0.2367 - val_auc: 0.9670\n",
            "Epoch 328/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2402 - auc: 0.9613 - val_loss: 0.2380 - val_auc: 0.9663\n",
            "Epoch 329/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2408 - auc: 0.9612 - val_loss: 0.2364 - val_auc: 0.9671\n",
            "Epoch 330/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2416 - auc: 0.9610 - val_loss: 0.2385 - val_auc: 0.9663\n",
            "Epoch 331/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2406 - auc: 0.9610 - val_loss: 0.2370 - val_auc: 0.9643\n",
            "Epoch 332/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2425 - auc: 0.9604 - val_loss: 0.2370 - val_auc: 0.9665\n",
            "Epoch 333/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2434 - auc: 0.9605 - val_loss: 0.2360 - val_auc: 0.9664\n",
            "Epoch 334/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2410 - auc: 0.9612 - val_loss: 0.2363 - val_auc: 0.9674\n",
            "Epoch 335/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2400 - auc: 0.9614 - val_loss: 0.2379 - val_auc: 0.9656\n",
            "Epoch 336/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2415 - auc: 0.9613 - val_loss: 0.2337 - val_auc: 0.9666\n",
            "Epoch 337/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2420 - auc: 0.9608 - val_loss: 0.2364 - val_auc: 0.9663\n",
            "Epoch 338/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2403 - auc: 0.9613 - val_loss: 0.2371 - val_auc: 0.9665\n",
            "Epoch 339/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2424 - auc: 0.9605 - val_loss: 0.2371 - val_auc: 0.9664\n",
            "Epoch 340/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2427 - auc: 0.9608 - val_loss: 0.2372 - val_auc: 0.9672\n",
            "Epoch 341/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2416 - auc: 0.9612 - val_loss: 0.2358 - val_auc: 0.9670\n",
            "Epoch 342/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2420 - auc: 0.9608 - val_loss: 0.2371 - val_auc: 0.9669\n",
            "Epoch 343/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2410 - auc: 0.9612 - val_loss: 0.2387 - val_auc: 0.9669\n",
            "Epoch 344/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2422 - auc: 0.9606 - val_loss: 0.2358 - val_auc: 0.9657\n",
            "Epoch 345/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2410 - auc: 0.9610 - val_loss: 0.2342 - val_auc: 0.9666\n",
            "Epoch 346/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2394 - auc: 0.9615 - val_loss: 0.2344 - val_auc: 0.9671\n",
            "Epoch 347/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2411 - auc: 0.9616 - val_loss: 0.2407 - val_auc: 0.9670\n",
            "Epoch 348/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2398 - auc: 0.9615 - val_loss: 0.2327 - val_auc: 0.9670\n",
            "Epoch 349/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2399 - auc: 0.9617 - val_loss: 0.2362 - val_auc: 0.9676\n",
            "Epoch 350/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2423 - auc: 0.9612 - val_loss: 0.2329 - val_auc: 0.9673\n",
            "Epoch 351/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2394 - auc: 0.9620 - val_loss: 0.2335 - val_auc: 0.9673\n",
            "Epoch 352/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2395 - auc: 0.9615 - val_loss: 0.2331 - val_auc: 0.9677\n",
            "Epoch 353/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2402 - auc: 0.9615 - val_loss: 0.2368 - val_auc: 0.9662\n",
            "Epoch 354/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2405 - auc: 0.9614 - val_loss: 0.2323 - val_auc: 0.9677\n",
            "Epoch 355/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2414 - auc: 0.9613 - val_loss: 0.2360 - val_auc: 0.9668\n",
            "Epoch 356/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2414 - auc: 0.9614 - val_loss: 0.2395 - val_auc: 0.9662\n",
            "Epoch 357/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2409 - auc: 0.9614 - val_loss: 0.2360 - val_auc: 0.9664\n",
            "Epoch 358/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2408 - auc: 0.9612 - val_loss: 0.2352 - val_auc: 0.9662\n",
            "Epoch 359/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2422 - auc: 0.9610 - val_loss: 0.2395 - val_auc: 0.9663\n",
            "Epoch 360/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2418 - auc: 0.9607 - val_loss: 0.2351 - val_auc: 0.9669\n",
            "Epoch 361/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2407 - auc: 0.9611 - val_loss: 0.2343 - val_auc: 0.9670\n",
            "Epoch 362/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2408 - auc: 0.9613 - val_loss: 0.2352 - val_auc: 0.9675\n",
            "Epoch 363/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2409 - auc: 0.9614 - val_loss: 0.2366 - val_auc: 0.9663\n",
            "Epoch 364/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2404 - auc: 0.9610 - val_loss: 0.2342 - val_auc: 0.9676\n",
            "Epoch 365/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2408 - auc: 0.9611 - val_loss: 0.2367 - val_auc: 0.9665\n",
            "Epoch 366/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2413 - auc: 0.9610 - val_loss: 0.2384 - val_auc: 0.9664\n",
            "Epoch 367/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2403 - auc: 0.9613 - val_loss: 0.2356 - val_auc: 0.9656\n",
            "Epoch 368/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2413 - auc: 0.9613 - val_loss: 0.2359 - val_auc: 0.9653\n",
            "Epoch 369/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2418 - auc: 0.9607 - val_loss: 0.2356 - val_auc: 0.9656\n",
            "Epoch 370/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2379 - auc: 0.9621 - val_loss: 0.2374 - val_auc: 0.9658\n",
            "Epoch 371/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2391 - auc: 0.9613 - val_loss: 0.2390 - val_auc: 0.9662\n",
            "Epoch 372/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2401 - auc: 0.9612 - val_loss: 0.2336 - val_auc: 0.9671\n",
            "Epoch 373/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2417 - auc: 0.9603 - val_loss: 0.2346 - val_auc: 0.9659\n",
            "Epoch 374/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2423 - auc: 0.9605 - val_loss: 0.2407 - val_auc: 0.9648\n",
            "Epoch 375/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2392 - auc: 0.9615 - val_loss: 0.2334 - val_auc: 0.9676\n",
            "Epoch 376/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2427 - auc: 0.9603 - val_loss: 0.2327 - val_auc: 0.9674\n",
            "Epoch 377/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2396 - auc: 0.9615 - val_loss: 0.2350 - val_auc: 0.9670\n",
            "Epoch 378/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2391 - auc: 0.9618 - val_loss: 0.2361 - val_auc: 0.9669\n",
            "Epoch 379/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2393 - auc: 0.9616 - val_loss: 0.2398 - val_auc: 0.9670\n",
            "Epoch 380/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2399 - auc: 0.9617 - val_loss: 0.2350 - val_auc: 0.9664\n",
            "Epoch 381/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2396 - auc: 0.9613 - val_loss: 0.2344 - val_auc: 0.9665\n",
            "Epoch 382/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2406 - auc: 0.9614 - val_loss: 0.2328 - val_auc: 0.9672\n",
            "Epoch 383/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2402 - auc: 0.9611 - val_loss: 0.2340 - val_auc: 0.9663\n",
            "Epoch 384/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2419 - auc: 0.9608 - val_loss: 0.2347 - val_auc: 0.9655\n",
            "Epoch 385/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2396 - auc: 0.9614 - val_loss: 0.2380 - val_auc: 0.9662\n",
            "Epoch 386/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2415 - auc: 0.9607 - val_loss: 0.2369 - val_auc: 0.9675\n",
            "Epoch 387/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2421 - auc: 0.9604 - val_loss: 0.2354 - val_auc: 0.9665\n",
            "Epoch 388/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2405 - auc: 0.9611 - val_loss: 0.2352 - val_auc: 0.9664\n",
            "Epoch 389/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2391 - auc: 0.9615 - val_loss: 0.2329 - val_auc: 0.9660\n",
            "Epoch 390/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2418 - auc: 0.9608 - val_loss: 0.2338 - val_auc: 0.9668\n",
            "Epoch 391/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2415 - auc: 0.9612 - val_loss: 0.2383 - val_auc: 0.9649\n",
            "Epoch 392/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2424 - auc: 0.9610 - val_loss: 0.2355 - val_auc: 0.9661\n",
            "Epoch 393/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2404 - auc: 0.9616 - val_loss: 0.2325 - val_auc: 0.9675\n",
            "Epoch 394/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2411 - auc: 0.9611 - val_loss: 0.2366 - val_auc: 0.9668\n",
            "Epoch 395/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2423 - auc: 0.9609 - val_loss: 0.2352 - val_auc: 0.9654\n",
            "Epoch 396/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2380 - auc: 0.9621 - val_loss: 0.2325 - val_auc: 0.9674\n",
            "Epoch 397/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2396 - auc: 0.9617 - val_loss: 0.2351 - val_auc: 0.9662\n",
            "Epoch 398/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2394 - auc: 0.9618 - val_loss: 0.2365 - val_auc: 0.9666\n",
            "Epoch 399/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2385 - auc: 0.9618 - val_loss: 0.2335 - val_auc: 0.9669\n",
            "Epoch 400/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2417 - auc: 0.9608 - val_loss: 0.2356 - val_auc: 0.9678\n",
            "Epoch 401/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2377 - auc: 0.9624 - val_loss: 0.2350 - val_auc: 0.9666\n",
            "Epoch 402/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2381 - auc: 0.9623 - val_loss: 0.2347 - val_auc: 0.9668\n",
            "Epoch 403/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2389 - auc: 0.9619 - val_loss: 0.2354 - val_auc: 0.9657\n",
            "Epoch 404/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2405 - auc: 0.9614 - val_loss: 0.2372 - val_auc: 0.9669\n",
            "Epoch 405/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2413 - auc: 0.9610 - val_loss: 0.2366 - val_auc: 0.9660\n",
            "Epoch 406/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2394 - auc: 0.9614 - val_loss: 0.2324 - val_auc: 0.9680\n",
            "Epoch 407/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2400 - auc: 0.9614 - val_loss: 0.2351 - val_auc: 0.9665\n",
            "Epoch 408/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2398 - auc: 0.9616 - val_loss: 0.2354 - val_auc: 0.9676\n",
            "Epoch 409/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2410 - auc: 0.9610 - val_loss: 0.2302 - val_auc: 0.9678\n",
            "Epoch 410/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2385 - auc: 0.9619 - val_loss: 0.2333 - val_auc: 0.9668\n",
            "Epoch 411/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2397 - auc: 0.9614 - val_loss: 0.2340 - val_auc: 0.9669\n",
            "Epoch 412/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2385 - auc: 0.9616 - val_loss: 0.2361 - val_auc: 0.9664\n",
            "Epoch 413/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2385 - auc: 0.9615 - val_loss: 0.2332 - val_auc: 0.9669\n",
            "Epoch 414/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2375 - auc: 0.9622 - val_loss: 0.2347 - val_auc: 0.9670\n",
            "Epoch 415/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2417 - auc: 0.9610 - val_loss: 0.2358 - val_auc: 0.9672\n",
            "Epoch 416/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2401 - auc: 0.9615 - val_loss: 0.2344 - val_auc: 0.9663\n",
            "Epoch 417/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2380 - auc: 0.9617 - val_loss: 0.2346 - val_auc: 0.9679\n",
            "Epoch 418/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2401 - auc: 0.9614 - val_loss: 0.2324 - val_auc: 0.9674\n",
            "Epoch 419/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2400 - auc: 0.9616 - val_loss: 0.2361 - val_auc: 0.9664\n",
            "Epoch 420/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2400 - auc: 0.9615 - val_loss: 0.2334 - val_auc: 0.9671\n",
            "Epoch 421/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2376 - auc: 0.9623 - val_loss: 0.2319 - val_auc: 0.9670\n",
            "Epoch 422/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2374 - auc: 0.9621 - val_loss: 0.2318 - val_auc: 0.9674\n",
            "Epoch 423/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2378 - auc: 0.9620 - val_loss: 0.2304 - val_auc: 0.9684\n",
            "Epoch 424/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2374 - auc: 0.9624 - val_loss: 0.2375 - val_auc: 0.9669\n",
            "Epoch 425/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2378 - auc: 0.9621 - val_loss: 0.2318 - val_auc: 0.9668\n",
            "Epoch 426/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2387 - auc: 0.9618 - val_loss: 0.2314 - val_auc: 0.9671\n",
            "Epoch 427/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2389 - auc: 0.9621 - val_loss: 0.2356 - val_auc: 0.9664\n",
            "Epoch 428/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2401 - auc: 0.9614 - val_loss: 0.2331 - val_auc: 0.9663\n",
            "Epoch 429/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2393 - auc: 0.9617 - val_loss: 0.2331 - val_auc: 0.9676\n",
            "Epoch 430/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2395 - auc: 0.9620 - val_loss: 0.2330 - val_auc: 0.9669\n",
            "Epoch 431/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2373 - auc: 0.9623 - val_loss: 0.2315 - val_auc: 0.9678\n",
            "Epoch 432/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2382 - auc: 0.9621 - val_loss: 0.2350 - val_auc: 0.9670\n",
            "Epoch 433/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2363 - auc: 0.9627 - val_loss: 0.2306 - val_auc: 0.9679\n",
            "Epoch 434/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2386 - auc: 0.9616 - val_loss: 0.2330 - val_auc: 0.9672\n",
            "Epoch 435/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2367 - auc: 0.9628 - val_loss: 0.2315 - val_auc: 0.9684\n",
            "Epoch 436/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2377 - auc: 0.9623 - val_loss: 0.2346 - val_auc: 0.9660\n",
            "Epoch 437/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2385 - auc: 0.9619 - val_loss: 0.2316 - val_auc: 0.9662\n",
            "Epoch 438/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2410 - auc: 0.9609 - val_loss: 0.2328 - val_auc: 0.9669\n",
            "Epoch 439/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2400 - auc: 0.9614 - val_loss: 0.2355 - val_auc: 0.9663\n",
            "Epoch 440/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2399 - auc: 0.9616 - val_loss: 0.2358 - val_auc: 0.9665\n",
            "Epoch 441/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2385 - auc: 0.9619 - val_loss: 0.2354 - val_auc: 0.9662\n",
            "Epoch 442/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2386 - auc: 0.9616 - val_loss: 0.2334 - val_auc: 0.9672\n",
            "Epoch 443/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2377 - auc: 0.9621 - val_loss: 0.2305 - val_auc: 0.9683\n",
            "Epoch 444/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2368 - auc: 0.9627 - val_loss: 0.2308 - val_auc: 0.9681\n",
            "Epoch 445/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2383 - auc: 0.9620 - val_loss: 0.2348 - val_auc: 0.9678\n",
            "Epoch 446/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2370 - auc: 0.9621 - val_loss: 0.2330 - val_auc: 0.9675\n",
            "Epoch 447/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2386 - auc: 0.9618 - val_loss: 0.2317 - val_auc: 0.9679\n",
            "Epoch 448/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2389 - auc: 0.9620 - val_loss: 0.2369 - val_auc: 0.9658\n",
            "Epoch 449/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2385 - auc: 0.9620 - val_loss: 0.2322 - val_auc: 0.9668\n",
            "Epoch 450/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2394 - auc: 0.9612 - val_loss: 0.2315 - val_auc: 0.9672\n",
            "Epoch 451/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2375 - auc: 0.9621 - val_loss: 0.2321 - val_auc: 0.9675\n",
            "Epoch 452/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2375 - auc: 0.9625 - val_loss: 0.2327 - val_auc: 0.9661\n",
            "Epoch 453/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2380 - auc: 0.9620 - val_loss: 0.2334 - val_auc: 0.9673\n",
            "Epoch 454/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2385 - auc: 0.9619 - val_loss: 0.2346 - val_auc: 0.9678\n",
            "Epoch 455/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2373 - auc: 0.9620 - val_loss: 0.2338 - val_auc: 0.9665\n",
            "Epoch 456/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2385 - auc: 0.9621 - val_loss: 0.2345 - val_auc: 0.9673\n",
            "Epoch 457/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2391 - auc: 0.9618 - val_loss: 0.2310 - val_auc: 0.9680\n",
            "Epoch 458/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2401 - auc: 0.9618 - val_loss: 0.2327 - val_auc: 0.9672\n",
            "Epoch 459/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2360 - auc: 0.9627 - val_loss: 0.2378 - val_auc: 0.9666\n",
            "Epoch 460/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2392 - auc: 0.9616 - val_loss: 0.2340 - val_auc: 0.9678\n",
            "Epoch 461/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2403 - auc: 0.9612 - val_loss: 0.2332 - val_auc: 0.9677\n",
            "Epoch 462/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2370 - auc: 0.9624 - val_loss: 0.2333 - val_auc: 0.9678\n",
            "Epoch 463/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2395 - auc: 0.9611 - val_loss: 0.2322 - val_auc: 0.9667\n",
            "Epoch 464/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2399 - auc: 0.9612 - val_loss: 0.2334 - val_auc: 0.9665\n",
            "Epoch 465/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2383 - auc: 0.9621 - val_loss: 0.2350 - val_auc: 0.9675\n",
            "Epoch 466/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2374 - auc: 0.9624 - val_loss: 0.2301 - val_auc: 0.9681\n",
            "Epoch 467/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2372 - auc: 0.9624 - val_loss: 0.2313 - val_auc: 0.9679\n",
            "Epoch 468/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2386 - auc: 0.9620 - val_loss: 0.2353 - val_auc: 0.9674\n",
            "Epoch 469/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2409 - auc: 0.9616 - val_loss: 0.2319 - val_auc: 0.9679\n",
            "Epoch 470/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2367 - auc: 0.9624 - val_loss: 0.2336 - val_auc: 0.9665\n",
            "Epoch 471/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2384 - auc: 0.9619 - val_loss: 0.2341 - val_auc: 0.9662\n",
            "Epoch 472/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2374 - auc: 0.9621 - val_loss: 0.2335 - val_auc: 0.9669\n",
            "Epoch 473/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2361 - auc: 0.9628 - val_loss: 0.2306 - val_auc: 0.9672\n",
            "Epoch 474/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2373 - auc: 0.9621 - val_loss: 0.2325 - val_auc: 0.9673\n",
            "Epoch 475/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2381 - auc: 0.9620 - val_loss: 0.2301 - val_auc: 0.9678\n",
            "Epoch 476/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2375 - auc: 0.9624 - val_loss: 0.2325 - val_auc: 0.9661\n",
            "Epoch 477/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2388 - auc: 0.9619 - val_loss: 0.2318 - val_auc: 0.9681\n",
            "Epoch 478/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2371 - auc: 0.9623 - val_loss: 0.2339 - val_auc: 0.9674\n",
            "Epoch 479/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2365 - auc: 0.9622 - val_loss: 0.2341 - val_auc: 0.9669\n",
            "Epoch 480/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2375 - auc: 0.9623 - val_loss: 0.2358 - val_auc: 0.9651\n",
            "Epoch 481/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2363 - auc: 0.9626 - val_loss: 0.2296 - val_auc: 0.9670\n",
            "Epoch 482/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2369 - auc: 0.9624 - val_loss: 0.2313 - val_auc: 0.9671\n",
            "Epoch 483/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2372 - auc: 0.9621 - val_loss: 0.2342 - val_auc: 0.9669\n",
            "Epoch 484/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2389 - auc: 0.9620 - val_loss: 0.2365 - val_auc: 0.9673\n",
            "Epoch 485/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2357 - auc: 0.9628 - val_loss: 0.2320 - val_auc: 0.9670\n",
            "Epoch 486/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2363 - auc: 0.9626 - val_loss: 0.2292 - val_auc: 0.9677\n",
            "Epoch 487/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2388 - auc: 0.9618 - val_loss: 0.2333 - val_auc: 0.9669\n",
            "Epoch 488/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2372 - auc: 0.9622 - val_loss: 0.2318 - val_auc: 0.9677\n",
            "Epoch 489/500\n",
            "117/117 [==============================] - 1s 11ms/step - loss: 0.2355 - auc: 0.9627 - val_loss: 0.2322 - val_auc: 0.9668\n",
            "Epoch 490/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2374 - auc: 0.9620 - val_loss: 0.2348 - val_auc: 0.9672\n",
            "Epoch 491/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2363 - auc: 0.9623 - val_loss: 0.2343 - val_auc: 0.9670\n",
            "Epoch 492/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2374 - auc: 0.9620 - val_loss: 0.2313 - val_auc: 0.9672\n",
            "Epoch 493/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2390 - auc: 0.9611 - val_loss: 0.2364 - val_auc: 0.9656\n",
            "Epoch 494/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2382 - auc: 0.9617 - val_loss: 0.2335 - val_auc: 0.9673\n",
            "Epoch 495/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2358 - auc: 0.9629 - val_loss: 0.2325 - val_auc: 0.9676\n",
            "Epoch 496/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2378 - auc: 0.9619 - val_loss: 0.2344 - val_auc: 0.9666\n",
            "Epoch 497/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2377 - auc: 0.9618 - val_loss: 0.2344 - val_auc: 0.9669\n",
            "Epoch 498/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2381 - auc: 0.9619 - val_loss: 0.2356 - val_auc: 0.9673\n",
            "Epoch 499/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2358 - auc: 0.9629 - val_loss: 0.2307 - val_auc: 0.9685\n",
            "Epoch 500/500\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2370 - auc: 0.9623 - val_loss: 0.2332 - val_auc: 0.9667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}